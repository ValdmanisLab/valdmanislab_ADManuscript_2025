{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# # Notebook Initialization"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check the information of the Notebook\n",
    "import sys\n",
    "print(sys.version)\n",
    "!pip list > ./pip_installed_packages.txt\n",
    "!conda list > ./conda_installed_packages.txt"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Set up the Environment and read Functions"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "import subprocess\n",
    "\n",
    "def install_packages(packages):\n",
    "    \"\"\"Check and install required packages.\"\"\"\n",
    "    for package in packages:\n",
    "        try:\n",
    "            spec = importlib.util.find_spec(package)\n",
    "            if spec is None:\n",
    "                print(f\"{package} is not installed. Installing...\")\n",
    "                subprocess.check_call([\"pip\", \"install\", package])\n",
    "            else:\n",
    "                print(f\"{package} is already installed.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error while installing {package}: {e}\")\n",
    "\n",
    "# List of packages to check/install\n",
    "required_packages = [\n",
    "    \"geopandas\", \"pgeocode\", \"geopy\", \"flexitext\", \"umap-learn\",\"lifelines\",\n",
    "    \"datashader\", \"bokeh\", \"holoviews\", \"scikit-image\", \"colorcet\", \"dask[complete]\"\n",
    "]\n",
    "\n",
    "# Call the function to install packages if needed\n",
    "install_packages(required_packages)\n",
    "\n",
    "# Main Imports\n",
    "import numpy as np\n",
    "from scipy.interpolate import make_interp_spline\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import statsmodels.stats.multicomp as mc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import hail as hl\n",
    "from hail.plot import show, output_notebook\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PowerTransformer, OneHotEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from tabulate import tabulate\n",
    "import ast\n",
    "from scipy.stats import ttest_1samp\n",
    "import matplotlib.cm as cm\n",
    "from collections import defaultdict\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats import mannwhitneyu\n",
    "import itertools\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.stats import skew, kurtosis\n",
    "from lifelines import KaplanMeierFitter\n",
    "import matplotlib.lines as mlines\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from scipy.stats import ttest_1samp, wilcoxon\n",
    "from statsmodels.stats.proportion import proportions_ztest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# create some fonctions new and old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     4,
     54,
     67,
     81,
     95,
     111,
     249,
     301,
     337,
     379,
     488
    ],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def save(folder_name,filename,file):\n",
    "    # Replace df with THE NAME OF YOUR DATAFRAME\n",
    "    my_dataframe = file\n",
    "    destination_filename = '{}/{}'.format(folder_name,filename)\n",
    "    # save dataframe in a csv file in the same workspace as the notebook\n",
    "    my_dataframe.to_csv(destination_filename, index=False)\n",
    "    # get the bucket name\n",
    "    my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "    # copy csv file to the bucket\n",
    "    args = [\"gsutil\", \"cp\", f\"./{destination_filename}\", f\"{my_bucket}/data/\"]\n",
    "    output = subprocess.run(args, capture_output=True)\n",
    "    # print output from gsutil\n",
    "    output.stderr\n",
    "def read_tsv(file_name,path='/'):\n",
    "    # Replace 'test.csv' with THE NAME of the file you're going to download from the bucket (don't delete the quotation marks)\n",
    "    if path == '/':\n",
    "        name_of_file_in_bucket = '{}'.format(file_name)\n",
    "    else:\n",
    "        name_of_file_in_bucket = '{}/{}'.format(path,file_name)\n",
    "    # get the bucket name\n",
    "    my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "    # copy csv file from the bucket to the current working space\n",
    "    os.system(f\"gsutil cp '{my_bucket}/data/{name_of_file_in_bucket}' .\")\n",
    "    print(f'[INFO] {name_of_file_in_bucket} is successfully downloaded into your working space')\n",
    "    # save dataframe in a csv file in the same workspace as the notebook\n",
    "    file = pd.read_csv(name_of_file_in_bucket,sep='\\t')\n",
    "    return file\n",
    "def read_csv(file_name,path='/'):\n",
    "    # Replace 'test.csv' with THE NAME of the file you're going to download from the bucket (don't delete the quotation marks)\n",
    "    if path == '/':\n",
    "        name_of_file_in_bucket = '{}'.format(file_name)\n",
    "    else:\n",
    "        name_of_file_in_bucket = '{}/{}'.format(path,file_name)\n",
    "    # get the bucket name\n",
    "    my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "    # copy csv file from the bucket to the current working space\n",
    "    os.system(f\"gsutil cp '{my_bucket}/data/{name_of_file_in_bucket}' .\")\n",
    "    print(f'[INFO] {name_of_file_in_bucket} is successfully downloaded into your working space')\n",
    "    # save dataframe in a csv file in the same workspace as the notebook\n",
    "    file = pd.read_csv(name_of_file_in_bucket,sep=',')\n",
    "    return file\n",
    "def initialize_hail_environment():\n",
    "    \"\"\"\n",
    "    Initialize the Hail environment and return the bucket variable and genomic location.\n",
    "\n",
    "    Returns:\n",
    "    str: Bucket variable for storing Hail data.\n",
    "    str: Genomic location.\n",
    "    \"\"\"\n",
    "    # Initialize Hail\n",
    "    hl.init(default_reference=\"GRCh38\")\n",
    "    \n",
    "    # Retrieve bucket variable and genomic location\n",
    "    bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "    genomic_location = os.getenv(\"CDR_STORAGE_PATH\")\n",
    "    \n",
    "    return bucket, genomic_location\n",
    "def read_person_information():\n",
    "    \"\"\"\n",
    "    Reads person information from a given file and filters it to keep only data with ICD10 and ICD9 codes.\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing filtered person information.\n",
    "    str: Message indicating the action taken.\n",
    "    \"\"\"\n",
    "    # This query represents dataset \"All participants\" for domain \"condition\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "    dataset_25030714_condition_sql = \"\"\"\n",
    "        SELECT\n",
    "            c_occurrence.person_id,\n",
    "            c_occurrence.condition_concept_id,\n",
    "            c_standard_concept.concept_name as standard_concept_name,\n",
    "            c_standard_concept.concept_code as standard_concept_code,\n",
    "            c_standard_concept.vocabulary_id as standard_vocabulary,\n",
    "            c_occurrence.condition_start_datetime,\n",
    "            c_occurrence.condition_end_datetime,\n",
    "            c_occurrence.condition_type_concept_id,\n",
    "            c_type.concept_name as condition_type_concept_name,\n",
    "            c_occurrence.stop_reason,\n",
    "            c_occurrence.visit_occurrence_id,\n",
    "            visit.concept_name as visit_occurrence_concept_name,\n",
    "            c_occurrence.condition_source_value,\n",
    "            c_occurrence.condition_source_concept_id,\n",
    "            c_source_concept.concept_name as source_concept_name,\n",
    "            c_source_concept.concept_code as source_concept_code,\n",
    "            c_source_concept.vocabulary_id as source_vocabulary,\n",
    "            c_occurrence.condition_status_source_value,\n",
    "            c_occurrence.condition_status_concept_id,\n",
    "            c_status.concept_name as condition_status_concept_name \n",
    "        FROM\n",
    "            ( SELECT\n",
    "                * \n",
    "            FROM\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".condition_occurrence` c_occurrence \n",
    "            WHERE\n",
    "                (\n",
    "                    condition_concept_id IN  (\n",
    "                        SELECT\n",
    "                            DISTINCT c.concept_id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                        JOIN\n",
    "                            (\n",
    "                                select\n",
    "                                    cast(cr.id as string) as id \n",
    "                                FROM\n",
    "                                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr \n",
    "                                WHERE\n",
    "                                    concept_id IN (\n",
    "                                        133468, 134057, 134736, 135930, 138239, 138525, 140190, 141960, 192438, 193460, 194133, 200174, 200219, 200452, 201618, 201891, 253549, 254068, 254761, 255919, 31610, 316866, 31821, 318800, 320128, 320136, 321588, 37018424, 37018713, 37203927, 37206233, 372887, 37311677, 37311678, 373499, 375252, 376106, 376208, 376337, 4000609, 4000610, 4002898, 4002905, 4006969, 4009890, 4011630, 4020346, 4021667, 4021780, 4021915, 4022201, 4022922, 4022923, 4022924, 4023995, 4024000, 4024013, 4024561, 4024566, 4024567, 4025215, 4027384, 4027553, 4028071, 4028076, 4028387, 4031814, 4038502, 4038677, 4038678, 4041283, 4041284, 4041285, 4041436, 4042056, 4042140, 4042141, 4042142, 4042503, 4042505, 4042835, 4042836, 4042837, 4043346, 4043371, 4043671, 4047779, 40480457, 40481517, 40481841, 40484102, 40484533, 40484935, 4051221, 4054501, 4071689, 4080992, 4081176, 4083787, 4086181, 4090426, 4090614, 4090615, 4091213, 4091363, 4091532, 4093227, 4093228, 4093991, 4094294, 4095793, 4096864, 4100932, 4101212, 4101343, 4101796, 4102111, 4103183, 4103320, 4103352, 4104157, 4113563, 4113999, 4115259, 4115386, 4115390, 4116811, 4117779, 4117930, 4132555, 4132926, 4134294, 4134440, 4150129, 4160062, 4162282, 4168335, 4170143, 4170226, 4170962, 4171379, 4175154, 4178545, 4178680, 4178818, 4179141, 4179167, 4179871, 4179873, 4180154, 4180169, 4180170, 4180628, 4181063, 4181187, 4182161, 4182165, 4182633, 4184252, 4185503, 4185640, 4190185, 4197094, 4198525, 4199402, 4200532, 4201745, 4206591, 4208786, 4212577, 4213101, 4221108, 4227253, 4244662, 4247371, 42538830, 4260918, 4266186, 4267789, 4269314, 4272867, 4274025, 4276569, 4276572, 4277352, 4293175, 4297887, 4301699, 4302537, 4304916, 4305027, 4308811, 4309188, 4316083, 4317258, 4318379, 432250, 432586, 432795, 432867, 4329041, 433128, 433736, 4338120, 4339410, 4339468, 4344497, 43530815, 43530877, 43531053, 43531054, 43531056, 43531057, 43531058, 43531059, 43531060, 435506, 435524, 436096, 436670, 437515, 438112, 440029, 440142, 440371, 440383, 440921, 441542, 442077, 443343, 443723, 443783, 443784, 443883, 444089, 444100, 444108, 444112, 444363, 44782620, 44783587, 44784102, 73553, 75865, 75909, 77074, 77670, 77960, 79106, 80180\n",
    "                                    ) \n",
    "                                    AND full_text LIKE '%_rank1]%'\n",
    "                            ) a \n",
    "                                ON (\n",
    "                                    c.path LIKE CONCAT('%.',\n",
    "                                a.id,\n",
    "                                '.%') \n",
    "                                OR c.path LIKE CONCAT('%.',\n",
    "                                a.id) \n",
    "                                OR c.path LIKE CONCAT(a.id,\n",
    "                                '.%') \n",
    "                                OR c.path = a.id) \n",
    "                            WHERE\n",
    "                                is_standard = 1 \n",
    "                                AND is_selectable = 1\n",
    "                            ) \n",
    "                            OR  condition_source_concept_id IN  (\n",
    "                                SELECT\n",
    "                                    DISTINCT c.concept_id \n",
    "                                FROM\n",
    "                                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                                JOIN\n",
    "                                    (\n",
    "                                        select\n",
    "                                            cast(cr.id as string) as id \n",
    "                                        FROM\n",
    "                                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr \n",
    "                                        WHERE\n",
    "                                            concept_id IN (\n",
    "                                                1326492, 1326493, 1326788, 1326896, 1326897, 1326898, 1326899, 1553844, 1567858, 1567893, 1567956, 1567958, 1567959, 1567960, 1567964, 1567965, 1567966, 1567969, 1567971, 1568017, 1568022, 1568023, 1568062, 1568177, 1568178, 1568179, 1568180, 1568217, 1568232, 1568233, 1568330, 1568337, 1568339, 1568344, 1568362, 1568363, 1568364, 1568366, 1568420, 1568421, 1568422, 1569133, 1569134, 1569135, 1569145, 1569447, 1569472, 1569473, 1569488, 1569489, 1569490, 1569491, 1569558, 1569639, 1569650, 1569657, 1569658, 1569659, 1569660, 1569661, 1569662, 1569663, 1569664, 1569665, 1569811, 1570333, 1570557, 1570563, 1570565, 1570566, 1570567, 1570568, 1570569, 1570570, 1570663, 1570671, 1570701, 1570703, 1570704, 1570705, 1570790, 1570791, 1570824, 1570832, 1571057, 1571059, 1571060, 1571061, 1571062, 1571063, 1571064, 1571177, 1571515, 1571516, 1571517, 1572190, 1572191, 1572193, 1572198, 1572201, 1572203, 1572209, 1572226, 1572229, 1572255, 1572256, 1572261, 1572273, 1572274, 1572281, 1576304, 1595534, 1595535, 1595617, 1595618, 1595619, 1595620, 1595697, 1595698, 1595699, 1595700, 1595701, 1595798, 35206751, 35206752, 35206753, 35206754, 35206755, 35206757, 35206852, 35206853, 35206854, 35206855, 35206856, 35206857, 35206858, 35206859, 35206881, 35206882, 35206991, 35206992, 35207021, 35207022, 35207023, 35207024, 35207060, 35207061, 35207062, 35207063, 35207064, 35207065, 35207066, 35207067, 35207092, 35207093, 35207094, 35207095, 35207096, 35207097, 35207098, 35207099, 35207100, 35207150, 35207151, 35207152, 35207153, 35207154, 35207155, 35207169, 35207170, 35207171, 35207172, 35207173, 35207175, 35207176, 35207177, 35207381, 35207409, 35207410, 35207543, 35207566, 35207567, 35207568, 35207668, 35207702, 35207703, 35207704, 35207705, 35207706, 35207922, 35207923, 35207924, 35207928, 35207929, 35207971, 35207972, 35207973, 35208189, 35208190, 35208288, 35208289, 35208290, 35208291, 35208292, 35208293, 35208772, 35208773, 35208774, 35208775, 35208776, 35208810, 35208871, 35208968, 35208969, 35208970, 35208971, 35208974, 35208975, 35209005, 35209006, 35209007, 35209008, 35209009, 35209010, 35209011, 35209013, 35209098, 35209099, 35209324, 35209325, 35209326, 35209327, 35211261, 35211262, 35211263, 35211264, 35211275, 35211276, 35211277, 35211278, 35211279, 35211280, 35211281, 35211282, 35211283, 35211284, 35211285, 35211286, 35211287, 35211288, 35211289, 35211290, 35211299, 35211300, 35211301, 35211302, 35211303, 35211304, 35211305, 35211306, 35211307, 35211308, 35211309, 35211336, 35211337, 35211338, 35211350, 35211388, 35211400, 35211401, 35211402, 35211414, 35211415, 35211416, 35211420, 35211442, 35211443, 35211512, 35211513, 35211514, 35211515, 35211516, 35211517, 35211518, 35211519, 35211520, 35211521, 35211522, 35211523, 35211524, 35211525, 35211527, 35225038, 35225264, 35225374, 35225375, 35225376, 35225378, 35225379, 37200198, 37200199, 37200200, 37200201, 37200202, 37200203, 37200204, 37200205, 37200206, 37200207, 37200208, 37200209, 37200210, 37200211, 37200212, 37200213, 37200214, 37200215, 37200216, 37200217, 37200218, 37200219, 37200220, 37200221, 37200222, 37200223, 37200224, 37200225, 37200227, 37200228, 37200229, 37200230, 37200232, 37200233, 37200234, 37200235, 37200237, 37200238, 37200239, 37200240, 37200242, 37200243, 37200244, 37200245, 37200246, 37200247, 37200248, 37200249, 37200251, 37200252, 37200253, 37200254, 37200312, 37200313, 37200319, 37200320, 37200649, 37200650, 37200651, 37200652, 37200701, 37200702, 37200703, 37200744, 37200877, 37200878, 37201113, 37201116, 37201118, 37201119, 37201120, 37201121, 37202304, 37202305, 44819500, 44819501, 44819502, 44819503, 44819504, 44819524, 44819525, 44819544, 44819554, 44819555, 44819556, 44819777, 44819778, 44819819, 44819946, 44819947, 44819948, 44819964, 44819965, 44819966, 44819967, 44819968, 44819970, 44819973, 44819974, 44819975, 44819978, 44819984, 44819985, 44819986, 44819987, 44820052, 44820053, 44820054, 44820055, 44820056, 44820057, 44820059, 44820060, 44820061, 44820062, 44820063, 44820064, 44820065, 44820066, 44820067, 44820068, 44820069, 44820070, 44820489, 44820682, 44820683, 44820684, 44820685, 44820725, 44820730, 44820731, 44820732, 44820733, 44820889, 44820924, 44820925, 44820926, 44820979, 44820980, 44820981, 44821091, 44821092, 44821101, 44821125, 44821142, 44821143, 44821144, 44821145, 44821146, 44821147, 44821150, 44821151, 44821152, 44821153, 44821154, 44821160, 44821161, 44821166, 44821236, 44821237, 44821238, 44821239, 44821241, 44821242, 44821243, 44821244, 44821245, 44821246, 44821247, 44821248, 44821249, 44821250, 44821251, 44821252, 44821253, 44821254, 44821255, 44821256, 44821557, 44821608, 44821787, 44821824, 44821827, 44821828, 44821949, 44821978, 44821979, 44821987, 44821988, 44822017, 44822018, 44822019, 44822165, 44822166, 44822167, 44822188, 44822189, 44822190, 44822191, 44822208, 44822209, 44822210, 44822211, 44822212, 44822213, 44822216, 44822217, 44822218, 44822219, 44822220, 44822221, 44822227, 44822228, 44822229, 44822235, 44822236, 44822237, 44822289, 44822292, 44822293, 44822294, 44822295, 44822296, 44822297, 44822298, 44822299, 44822300, 44822301, 44822302, 44822303, 44822304, 44822305, 44822306, 44822307, 44822308, 44822309, 44822310, 44822311, 44822312, 44822313, 44822316, 44822668, 44822751, 44822934, 44822935, 44822936, 44822948, 44822953, 44822985, 44822987, 44822988, 44822989, 44823109, 44823144, 44823196, 44823197, 44823333, 44823349, 44823350, 44823360, 44823361, 44823362, 44823367, 44823368, 44823369, 44823370, 44823371, 44823372, 44823373, 44823376, 44823377, 44823378, 44823382, 44823441, 44823442, 44823443, 44823444, 44823445, 44823446, 44823448, 44823449, 44823450, 44823451, 44823452, 44823453, 44823454, 44823455, 44823456, 44823457, 44823458, 44823459, 44823461, 44824071, 44824072, 44824073, 44824074, 44824082, 44824083, 44824092, 44824093, 44824120, 44824121, 44824132, 44824287, 44824288, 44824289, 44824311, 44824312, 44824350, 44824351, 44824352, 44824473, 44824474, 44824475, 44824486, 44824487, 44824510, 44824511, 44824512, 44824513, 44824514, 44824515, 44824519, 44824520, 44824521, 44824522, 44824523, 44824528, 44824536, 44824537, 44824538, 44824540, 44824541, 44824616, 44824617, 44824618, 44824619, 44824620, 44824621, 44824622, 44824623, 44824624, 44824625, 44824626, 44824627, 44824628, 44824629, 44824630, 44824631, 44824632, 44824633, 44824634, 44824635, 44824636, 44825264, 44825280, 44825281, 44825282, 44825298, 44825307, 44825308, 44825499, 44825500, 44825501, 44825551, 44825651, 44825661, 44825677, 44825678, 44825679, 44825680, 44825681, 44825682, 44825696, 44825697, 44825698, 44825699, 44825700, 44825701, 44825702, 44825703, 44825707, 44825708, 44825709, 44825710, 44825711, 44825717, 44825718, 44825719, 44825729, 44825730, 44825731, 44825732, 44825733, 44825734, 44825735, 44825796, 44825801, 44825802, 44825803, 44825804, 44825805, 44825806, 44825807, 44825808, 44825809, 44825810, 44825811, 44825812, 44825813, 44825814, 44825815, 44825816, 44825817, 44825821, 44826155, 44826193, 44826459, 44826460, 44826461, 44826471, 44826503, 44826504, 44826505, 44826506, 44826507, 44826518, 44826519, 44826662, 44826666, 44826678, 44826679, 44826700, 44826701, 44826736, 44826737, 44826848, 44826854, 44826869, 44826870, 44826885, 44826886, 44826887, 44826888, 44826889, 44826890, 44826896, 44826897, 44826902, 44826911, 44826912, 44826913, 44826914, 44826915, 44826969, 44826970, 44826973, 44826974, 44826975, 44826976, 44826977, 44826979, 44826981, 44826983, 44826984, 44827406, 44827615, 44827616, 44827617, 44827629, 44827630, 44827635, 44827661, 44827668, 44827894, 44828003, 44828004, 44828005, 44828019, 44828035, 44828036, 44828037, 44828047, 44828048, 44828049, 44828050, 44828051, 44828052, 44828053, 44828059, 44828060, 44828061, 44828075, 44828076, 44828077, 44828144, 44828145, 44828146, 44828147, 44828148, 44828151, 44828152, 44828153, 44828154, 44828155, 44828156, 44828157, 44828158, 44828159, 44828160, 44828161, 44828162, 44828163, 44828164, 44828165, 44828166, 44828793, 44828794, 44828795, 44828820, 44828833, 44828834, 44828835, 44828841, 44828842, 44829001, 44829012, 44829068, 44829178, 44829179, 44829180, 44829188, 44829195, 44829196, 44829197, 44829213, 44829214, 44829215, 44829216, 44829217, 44829218, 44829219, 44829220, 44829223, 44829225, 44829226, 44829232, 44829233, 44829234, 44829292, 44829293, 44829294, 44829298, 44829299, 44829300, 44829301, 44829302, 44829303, 44829304, 44829305, 44829308, 44829639, 44829878, 44829879, 44829880, 44829881, 44829882, 44829903, 44829926, 44829927, 44829928, 44829936, 44829937, 44829938, 44829939, 44829940, 44829941, 44829942, 44830105, 44830115, 44830137, 44830182, 44830299, 44830310, 44830323, 44830324, 44830325, 44830326, 44830343, 44830345, 44830346, 44830347, 44830348, 44830350, 44830351, 44830352, 44830353, 44830364, 44830365, 44830366, 44830439, 44830440, 44830441, 44830442, 44830443, 44830445, 44830446, 44830447, 44830448, 44830449, 44830450, 44830451, 44830452, 44830453, 44830454, 44830455, 44830457, 44830794, 44830848, 44831045, 44831046, 44831047, 44831059, 44831068, 44831093, 44831094, 44831103, 44831104, 44831105, 44831106, 44831107, 44831108, 44831272, 44831278, 44831279, 44831280, 44831298, 44831299, 44831336, 44831488, 44831489, 44831490, 44831504, 44831505, 44831506, 44831507, 44831508, 44831509, 44831510, 44831512, 44831517, 44831519, 44831524, 44831525, 44831529, 44831583, 44831587, 44831588, 44831589, 44831590, 44831591, 44831592, 44831593, 44831594, 44831595, 44831596, 44831597, 44831598, 44831599, 44831600, 44831601, 44831602, 44831604, 44831605, 44831606, 44832190, 44832191, 44832192, 44832193, 44832194, 44832214, 44832239, 44832240, 44832241, 44832248, 44832249, 44832250, 44832251, 44832423, 44832424, 44832451, 44832602, 44832630, 44832646, 44832647, 44832648, 44832649, 44832650, 44832651, 44832652, 44832653, 44832654, 44832659, 44832663, 44832708, 44832709, 44832710, 44832711, 44832714, 44832715, 44832716, 44832717, 44832718, 44832719, 44832720, 44832722, 44832723, 44833100, 44833101, 44833365, 44833366, 44833367, 44833368, 44833387, 44833394, 44833403, 44833414, 44833415, 44833421, 44833556, 44833611, 44833628, 44833629, 44833630, 44833631, 44833632, 44833670, 44833787, 44833810, 44833811, 44833812, 44833813, 44833831, 44833832, 44833833, 44833834, 44833835, 44833836, 44833837, 44833838, 44833847, 44833848, 44833849, 44833850, 44833851, 44833865, 44833866, 44833912, 44833913, 44833914, 44833917, 44833918, 44833919, 44833920, 44833921, 44833922, 44833923, 44833924, 44833925, 44834342, 44834548, 44834549, 44834563, 44834564, 44834565, 44834569, 44834600, 44834601, 44834602, 44834603, 44834715, 44834764, 44834769, 44834797, 44834841, 44834842, 44834952, 44834953, 44834975, 44834976, 44834977, 44834978, 44834979, 44834980, 44834998, 44834999, 44835000, 44835001, 44835002, 44835003, 44835006, 44835007, 44835008, 44835009, 44835015, 44835022, 44835023, 44835081, 44835082, 44835083, 44835084, 44835085, 44835086, 44835087, 44835088, 44835089, 44835090, 44835093, 44835474, 44835758, 44835769, 44835791, 44835792, 44835974, 44836009, 44836041, 44836042, 44836149, 44836150, 44836159, 44836171, 44836172, 44836173, 44836174, 44836175, 44836189, 44836190, 44836191, 44836192, 44836193, 44836194, 44836195, 44836202, 44836203, 44836204, 44836205, 44836214, 44836215, 44836223, 44836224, 44836225, 44836226, 44836287, 44836288, 44836289, 44836293, 44836294, 44836295, 44836296, 44836297, 44836298, 44836302, 44836303, 44836914, 44836915, 44836916, 44836917, 44836918, 44836929, 44836944, 44836945, 44836970, 44836971, 44836972, 44836973, 44836984, 44836985, 44837129, 44837135, 44837136, 44837309, 44837310, 44837317, 44837335, 44837347, 44837348, 44837349, 44837350, 44837351, 44837352, 44837353, 44837354, 44837358, 44837359, 44837360, 44837361, 44837362, 44837363, 44837369, 44837375, 44837376, 44837423, 44837424, 44837425, 44837430, 44837433, 44837434, 44837435, 44837436, 44837437, 44837438, 44837439, 44837440, 44837441, 44837442, 44837443, 44837444, 44837445, 44837446, 44837449, 44837823, 45533019, 45533020, 45533021, 45533022, 45533023, 45533085, 45533136, 45533137, 45533138, 45533140, 45533147, 45533148, 45533149, 45533277, 45533353, 45533354, 45533439, 45533746, 45533747, 45533748, 45533749, 45533807, 45533808, 45533810, 45533811, 45533812, 45533813, 45533814, 45533815, 45533816, 45533817, 45533818, 45533819, 45533848, 45533849, 45533850, 45533851, 45533852, 45533853, 45533867, 45533868, 45533881, 45533883, 45533884, 45533885, 45533886, 45533887, 45533939, 45533940, 45533941, 45533942, 45534020, 45534021, 45534023, 45534024, 45534025, 45534026, 45534027, 45534130, 45534422, 45534424, 45534427, 45534428, 45534429, 45534430, 45534433, 45534434, 45534435, 45534440, 45534458, 45534479, 45537591, 45537600, 45537698, 45537961, 45537962, 45538046, 45538069, 45538108, 45538109, 45538110, 45538111, 45538112, 45538114, 45538115, 45538121, 45538122, 45538123, 45538143, 45538241, 45538312, 45538313, 45538314, 45538315, 45538373, 45538374, 45538375, 45538377, 45538586, 45538681, 45538682, 45538683, 45538687, 45538688, 45538689, 45538735, 45538737, 45538738, 45538739, 45538740, 45538742, 45538743, 45538744, 45538745, 45538746, 45538747, 45538748, 45538773, 45538774, 45538788, 45538809, 45538814, 45538815, 45538816, 45538817, 45538818, 45538819, 45538866, 45538867, 45538868, 45538944, 45538949, 45538950, 45538951, 45538952, 45539314, 45539371, 45542487, 45542738, 45542780, 45542781, 45542821, 45542887, 45542893, 45542911, 45542912, 45543167, 45543168, 45543269, 45543270, 45543322, 45543324, 45543485, 45543486, 45543487, 45543547, 45543548, 45543549, 45543551, 45543553, 45543554, 45543555, 45543556, 45543557, 45543558, 45543560, 45543561, 45543590, 45543592, 45543593, 45543594, 45543612, 45543613, 45543631, 45543633, 45543634, 45543635, 45543636, 45543689, 45543690, 45543772, 45543773, 45543774, 45543775, 45544130, 45544133, 45544134, 45544169, 45547372, 45547625, 45547626, 45547627, 45547657, 45547704, 45547707, 45547708, 45547732, 45547734, 45547735, 45547743, 45547744, 45547763, 45547840, 45547841, 45547842, 45547843, 45547933, 45547936, 45547937, 45547938, 45548010, 45548011, 45548012, 45548013, 45548116, 45548117, 45548163, 45548321, 45548323, 45548324, 45548325, 45548326, 45548384, 45548385, 45548386, 45548387, 45548388, 45548392, 45548393, 45548394, 45548395, 45548396, 45548397, 45548423, 45548424, 45548443, 45548444, 45548465, 45548466, 45548503, 45548569, 45548570, 45548571, 45548575, 45548576, 45548944, 45548948, 45548951, 45548952, 45548953, 45548954, 45548996, 45552047, 45552385, 45552386, 45552417, 45552453, 45552454, 45552527, 45552528, 45552530, 45552537, 45552538, 45552539, 45552551, 45552638, 45552639, 45552720, 45552721, 45552885, 45552937, 45552938, 45552939, 45552940, 45552941, 45553098, 45553099, 45553148, 45553149, 45553151, 45553152, 45553153, 45553154, 45553155, 45553156, 45553157, 45553158, 45553159, 45553160, 45553161, 45553162, 45553163, 45553189, 45553204, 45553206, 45553224, 45553225, 45553226, 45553227, 45553271, 45553352, 45553353, 45553355, 45553356, 45553357, 45553714, 45553715, 45553716, 45553717, 45553718, 45553719, 45553748, 45556807, 45557112, 45557113, 45557236, 45557237, 45557238, 45557240, 45557376, 45557377, 45557378, 45557379, 45557464, 45557465, 45557538, 45557539, 45557626, 45557661, 45557662, 45557664, 45557807, 45557808, 45557809, 45557850, 45557851, 45557852, 45557853, 45557854, 45557855, 45557856, 45557857, 45557858, 45557859, 45557884, 45557885, 45557886, 45557901, 45557902, 45557903, 45557925, 45557926, 45557927, 45557928, 45557929, 45557992, 45557993, 45557994, 45558062, 45558063, 45558064, 45558066, 45558069, 45558453, 45558454, 45558455, 45558456, 45558459, 45558483, 45558493, 45561616, 45561949, 45561985, 45561986, 45562025, 45562087, 45562088, 45562093, 45562095, 45562096, 45562109, 45562204, 45562206, 45562207, 45562271, 45562272, 45562273, 45562274, 45562343, 45562344, 45562457, 45562650, 45562651, 45562691, 45562692, 45562693, 45562694, 45562696, 45562697, 45562698, 45562699, 45562700, 45562701, 45562732, 45562733, 45562769, 45562771, 45562772, 45562773, 45562774, 45562775, 45562776, 45562777, 45562778, 45562837, 45562838, 45562839, 45562840, 45562926, 45562927, 45562930, 45562933, 45562934, 45562935, 45562936, 45562937, 45563013, 45563288, 45563290, 45563299, 45563315, 45566384, 45566731, 45566810, 45566874, 45566875, 45566876, 45566884, 45566885, 45566886, 45566887, 45566906, 45566907, 45567013, 45567093, 45567094, 45567095, 45567097, 45567167, 45567168, 45567265, 45567266, 45567315, 45567317, 45567469, 45567472, 45567473, 45567474, 45567524, 45567525, 45567526, 45567528, 45567529, 45567530, 45567531, 45567532, 45567533, 45567534, 45567535, 45567564, 45567578, 45567579, 45567580, 45567603, 45567605, 45567608, 45567610, 45567611, 45567659, 45567660, 45567743, 45567746, 45567748, 45567749, 45567750, 45567751, 45567752, 45567753, 45567754, 45567842, 45568112, 45568114, 45568115, 45568118, 45568146, 45568157, 45571289, 45571314, 45571329, 45571741, 45571742, 45571743, 45571802, 45571803, 45571804, 45571805, 45571810, 45571811, 45571812, 45572168, 45572169, 45572170, 45572171, 45572217, 45572219, 45572374, 45572375, 45572416, 45572417, 45572418, 45572419, 45572420, 45572421, 45572422, 45572423, 45572424, 45572425, 45572426, 45572427, 45572428, 45572429, 45572430, 45572431, 45572432, 45572433, 45572434, 45572435, 45572436, 45572437, 45572438, 45572439, 45572458, 45572459, 45572460, 45572461, 45572471, 45572492, 45572494, 45572495, 45572496, 45572497, 45572498, 45572552, 45572627, 45572630, 45572635, 45572636, 45572637, 45572638, 45572639, 45573007, 45573009, 45573010, 45573011, 45573012, 45573016, 45573032, 45573037, 45576443, 45576480, 45576521, 45576541, 45576545, 45576546, 45576547, 45576590, 45576591, 45576592, 45576593, 45576700, 45576787, 45576788, 45576866, 45576868, 45576951, 45576952, 45576994, 45577165, 45577168, 45577217, 45577219, 45577221, 45577222, 45577223, 45577224, 45577225, 45577226, 45577227, 45577228, 45577229, 45577230, 45577231, 45577232, 45577233, 45577234, 45577235, 45577268, 45577269, 45577306, 45577307, 45577310, 45577313, 45577314, 45577315, 45577358, 45577359, 45577435, 45577437, 45577776, 45577778, 45577781, 45577782, 45577783, 45577786, 45577787, 45577807, 45577808, 45577809, 45577823, 45577828, 45577829, 45581352, 45581353, 45581354, 45581355, 45581435, 45581461, 45581491, 45581492, 45581497, 45581498, 45581499, 45581500, 45581519, 45581626, 45581627, 45581702, 45581703, 45581766, 45581853, 45581860, 45581904, 45582061, 45582062, 45582063, 45582064, 45582108, 45582109, 45582110, 45582111, 45582112, 45582113, 45582114, 45582115, 45582116, 45582117, 45582118, 45582120, 45582121, 45582122, 45582156, 45582157, 45582174, 45582175, 45582176, 45582197, 45582201, 45582202, 45582247, 45582248, 45582249, 45582250, 45582251, 45582316, 45582318, 45582319, 45582694, 45582695, 45582701, 45582718, 45582732, 45582734, 45582735, 45585781, 45585793, 45585857, 45586119, 45586139, 45586140, 45586173, 45586174, 45586219, 45586220, 45586243, 45586289, 45586290, 45586291, 45586292, 45586297, 45586298, 45586299, 45586421, 45586506, 45586572, 45586573, 45586574, 45586575, 45586674, 45586675, 45586725, 45586726, 45586891, 45586892, 45586893, 45586894, 45586936, 45586937, 45586938, 45586939, 45586940, 45586942, 45586943, 45586944, 45586945, 45586946, 45586947, 45586948, 45586975, 45586993, 45587008, 45587013, 45587014, 45587015, 45587016, 45587018, 45587064, 45587065, 45587066, 45587067, 45587068, 45587069, 45587157, 45587160, 45587161, 45587162, 45587163, 45587496, 45587497, 45587523, 45587538, 45590768, 45591027, 45591029, 45591030, 45591031, 45591051, 45591115, 45591116, 45591178, 45591181, 45591185, 45591186, 45591201, 45591297, 45591298, 45591299, 45591300, 45591388, 45591456, 45591458, 45591459, 45591460, 45591461, 45591555, 45591558, 45591559, 45591596, 45591597, 45591598, 45591599, 45591743, 45591744, 45591745, 45591746, 45591747, 45591800, 45591802, 45591804, 45591805, 45591806, 45591807, 45591808, 45591809, 45591810, 45591811, 45591812, 45591846, 45591847, 45591848, 45591851, 45591852, 45591853, 45591885, 45591888, 45591889, 45591890, 45591934, 45591935, 45591936, 45592028, 45592030, 45592034, 45592133, 45592134, 45592135, 45592407, 45592429, 45592434, 45592442, 45592444, 45595569, 45595797, 45595798, 45595799, 45595884, 45595885, 45595940, 45595942, 45595947, 45596049, 45596129, 45596130, 45596131, 45596197, 45596198, 45596199, 45596335, 45596388, 45596495, 45596497, 45596498, 45596546, 45596548, 45596549, 45596550, 45596551, 45596552, 45596553, 45596554, 45596592, 45596593, 45596594, 45596595, 45596630, 45596752, 45596757, 45596762, 45596763, 45596764, 45596766, 45596767, 45596768, 45596769, 45596770, 45596771, 45596864, 45597165, 45597167, 45597168, 45597169, 45597170, 45597171, 45597192, 45597197, 45597199, 45597211, 45597212, 45600374, 45600375, 45600609, 45600641, 45600642, 45600659, 45600719, 45600720, 45600746, 45600747, 45600785, 45600786, 45600793, 45600888, 45600889, 45600958, 45601024, 45601026, 45601027, 45601028, 45601125, 45601133, 45601134, 45601182, 45601354, 45601356, 45601416, 45601418, 45601419, 45601421, 45601422, 45601423, 45601424, 45601425, 45601479, 45601480, 45601495, 45601496, 45601497, 45601498, 45601499, 45601545, 45601546, 45601547, 45601623, 45601625, 45601626, 45601627, 45601629, 45601630, 45601631, 45601633, 45601634, 45601635, 45601727, 45602002, 45602003, 45602004, 45602005, 45602006, 45602007, 45602008, 45602011, 45602032, 45602041, 45605095, 45605401, 45605402, 45605403, 45605404, 45605405, 45605476, 45605543, 45605545, 45605547, 45605556, 45605558, 45605559, 45605560, 45605643, 45605645, 45605784, 45605785, 45605786, 45605787, 45605788, 45605943, 45605944, 45605946, 45606131, 45606132, 45606133, 45606191, 45606192, 45606193, 45606194, 45606195, 45606196, 45606197, 45606198, 45606199, 45606200, 45606201, 45606202, 45606203, 45606204, 45606205, 45606206, 45606227, 45606229, 45606270, 45606272, 45606273, 45606274, 45606276, 45606323, 45606324, 45606411, 45606412, 45606413, 45606414, 45606793, 45606794, 45606795, 45606796, 45606797, 45606799, 45606832, 45606833, 45609901, 713855, 725363, 725364, 725365, 725366, 725378, 725379, 725380, 725388, 725389, 725390, 725458, 725459, 766349, 766412, 766413, 766414, 766424, 766425, 766426, 766427, 766428, 766429, 766430, 766431, 766437\n",
    "                                            ) \n",
    "                                            AND full_text LIKE '%_rank1]%'\n",
    "                                    ) a \n",
    "                                        ON (\n",
    "                                            c.path LIKE CONCAT('%.',\n",
    "                                        a.id,\n",
    "                                        '.%') \n",
    "                                        OR c.path LIKE CONCAT('%.',\n",
    "                                        a.id) \n",
    "                                        OR c.path LIKE CONCAT(a.id,\n",
    "                                        '.%') \n",
    "                                        OR c.path = a.id) \n",
    "                                    WHERE\n",
    "                                        is_standard = 0 \n",
    "                                        AND is_selectable = 1\n",
    "                                    )\n",
    "                            )\n",
    "                        ) c_occurrence \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_standard_concept \n",
    "                            ON c_occurrence.condition_concept_id = c_standard_concept.concept_id \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_type \n",
    "                            ON c_occurrence.condition_type_concept_id = c_type.concept_id \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".visit_occurrence` v \n",
    "                            ON c_occurrence.visit_occurrence_id = v.visit_occurrence_id \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` visit \n",
    "                            ON v.visit_concept_id = visit.concept_id \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_source_concept \n",
    "                            ON c_occurrence.condition_source_concept_id = c_source_concept.concept_id \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_status \n",
    "                            ON c_occurrence.condition_status_concept_id = c_status.concept_id\"\"\"\n",
    "\n",
    "    person_information_all = pd.read_gbq(\n",
    "        dataset_25030714_condition_sql,\n",
    "        dialect=\"standard\",\n",
    "        use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "        progress_bar_type=\"tqdm_notebook\")\n",
    "    \n",
    "    # Keep only the information we want\n",
    "    person_information = person_information_all[['person_id', 'standard_concept_name', 'condition_start_datetime',\n",
    "                                               'condition_end_datetime', 'source_concept_name', 'source_concept_code',\n",
    "                                               'source_vocabulary']]\n",
    "\n",
    "    # Filter for ICD10CM and ICD9CM source vocabularies\n",
    "    person_information_all = person_information_all[person_information_all['source_vocabulary'].isin(['ICD10CM', 'ICD9CM'])]\n",
    "\n",
    "    # Prepare message\n",
    "    message = \"Read the personal information about the patient and kept only data with ICD-10 and ICD-9.\"\n",
    "\n",
    "    return person_information_all, message\n",
    "def read_person_information_df():\n",
    "    \"\"\"\n",
    "    Reads person information from BigQuery and filters it to keep only data with 'Male' and 'Female' sexes.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing filtered person information.\n",
    "    str: Message indicating the action taken.\n",
    "    \"\"\"\n",
    "    # This query represents dataset \"All participants\" for domain \"person\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "    dataset_25030714_person_sql = \"\"\"\n",
    "        SELECT\n",
    "            person.person_id,\n",
    "            person.gender_concept_id,\n",
    "            p_gender_concept.concept_name as gender,\n",
    "            person.birth_datetime as date_of_birth,\n",
    "            person.race_concept_id,\n",
    "            p_race_concept.concept_name as race,\n",
    "            person.ethnicity_concept_id,\n",
    "            p_ethnicity_concept.concept_name as ethnicity,\n",
    "            person.sex_at_birth_concept_id,\n",
    "            p_sex_at_birth_concept.concept_name as sex_at_birth\n",
    "        FROM\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".person` person\n",
    "        LEFT JOIN\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_gender_concept \n",
    "                ON person.gender_concept_id = p_gender_concept.concept_id \n",
    "        LEFT JOIN\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_race_concept \n",
    "                ON person.race_concept_id = p_race_concept.concept_id \n",
    "        LEFT JOIN\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_ethnicity_concept \n",
    "                ON person.ethnicity_concept_id = p_ethnicity_concept.concept_id \n",
    "        LEFT JOIN\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_sex_at_birth_concept \n",
    "                ON person.sex_at_birth_concept_id = p_sex_at_birth_concept.concept_id\"\"\"\n",
    "\n",
    "    person_df = pd.read_gbq(\n",
    "        dataset_25030714_person_sql,\n",
    "        dialect=\"standard\",\n",
    "        use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "        progress_bar_type=\"tqdm_notebook\")\n",
    "    \n",
    "    # Keep only the information we want\n",
    "    person_df_all = person_df[['person_id', 'date_of_birth', 'race', 'ethnicity', 'sex_at_birth']]\n",
    "\n",
    "    # Filter for 'Male' and 'Female' sexes\n",
    "    person_df_all = person_df_all[person_df_all['sex_at_birth'].isin(['Male', 'Female'])]\n",
    "\n",
    "    # Prepare message\n",
    "    message = \"Read the personal information about the patient and kept only data with 'Male' and 'Female' sexes.\"\n",
    "\n",
    "    return person_df_all, message\n",
    "def copy_files_to_local(bucket):\n",
    "    \"\"\"\n",
    "    Copies files from Google Cloud Storage to the local directory './data' if they don't already exist.\n",
    "\n",
    "    Args:\n",
    "    bucket (str): The Google Cloud Storage bucket where the files are located.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Check if the folders exist at the specified path './'\n",
    "    folders = ['data', 'new_run', 'download']\n",
    "    for folder in folders:\n",
    "        folder_path = os.path.join('.', folder)\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "            print(f\"Created folder: {folder}\")\n",
    "\n",
    "    # Define the paths for the files\n",
    "    files = {\n",
    "        'ancestry_preds.tsv': 'gs://fc-aou-datasets-controlled/v7/wgs/short_read/snpindel/aux/ancestry/ancestry_preds.tsv',\n",
    "        'relatedness.tsv': 'gs://fc-aou-datasets-controlled/v7/wgs/short_read/snpindel/aux/relatedness/relatedness.tsv',\n",
    "        'relatedness_flagged_samples.tsv': 'gs://fc-aou-datasets-controlled/v7/wgs/short_read/snpindel/aux/relatedness/relatedness_flagged_samples.tsv'\n",
    "    }\n",
    "\n",
    "    # Copy files using gsutil\n",
    "    for file_name, file_path in files.items():\n",
    "        local_file_path = os.path.join('.', 'data', file_name)\n",
    "        if not os.path.exists(local_file_path):\n",
    "            gsutil_command = f\"gsutil -u $GOOGLE_PROJECT cp {file_path} {bucket}/data/\"\n",
    "            print(f\"Copying file {file_name} to {bucket}/data/ ...\")\n",
    "            !{gsutil_command}\n",
    "            if os.path.exists(local_file_path):\n",
    "                print(f\"File {file_name} copied successfully.\")\n",
    "            else:\n",
    "                print(f\"Failed to copy file {file_name} you have the file there already.\")\n",
    "def read_zip_code_socioeconomic_data():\n",
    "    \"\"\"\n",
    "    Reads zip code socioeconomic data from BigQuery.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing zip code socioeconomic data.\n",
    "    str: Message indicating the action taken.\n",
    "    \"\"\"\n",
    "    # This query represents dataset \"test2\" for domain \"zip_code_socioeconomic\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "    dataset_65271084_zip_code_socioeconomic_sql = \"\"\"\n",
    "        SELECT\n",
    "            observation.person_id,\n",
    "            observation.observation_datetime,\n",
    "            zip_code.zip3_as_string as zip_code,\n",
    "            zip_code.fraction_assisted_income as assisted_income,\n",
    "            zip_code.fraction_high_school_edu as high_school_education,\n",
    "            zip_code.median_income,\n",
    "            zip_code.fraction_no_health_ins as no_health_insurance,\n",
    "            zip_code.fraction_poverty as poverty,\n",
    "            zip_code.fraction_vacant_housing as vacant_housing,\n",
    "            zip_code.deprivation_index,\n",
    "            zip_code.acs as american_community_survey_year \n",
    "        FROM\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".zip3_ses_map` zip_code \n",
    "        JOIN\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".observation` observation \n",
    "                ON CAST(SUBSTR(observation.value_as_string,\n",
    "            0,\n",
    "            STRPOS(observation.value_as_string,\n",
    "            '*') - 1) AS INT64) = zip_code.zip3 \n",
    "            AND observation_source_concept_id = 1585250 \n",
    "            AND observation.value_as_string NOT LIKE 'Res%'\"\"\"\n",
    "\n",
    "    zip_code_socioeconomic_df = pd.read_gbq(\n",
    "        dataset_65271084_zip_code_socioeconomic_sql,\n",
    "        dialect=\"standard\",\n",
    "        use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "        progress_bar_type=\"tqdm_notebook\")\n",
    "    \n",
    "    message = \"Read zip code socioeconomic data successfully.\"\n",
    "\n",
    "    return zip_code_socioeconomic_df, message\n",
    "def run_analysis():\n",
    "    \"\"\"\n",
    "    Runs the analysis, resets the Person_df and Person_information, and returns the necessary dataframes along with messages.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing Person_df after resetting.\n",
    "    pd.DataFrame: DataFrame containing Person_information after resetting.\n",
    "    pd.Series: Series containing counts of individuals in each race.\n",
    "    pd.Series: Series containing counts of Hispanic individuals in each race.\n",
    "    pd.DataFrame: DataFrame containing Population data.\n",
    "    str: Message indicating the action taken.\n",
    "    \"\"\"\n",
    "\n",
    "    # reset Person_df and Person_information\n",
    "    person_df = person_df_all.copy()\n",
    "    person_information = person_information_all.copy()\n",
    "\n",
    "    # Count the number of individuals in each race\n",
    "    race_counts = person_df['race'].value_counts()\n",
    "    race_counts = race_counts.apply(lambda x: '<20' if x < 20 else x)\n",
    "    race_counts_message = \"Number of individuals in each race:\\n\" + str(race_counts)\n",
    "\n",
    "    # Count the number of Hispanic individuals in each race\n",
    "    hispanic_counts = person_df[person_df['ethnicity'] == 'Hispanic or Latino']['race'].value_counts()\n",
    "    hispanic_counts = hispanic_counts.apply(lambda x: '<20' if x < 20 else x)\n",
    "    hispanic_counts_message = \"Number of Hispanic individuals in each race:\\n\" + str(hispanic_counts)\n",
    "\n",
    "    # Prepare Population data\n",
    "    population = read_tsv('ancestry_preds.tsv')\n",
    "    population_message = \"\\nPopulation data loaded successfully.\"\n",
    "\n",
    "    # Convert string representation of lists to actual lists\n",
    "    population['pca_features'] = population['pca_features'].apply(ast.literal_eval)\n",
    "    population['probabilities'] = population['probabilities'].apply(ast.literal_eval)\n",
    "\n",
    "    # Extracting PCA features into separate columns\n",
    "    pca_columns = [f'principal_component_{i}' for i in range(1, 17)]\n",
    "    population[pca_columns] = pd.DataFrame(population['pca_features'].tolist(), index=population.index)\n",
    "\n",
    "    # Extracting probabilities into separate columns\n",
    "    probability_columns = [f'probability_{i}' for i in range(1, 7)]\n",
    "    population[probability_columns] = pd.DataFrame(population['probabilities'].tolist(), index=population.index)\n",
    "\n",
    "    # Create a new column 'max_probability' with the maximum probability across columns\n",
    "    population['max_probability'] = population[probability_columns].max(axis=1)\n",
    "\n",
    "    max_probability_message = \"Maximum probability calculated successfully.\"\n",
    "\n",
    "    return person_df, person_information, race_counts, hispanic_counts, population, race_counts_message, hispanic_counts_message, population_message, max_probability_message\n",
    "def plot_pca_graphs(population):\n",
    "    \"\"\"\n",
    "    Generates PCA scatterplots and a line chart based on ancestry prediction and saves them as images.\n",
    "\n",
    "    Args:\n",
    "    population (pd.DataFrame): DataFrame containing population data.\n",
    "\n",
    "    Returns:\n",
    "    str: Message indicating the action taken.\n",
    "    \"\"\"\n",
    "\n",
    "    # Scatterplot for 'ancestry_pred_other'\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    colors = {'eur': 'darkblue', 'afr': 'darkred', 'amr': 'darkgreen', 'oth': 'gold', 'eas': 'purple', 'sas': 'darkorange', 'mid': 'black'}\n",
    "\n",
    "    for ancestry, color in colors.items():\n",
    "        subset = population[population['ancestry_pred_other'].eq(ancestry)]\n",
    "        plt.scatter(subset['principal_component_1'], subset['principal_component_2'], label=ancestry, color=color, alpha=0.7, s=3)\n",
    "\n",
    "    plt.title('PCA Scatterplot - Ancestry_pred_other')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.legend()\n",
    "    plt.savefig('./download/PCA_Scatterplot_Ancestry_pred_other.pdf',dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Scatterplot for 'ancestry_pred'\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    colors = {'eur': 'darkblue', 'afr': 'darkred', 'amr': 'darkgreen', 'eas': 'purple', 'sas': 'darkorange', 'mid': 'black'}\n",
    "\n",
    "    for ancestry, color in colors.items():\n",
    "        subset = population[population['ancestry_pred'].eq(ancestry)]\n",
    "        plt.scatter(subset['principal_component_1'], subset['principal_component_2'], label=ancestry, color=color, alpha=0.5, s=3)\n",
    "\n",
    "    plt.title('PCA Scatterplot - Ancestry_pred')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.legend()\n",
    "    plt.savefig('./download/PCA_Scatterplot_Ancestry_pred.pdf',dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Line Chart\n",
    "    principal_components = ['principal_component_{}'.format(i) for i in range(1, 17)]\n",
    "    colors = {'oth':'gold','eur': 'darkblue', 'afr': 'darkred', 'amr': 'darkgreen', 'eas': 'purple', 'sas': 'darkorange', 'mid': 'black'}\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for ancestry, color in colors.items():\n",
    "        mean_values = population.loc[population['ancestry_pred_other'] == ancestry, principal_components].median()\n",
    "        plt.plot(principal_components, mean_values, label=ancestry, color=color, marker='o',alpha=0.5)\n",
    "\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.xticks(ticks=range(0, 16), labels=['PCA{}'.format(i) for i in range(1, 17)])\n",
    "    plt.title('Line Chart - Principal Components by Ancestry Prediction')\n",
    "    plt.xlabel('Principal Components')\n",
    "    plt.ylabel('Median Values')\n",
    "    plt.legend()\n",
    "    plt.savefig('./download/Line_Chart_Principal_Components_by_Ancestry_Prediction.pdf',dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    return \"PCA graphs saved successfully.\"\n",
    "def perform_pca(population_data):\n",
    "    \"\"\"\n",
    "    Performs PCA (Principal Component Analysis) on the population data and creates scatterplots and a line chart.\n",
    "\n",
    "    Args:\n",
    "    population_data (pd.DataFrame): DataFrame containing population data.\n",
    "\n",
    "    Returns:\n",
    "    PCA: PCA object containing the transformed data.\n",
    "    str: Message indicating the action taken.\n",
    "    \"\"\"\n",
    "    # Selecting features for PCA\n",
    "    pca_features = population_data.iloc[:, 8:24]\n",
    "\n",
    "    # Initialize PCA\n",
    "    pca = PCA(n_components=2)\n",
    "\n",
    "    # Fit and transform the data\n",
    "    pca_data = pca.fit_transform(pca_features)\n",
    "\n",
    "    # Create scatterplot for 'ancestry_pred_other'\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    colors = {'eur': 'darkblue', 'afr': 'darkred', 'amr': 'darkgreen', 'oth': 'gold', 'eas': 'purple', 'sas': 'darkorange', 'mid': 'black'}\n",
    "\n",
    "    for ancestry, color in colors.items():\n",
    "        subset = population_data[population_data['ancestry_pred_other'].eq(ancestry)]\n",
    "        plt.scatter(pca_data[subset.index, 0], pca_data[subset.index, 1], label=ancestry, color=color, alpha=0.7, s=3)\n",
    "\n",
    "    plt.title('PCA Scatterplot - Ancestry_pred_other')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.legend()\n",
    "    plt.savefig('./download/PCA_Scatterplot_Ancestry_pred_other_1.pdf',dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    # Create scatterplot for 'ancestry_pred'\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    colors = {'eur': 'darkblue', 'afr': 'darkred', 'amr': 'darkgreen', 'eas': 'purple', 'sas': 'darkorange', 'mid': 'black'}\n",
    "\n",
    "    for ancestry, color in colors.items():\n",
    "        subset = population_data[population_data['ancestry_pred'].eq(ancestry)]\n",
    "        plt.scatter(pca_data[subset.index, 0], pca_data[subset.index, 1], label=ancestry, color=color, alpha=0.7, s=3)\n",
    "\n",
    "    plt.title('PCA Scatterplot - Ancestry_pred')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.legend()\n",
    "    plt.savefig('./download/PCA_Scatterplot_Ancestry_pred_1.pdf',dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    # Create line chart\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # List of principal components\n",
    "    principal_components = ['principal_component_{}'.format(i) for i in range(1, 17)]\n",
    "\n",
    "    # Set the color palette for each ancestry prediction\n",
    "    colors = {'oth':'gold','eur': 'darkblue', 'afr': 'darkred', 'amr': 'darkgreen', 'eas': 'purple', 'sas': 'darkorange', 'mid': 'black'}\n",
    "\n",
    "    # Loop through each ancestry prediction and plot a line for each\n",
    "    for ancestry, color in colors.items():\n",
    "        # Calculate the mean of each principal component for the current ancestry\n",
    "        mean_values = population_data.loc[population_data['ancestry_pred_other'] == ancestry, principal_components].median()\n",
    "        plt.plot(principal_components, mean_values, label=ancestry, color=color, marker='o')\n",
    "\n",
    "    # Rotate x-axis labels\n",
    "    plt.xticks(rotation=90)\n",
    "\n",
    "    # Rename x-axis labels\n",
    "    plt.xticks(ticks=range(0, 16), labels=['PCA{}'.format(i) for i in range(1, 17)])\n",
    "\n",
    "    plt.title('Line Chart - Principal Components by Ancestry Prediction')\n",
    "    plt.xlabel('Principal Components')\n",
    "    plt.ylabel('Median Values')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return pca, \"PCA performed successfully. Scatterplots and line chart created.\"\n",
    "def prepare_genotyping_data(pop_variable, population, person_df, person_information):\n",
    "    \"\"\"\n",
    "    Prepares data for genotyping analysis based on the specified population variable.\n",
    "\n",
    "    Args:\n",
    "    pop_variable (str): The population variable to filter the data.\n",
    "    population (pd.DataFrame): DataFrame containing population data.\n",
    "    person_df (pd.DataFrame): DataFrame containing person data.\n",
    "    person_information (pd.DataFrame): DataFrame containing person information data.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing filtered population data.\n",
    "    pd.DataFrame: DataFrame containing filtered person data.\n",
    "    pd.DataFrame: DataFrame containing filtered person information data.\n",
    "    str: Message indicating the action taken.\n",
    "    \"\"\"\n",
    "    if pop_variable == 'all':\n",
    "        message = \"Using all Ancestries for genotyping analysis.\"\n",
    "    else:\n",
    "        population = population[population['ancestry_pred'] == pop_variable]\n",
    "        message = f\"Using {pop_variable} population ancestry for genotyping analysis.\"\n",
    "\n",
    "    population.rename(columns={'research_id': 'person_id'}, inplace=True)\n",
    "    ids = population['person_id'].astype(str).tolist()\n",
    "\n",
    "    person_df['person_id'] = person_df['person_id'].astype(str)\n",
    "    person_df = person_df[person_df['person_id'].isin(ids)].reset_index(drop=True)\n",
    "\n",
    "    person_information['person_id'] = person_information['person_id'].astype(str)\n",
    "    person_information = person_information[person_information['person_id'].isin(ids)].reset_index(drop=True)\n",
    "\n",
    "    return population, person_df, person_information, message\n",
    "def remove_related_samples(person_df):\n",
    "    \"\"\"\n",
    "    Removes samples that are flagged as related from the person DataFrame.\n",
    "\n",
    "    Args:\n",
    "    person_df (pd.DataFrame): DataFrame containing person data.\n",
    "    relatedness_flaged_samples (pd.DataFrame): DataFrame containing relatedness flagged samples.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing person data with related samples removed.\n",
    "    str: Message indicating the action taken.\n",
    "    \"\"\"\n",
    "    relatedness = read_tsv('relatedness.tsv')\n",
    "    relatedness_flaged_samples = read_tsv('relatedness_flagged_samples.tsv')\n",
    "    ids = relatedness_flaged_samples['sample_id'].astype(str).tolist()\n",
    "    person_df = person_df[~person_df['person_id'].isin(ids)].reset_index(drop=True)\n",
    "    message = f\"{len(ids)} samples are flagged as related and removed from the person DataFrame.\"\n",
    "    return person_df, message\n",
    "def transform_genotypes(df, alleles_row, reference_allele=None, alternative_allele=None):\n",
    "    # Step 1: Initialize the message\n",
    "    message = \"\"\n",
    "\n",
    "    # Step 2: Remove rows with missing genotype information\n",
    "    df = df.dropna(subset=['GT'])\n",
    "\n",
    "    # Step 4: Convert 'GT' column to string type\n",
    "    df['GT'] = df['GT'].astype(str)\n",
    "\n",
    "    # Step 4: Split 'GT' column into separate alleles\n",
    "    df[['Allele_1', 'Allele_2']] = df['GT'].str.split('/', expand=True)\n",
    "\n",
    "    # Step 6: Set the reference allele\n",
    "    if reference_allele is None:\n",
    "        if len(alleles_row) == 2:\n",
    "            reference_allele = alleles_row[0]\n",
    "            alternative_allele = alleles_row[1]\n",
    "        else:\n",
    "            reference_allele = alleles_row[0]\n",
    "\n",
    "    # Step 8: Map allele values to letters\n",
    "    allele_mapping = {str(i): allele for i, allele in enumerate(alleles_row)}\n",
    "    df['Allele_1_map'] = df['Allele_1'].map(allele_mapping)\n",
    "    df['Allele_2_map'] = df['Allele_2'].map(allele_mapping)\n",
    "\n",
    "    # Step 9: Create 'Allele_combination' column and count occurrences\n",
    "    df['Allele_combination'] = df['Allele_1_map'] + '/' + df['Allele_2_map']\n",
    "    allele_counts = df['Allele_combination'].value_counts().reset_index()\n",
    "    allele_counts.columns = ['Allele_combination', 'Allele_count']\n",
    "\n",
    "    # Step 10: Determine alternative allele\n",
    "    if len(alleles_row) != 2:\n",
    "        alternative_combination = \"\"\n",
    "        if alternative_allele is None:\n",
    "            # Step 11: Find all combinations except reference/reference\n",
    "            alternative_combinations = allele_counts[~allele_counts['Allele_combination'].str.contains(reference_allele)]\n",
    "            if not alternative_combinations.empty:\n",
    "                # Step 13: Find the most frequent combination with reference allele\n",
    "                max_combination = alternative_combinations.loc[alternative_combinations['Allele_count'].idxmax()]\n",
    "                alternative_combination = max_combination['Allele_combination']\n",
    "                # Step 14: Set alternative allele as the non-reference allele in the most frequent combination\n",
    "                alternative_allele = alternative_combination.replace(reference_allele, '')\n",
    "    else:\n",
    "        # If alleles_row has length 2, set the second allele as the alternative allele\n",
    "        alternative_allele = alleles_row[1]\n",
    "\n",
    "    # At this point, we have the reference and alternative alleles\n",
    "    # Step 12 Remove reference allele from alternative_combination\n",
    "    if len(alleles_row) != 2:\n",
    "        if alternative_combination:\n",
    "            alternative_allele = alternative_combination.replace(reference_allele, '')\n",
    "\n",
    "    # Step 13 Create 'GT' column\n",
    "    df['GT'] = -1  # Initialize all to -1\n",
    "\n",
    "    # handle combination alternative allele\n",
    "    if alternative_allele is None:\n",
    "        alternative_combination = \"\"\n",
    "        alternative_combinations = allele_counts[~allele_counts['Allele_combination'].str.contains(reference_allele)]\n",
    "        if not alternative_combinations.empty:\n",
    "            max_combination = alternative_combinations.loc[alternative_combinations['Allele_count'].idxmax()]\n",
    "            alternative_combination = max_combination['Allele_combination']\n",
    "            alternative_allele = alternative_combination.replace(reference_allele, '')\n",
    "\n",
    "    # Step 14 Split the alternative allele if it's a combination\n",
    "    if alternative_allele and '/' in alternative_allele:\n",
    "        alternative_alleles = alternative_allele.split('/')\n",
    "    else:\n",
    "        alternative_alleles = [alternative_allele] if alternative_allele else []\n",
    "\n",
    "    # Step 15 Assign genotype values based on reference and alternative alleles\n",
    "    df.loc[(df['Allele_1_map'] == reference_allele) & (df['Allele_2_map'] == reference_allele), 'GT'] = 0\n",
    "    if alternative_alleles:\n",
    "        df.loc[(df['Allele_1_map'] == reference_allele) & (df['Allele_2_map'] == alternative_alleles[0]), 'GT'] = 1\n",
    "        df.loc[(df['Allele_1_map'] == alternative_alleles[0]) & (df['Allele_2_map'] == reference_allele), 'GT'] = 1\n",
    "\n",
    "    # Check if genotype 1 is present but genotype 2 is not\n",
    "    if 1 in df['GT'].values and 2 not in df['GT'].values:\n",
    "        # Set genotype 1 where Allele_1_map is the first allele in alternative_alleles\n",
    "        df.loc[(df['Allele_1_map'] == alternative_alleles[0]) & (df['Allele_2_map'] == alternative_alleles[0]), 'GT'] = 1\n",
    "\n",
    "    # Step 16 Check if alternative_alleles contains two or more elements\n",
    "    if len(alternative_alleles) >=1:\n",
    "        df.loc[(df['Allele_1_map'] == alternative_alleles[0]) & (df['Allele_2_map'] == alternative_alleles[0]), 'GT'] = 2\n",
    "\n",
    "    # Step 17 Remove rows with GT == -1 and keep only the reference and alternative alleles\n",
    "    df = df[df['GT'] != -1]\n",
    "    \n",
    "    # Filter allele combinations with counts less than 20\n",
    "    filtered_allele_counts = allele_counts[allele_counts['Allele_count'] >= 20]\n",
    "\n",
    "    \n",
    "    # Step 18: Generate message\n",
    "    message += \"Alleles for SNP: {}\\n\".format(alleles_row)\n",
    "    message += \"Reference allele: {}\\n\".format(reference_allele)\n",
    "    message += \"Alternative allele: {}\\n\".format(alternative_allele)\n",
    "    message += \"Allele combinations count:\\n{}\\n\".format(allele_counts)\n",
    "    message += \"Removed {} rows with missing genotype information.\\n\".format(len(df[df['GT'].isna()]))\n",
    "\n",
    "    return df, message\n",
    "def create_pie_chart(genotype_counts, rs_name, pop_variable):\n",
    "    \"\"\"\n",
    "    Create a pie chart based on genotype counts.\n",
    "\n",
    "    Args:\n",
    "    genotype_counts (pd.Series): Series containing genotype counts.\n",
    "    rs_name (str): Name of the SNP.\n",
    "    pop_variable (str): Name of the population variable.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Replace values less than 20 with a placeholder\n",
    "    genotype_counts = genotype_counts.apply(lambda x: x if x >= 20 else '<20')\n",
    "    if 1 not in genotype_counts.index:\n",
    "        # If '2' is not present, set its count to 0\n",
    "        genotype_counts[1] = 0\n",
    "    # Check if genotype '2' is present in the counts\n",
    "    if 2 not in genotype_counts.index:\n",
    "        # If '2' is not present, set its count to 0\n",
    "        genotype_counts[2] = 0\n",
    "    \n",
    "\n",
    "    # Plot the pie chart\n",
    "    pie_chart = genotype_counts.plot(kind='pie', title='{}'.format(rs_name), legend=True)\n",
    "    \n",
    "    \n",
    "    # Add the genotype counts to the title\n",
    "    title_with_counts = '{}  with {} population(0: {}, 1: {}, 2: {})'.format(rs_name,pop_variable, \n",
    "                                                         genotype_counts.get(0, 0),\n",
    "                                                         genotype_counts.get(1, 0),\n",
    "                                                         genotype_counts.get(2, 0))\n",
    "    pie_chart.set_title(title_with_counts)\n",
    "\n",
    "    # Save the figure\n",
    "    plt.savefig('./download/{}_{}_pie_GT_my_data_before_remove_data.pdf'.format(rs_name, pop_variable), dpi=300, facecolor='w',bbox_inches='tight')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "def filter_by_ethnicity(person_df, ethnicity=None):\n",
    "    \"\"\"\n",
    "    Filters the person DataFrame based on ethnicity.\n",
    "\n",
    "    Args:\n",
    "    person_df (pd.DataFrame): DataFrame containing person data.\n",
    "    ethnicity (str or None): The ethnicity to filter by. If None, no filtering is applied.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing filtered person data.\n",
    "    str: Message indicating the action taken.\n",
    "    \"\"\"\n",
    "    if ethnicity is None:\n",
    "        message = \"No specific ethnicity selected. Performing a classic run.\"\n",
    "        return person_df, message\n",
    "\n",
    "    if ethnicity.lower() == 'hispanic':\n",
    "        filtered_df = person_df[person_df['ethnicity'] == 'Hispanic or Latino']\n",
    "        message = \"Filtering by Hispanic ethnicity.\"\n",
    "    elif ethnicity.lower() == 'not_hispanic':\n",
    "        person_df = person_df[person_df['ethnicity'] == 'Not Hispanic or Latino']\n",
    "        message = \"Filtering by Non-Hispanic ethnicity.\"\n",
    "    else:\n",
    "        message = f\"Invalid ethnicity option: {ethnicity}. Performing a classic run.\"\n",
    "        return person_df, message\n",
    "\n",
    "    return person_df, message\n",
    "def perform_hail_analysis(rs_name, rs_position, sex, person_df, mt_acaf):\n",
    "    \"\"\"\n",
    "    Performs Hail analysis for the given SNP and sex variable.\n",
    "\n",
    "    Args:\n",
    "    rs_name (str): The name of the SNP.\n",
    "    rs_position (str): The position of the SNP.\n",
    "    sex (str): The sex variable to filter the data ('Male', 'Female', or None).\n",
    "    person_df (pd.DataFrame): DataFrame containing person data.\n",
    "    mt_acaf (str): Path to the MatrixTable file.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing genotype information.\n",
    "    str: Message indicating the action taken.\n",
    "    \"\"\"\n",
    "    # Initialize message\n",
    "    message = \"\"\n",
    "\n",
    "    # Set up Hail environment\n",
    "    mt = hl.read_matrix_table(mt_acaf)\n",
    "\n",
    "    # Filter MatrixTable for the given SNP position\n",
    "    test_intervals = [rs_position]\n",
    "    mt = hl.filter_intervals(mt, [hl.parse_locus_interval(x) for x in test_intervals])\n",
    "\n",
    "    # Get genotype quality (GQ) histogram\n",
    "    p = hl.plot.histogram(mt.GQ, range=(0, 100), bins=10, title='GQ Histogram', legend='GQ')\n",
    "\n",
    "    # Add alleles message\n",
    "    alleles_row = mt.aggregate_rows(hl.agg.collect(mt.alleles))\n",
    "    alleles_row = alleles_row[0]\n",
    "    message += f\"Alleles for SNP {rs_name}: {alleles_row[0]}\\n\"\n",
    "\n",
    "    # Create DataFrame with genotype information\n",
    "    s = mt.aggregate_entries(hl.agg.collect(mt.s))\n",
    "    AD = mt.aggregate_entries(hl.agg.collect(mt.AD))\n",
    "    GT = mt.aggregate_entries(hl.agg.collect(mt.GT))\n",
    "    FT = mt.aggregate_entries(hl.agg.collect(mt.FT))\n",
    "    GQ = mt.aggregate_entries(hl.agg.collect(mt.GQ))\n",
    "    RGQ = mt.aggregate_entries(hl.agg.collect(mt.RGQ))\n",
    "    df = pd.DataFrame({'s': s, 'GT': GT, 'AD': AD, 'FT': FT, 'GQ': GQ, 'RGQ': RGQ})\n",
    "\n",
    "    # Rename columns\n",
    "    df = df.rename(columns={'s': 'id'})\n",
    "\n",
    "    # Filter person DataFrame based on sex\n",
    "    if sex.lower() == 'male':\n",
    "        person_df_filtered = person_df[person_df['sex_at_birth'] == 'Male']\n",
    "        message += f\"Filtering by Male sex.\\n\"\n",
    "    elif sex.lower() == 'female':\n",
    "        person_df_filtered = person_df[person_df['sex_at_birth'] == 'Female']\n",
    "        message += f\"Filtering by Female sex.\\n\"\n",
    "    else:\n",
    "        person_df_filtered = person_df\n",
    "        message += \"No specific sex selected. Performing analysis on all individuals.\\n\"\n",
    "\n",
    "    # Filter DataFrame based on person DataFrame\n",
    "    person_df_filtered = person_df_filtered.rename(columns={'person_id': 'id'})\n",
    "    person_df_filtered['id'] = person_df_filtered['id'].astype(str)\n",
    "    samples = person_df_filtered['id'].tolist()\n",
    "    df['id'] = df['id'].astype(str)\n",
    "    df = df[df['id'].isin(samples)]\n",
    "    df = pd.merge(df, person_df_filtered, on='id')\n",
    "\n",
    "    # Save pie chart\n",
    "    df['GT'].value_counts().plot(kind='pie', title='{}_{}'.format(rs_name, sex),\n",
    "                                  legend=True).get_figure().savefig('./download/{}_{}_pie_GT_all_1.pdf'.format(rs_name, sex),\n",
    "                                                                     dpi=300, facecolor='w',bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    return df, message,alleles_row\n",
    "def filter_data_and_print_value_counts(df, rs_name, person_information, GQ_threshold, phecode_min):\n",
    "    \"\"\"\n",
    "    Filter the genotype data based on genotype quality threshold and print the value counts of genotypes.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): DataFrame containing genotype data.\n",
    "    rs_name (str): Name of the SNP.\n",
    "    person_information (pd.DataFrame): DataFrame containing person information for conditions.\n",
    "    GQ_threshold (int): Genotype quality threshold (default is 20).\n",
    "    phecode_min (int): Minimum number of PheCodes in the dataset (default is 0).\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Filtered DataFrame for genotype data.\n",
    "    str: Message indicating the number of entries removed based on GQ threshold and PheCode minimum.\n",
    "    pd.DataFrame or None: DataFrame containing conditions data if phecode_min is greater than zero, otherwise None.\n",
    "    \"\"\"\n",
    "    # Choose samples with genotype quality >= GQ_threshold\n",
    "    num_samples_removed_gq = df.shape[0] - df[df['GQ'] >= GQ_threshold].shape[0]\n",
    "    df = df[df['GQ'] >= GQ_threshold]\n",
    "\n",
    "    # Rename the 'GT' column to 'rs_name'\n",
    "    df = df.rename(columns={'GT': rs_name})\n",
    "\n",
    "    # Print value counts of genotypes\n",
    "    genotype_value_counts = df[rs_name].value_counts()\n",
    "    print(genotype_value_counts)\n",
    "\n",
    "    # Sort DataFrame by 'id'\n",
    "    df = df.sort_values(by=['id'])\n",
    "\n",
    "    # Create conditions DataFrame\n",
    "    conditions = pd.DataFrame(data=person_information, columns=['person_id','source_vocabulary','source_concept_code','source_concept_name','count'])\n",
    "    conditions['count'] = conditions.groupby(['person_id','source_vocabulary', 'source_concept_code','source_concept_name'])['source_concept_code'].transform('count')\n",
    "    conditions.sort_values(by=['person_id'], inplace=True)\n",
    "    conditions.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Filter DataFrame based on minimum PheCode count if phecode_min is greater than zero\n",
    "    if phecode_min > 0:\n",
    "        list_con = conditions['source_concept_code'].value_counts().rename_axis('source_concept_code').to_frame('counts')\n",
    "        list_con = list_con.reset_index()\n",
    "        list_con = list_con[list_con['counts'] >= phecode_min]\n",
    "        num_entries_removed_phecode = conditions.shape[0] - conditions[conditions['source_concept_code'].isin(list_con['source_concept_code'])].shape[0]\n",
    "        conditions = conditions[conditions['source_concept_code'].isin(list_con['source_concept_code'])]\n",
    "        conditions = conditions.reset_index(drop=True)\n",
    "    else:\n",
    "        num_entries_removed_phecode = 0\n",
    "\n",
    "    # Create message\n",
    "    message = f\"Number of entries removed based on GQ threshold ({GQ_threshold}): {num_samples_removed_gq}\\n\"\n",
    "    message += f\"Number of entries removed based on PheCode minimum threshold ({phecode_min}): {num_entries_removed_phecode}\"\n",
    "\n",
    "    return df, message, conditions\n",
    "def filter_common_ids(samples_GT, conditions, rs_name):\n",
    "    \"\"\"\n",
    "    Keep only the IDs that have data in both samples_GT and conditions DataFrames.\n",
    "\n",
    "    Args:\n",
    "    samples_GT (pd.DataFrame): DataFrame containing genotype data with 'id' column.\n",
    "    conditions (pd.DataFrame): DataFrame containing conditions data with 'id' column.\n",
    "    rs_name (str): Name of the SNP.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing samples_GT with common IDs.\n",
    "    pd.DataFrame: DataFrame containing conditions with common IDs.\n",
    "    str: Message indicating the number of IDs removed and the number of unique IDs remaining in both DataFrames.\n",
    "    \"\"\"\n",
    "    # Rename the 'person_id' column in conditions to 'id'\n",
    "    conditions = conditions.rename(columns={'person_id': 'id'})\n",
    "\n",
    "    # Convert 'id' column in samples_GT and conditions to string\n",
    "    df['id'] = df['id'].astype(str)\n",
    "    conditions['id'] = conditions['id'].astype(str)\n",
    "\n",
    "    # Get unique values of 'id' columns in samples_GT and conditions\n",
    "    df_unique_list = set(df['id'].unique())\n",
    "    conditions_unique_list = set(conditions['id'].unique())\n",
    "\n",
    "    # Keep only values in conditions_unique_list that are in conditions_unique_list\n",
    "    common_ids = df_unique_list.intersection(conditions_unique_list)\n",
    "\n",
    "    # Filter df and conditions_unique based on the common 'id' values\n",
    "    df_common = df[df['id'].isin(common_ids)]\n",
    "    conditions_common = conditions[conditions['id'].isin(common_ids)]\n",
    "\n",
    "    # Select specific columns in df\n",
    "    df_common = df_common[['id', rs_name]]\n",
    "\n",
    "    # Create message\n",
    "    message = f\"Number of IDs removed: {len(df_unique_list) - len(common_ids)}\\n\"\n",
    "    message += f\"Number of unique IDs remaining in both DataFrames: {len(common_ids)}\"\n",
    "\n",
    "    return df_common, conditions_common, message\n",
    "def filter_df_by_common_ids(df, df_common):\n",
    "    \"\"\"\n",
    "    Keep only the IDs that are present in the df_common DataFrame from the original df.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): Original DataFrame containing genotype data.\n",
    "    df_common (pd.DataFrame): DataFrame containing common IDs.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing df with common IDs.\n",
    "    \"\"\"\n",
    "    # Filter the original DataFrame based on common IDs\n",
    "    filtered_df = df[df['id'].isin(df_common['id'])]\n",
    "\n",
    "    return filtered_df\n",
    "def generate_genotype_frequency_table(filtered_df, rs_name):\n",
    "    \"\"\"\n",
    "    Generate a genotype frequency table for the given DataFrame and SNP name.\n",
    "\n",
    "    Args:\n",
    "    filtered_df (pd.DataFrame): DataFrame containing genotype data.\n",
    "    rs_name (str): Name of the SNP.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing the genotype frequency table.\n",
    "    str: Message indicating the table has been created and saved.\n",
    "    \"\"\"\n",
    "    # Count the occurrences of each genotype value for all samples\n",
    "    all_genotype_counts = filtered_df[rs_name].value_counts()\n",
    "\n",
    "    # Count the occurrences of each genotype value for male samples\n",
    "    male_genotype_counts = filtered_df[filtered_df['sex_at_birth'] == 'Male'][rs_name].value_counts()\n",
    "\n",
    "    # Count the occurrences of each genotype value for female samples\n",
    "    female_genotype_counts = filtered_df[filtered_df['sex_at_birth'] == 'Female'][rs_name].value_counts()\n",
    "\n",
    "    # Define the genotypes\n",
    "    genotypes = [0, 1, 2]\n",
    "\n",
    "    # Create Series for all_gt, male_gt, and female_gt\n",
    "    all_gt = pd.Series(all_genotype_counts, name='all_gt', index=genotypes)\n",
    "    male_gt = pd.Series(male_genotype_counts, name='male_gt', index=genotypes)\n",
    "    female_gt = pd.Series(female_genotype_counts, name='female_gt', index=genotypes)\n",
    "\n",
    "    # Calculate the total genotype count for all samples\n",
    "    total_all_gt = all_gt.sum()\n",
    "\n",
    "    # Calculate the total genotype count for males\n",
    "    total_male_gt = male_gt.sum()\n",
    "\n",
    "    # Calculate the total genotype count for females\n",
    "    total_female_gt = female_gt.sum()\n",
    "\n",
    "    # Check if counts for male, female, or all genotypes are less than 20\n",
    "    if total_all_gt < 20 or total_male_gt < 20 or total_female_gt < 20:\n",
    "        print(\"Counts for male, female, or all genotypes are less than 20. Changing counts to <20.\")\n",
    "        all_gt = all_gt.apply(lambda x: x if x >= 20 else '<20')\n",
    "        male_gt = male_gt.apply(lambda x: x if x >= 20 else '<20')\n",
    "        female_gt = female_gt.apply(lambda x: x if x >= 20 else '<20')\n",
    "\n",
    "    # Replace NaN counts with 0\n",
    "    all_gt.fillna(0, inplace=True)\n",
    "    male_gt.fillna(0, inplace=True)\n",
    "    female_gt.fillna(0, inplace=True)\n",
    "    # Convert counts to integers\n",
    "    all_gt = all_gt.astype(int)\n",
    "    male_gt = male_gt.astype(int)\n",
    "    female_gt = female_gt.astype(int)\n",
    "\n",
    "    # Create a DataFrame to store the frequencies of each genotype, with NaN for missing values\n",
    "    frequency_df = pd.DataFrame({'all_gt': all_gt, 'male_gt': male_gt, 'female_gt': female_gt})\n",
    "\n",
    "    # Replace counts less than 20 with \"<20\"\n",
    "    frequency_df = frequency_df.applymap(lambda x: x if isinstance(x, str) else '<20' if x < 20 else x)\n",
    "\n",
    "    # Display the frequency DataFrame using tabulate\n",
    "    table_str = tabulate(frequency_df, headers='keys', tablefmt='pretty')\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    file_path = './download/{}_frequency_of_genotype.csv'.format(rs_name)\n",
    "    frequency_df.to_csv(file_path, index=False)\n",
    "\n",
    "    # Message indicating the table has been created and saved\n",
    "    message = f\"Genotype frequency table has been created and saved.\\n\"\n",
    "    message += table_str\n",
    "\n",
    "    return frequency_df, message\n",
    "def plot_genotype_proportion(filtered_df, rs_name, pop_variable):\n",
    "    \"\"\"\n",
    "    Plot the proportion of male and female genotypes from the filtered DataFrame and save it as an image.\n",
    "\n",
    "    Args:\n",
    "    filtered_df (pd.DataFrame): DataFrame containing the filtered genotype data.\n",
    "    rs_name (str): Name of the SNP.\n",
    "    pop_variable (str): Name of the population.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Count the occurrences of each genotype value for all samples\n",
    "    all_gt = filtered_df[rs_name].value_counts().tolist()\n",
    "\n",
    "    # Count the occurrences of each genotype value for male samples\n",
    "    male_gt = filtered_df[filtered_df['sex_at_birth'] == 'Male'][rs_name].value_counts().tolist()\n",
    "    if len(male_gt) != 3:\n",
    "        male_gt.append(0)\n",
    "\n",
    "    # Count the occurrences of each genotype value for female samples\n",
    "    female_gt = filtered_df[filtered_df['sex_at_birth'] == 'Female'][rs_name].value_counts().tolist()\n",
    "    if len(female_gt) != 3:\n",
    "        female_gt.append(0)\n",
    "\n",
    "    # Total number of samples\n",
    "    total_samples = sum(all_gt)\n",
    "\n",
    "    # Calculate proportions\n",
    "    all_gt_proportion = [count / total_samples * 100 for count in all_gt]\n",
    "    male_gt_proportion = [count / total_samples * 100 for count in male_gt]\n",
    "    female_gt_proportion = [count / total_samples * 100 for count in female_gt]\n",
    "\n",
    "    # Define the genotypes\n",
    "    genotypes = ['0', '1', '2']\n",
    "\n",
    "    # Create DataFrame to store the proportions of each genotype\n",
    "    proportion_df = pd.DataFrame({'All': all_gt_proportion, 'Male': male_gt_proportion, 'Female': female_gt_proportion}, index=genotypes)\n",
    "\n",
    "    # Melt the DataFrame to long format for easier plotting\n",
    "    melted_df = pd.melt(proportion_df.reset_index(), id_vars='index', var_name='Group', value_name='Proportion')\n",
    "\n",
    "    # Plotting grouped bar graph\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='index', y='Proportion', hue='Group', data=melted_df, palette='viridis')\n",
    "\n",
    "    # Set y-axis limits\n",
    "    plt.ylim(0, 100)\n",
    "\n",
    "    # Adding labels and title\n",
    "    plt.xlabel('Genotypes')\n",
    "    plt.ylabel('Proportion (%)')\n",
    "    plt.title('Proportion of Male and Female Genotypes')\n",
    "    plt.legend(frameon=False)\n",
    "    ax = plt.gca()\n",
    "    ax.spines['left'].set_color('black')\n",
    "    ax.spines['bottom'].set_color('black')\n",
    "    # do not show the right and top spines\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['bottom'].set_linewidth(2)\n",
    "    ax.spines['left'].set_linewidth(2)\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "    # Save the figure\n",
    "    plt.savefig('./download/{}_{}_Genotype_Proportions_for_Different_Sex_Groups.pdf'.format(rs_name, pop_variable), bbox_inches='tight', pad_inches=0.5, dpi=300, facecolor='w')\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "def transform_sex_labels_and_calculate_age(df):\n",
    "    \"\"\"\n",
    "    Transform sex labels from 'Male' to 'M' and 'Female' to 'F' in the DataFrame,\n",
    "    and calculate the age based on the date of birth.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): DataFrame containing the sex labels and date of birth.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with transformed sex labels and calculated age.\n",
    "    str: Message indicating the transformation and age calculation.\n",
    "    \"\"\"\n",
    "    # Make a copy of the DataFrame to avoid modifying the original DataFrame\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Map 'Male' to 'M' and 'Female' to 'F' in a new 'sex' column\n",
    "    df_copy['sex'] = df_copy['sex_at_birth'].map({'Male': 'M', 'Female': 'F'})\n",
    "\n",
    "    # Calculate age based on date of birth\n",
    "    df_copy['date_of_birth'] = df_copy['date_of_birth'].astype(str).str[:4]\n",
    "    df_copy['age'] = 2023 - df_copy['date_of_birth'].astype(int)\n",
    "\n",
    "    # Add a message\n",
    "    message = 'Transformed sex labels to \"M\" and \"F\" and calculated age.'\n",
    "\n",
    "    return df_copy, message\n",
    "def plot_age_distribution_for_genotypes(filtered_df, rs_name):\n",
    "    \"\"\"\n",
    "    Generate plots for age distribution for different genotypes in males, females, and overall.\n",
    "\n",
    "    Args:\n",
    "    filtered_df (pd.DataFrame): DataFrame containing the filtered genotype data.\n",
    "    rs_name (str): Name of the SNP.\n",
    "\n",
    "    Returns:\n",
    "    str: Message indicating that plots have been saved.\n",
    "    \"\"\"\n",
    "    print(filtered_df.head())  # Debug print to check the filtered DataFrame\n",
    "    genotypes = [0, 1, 2]\n",
    "    sex_labels = {'M': 'Male', 'F': 'Female'}\n",
    "\n",
    "    for genotype in genotypes:\n",
    "        # Debug print to check the number of samples for each genotype\n",
    "        print(f\"Number of samples for genotype {genotype}: {len(filtered_df[filtered_df[rs_name] == genotype])}\")\n",
    "\n",
    "        # Skip plotting if there are no samples for the current genotype\n",
    "        if len(filtered_df[filtered_df[rs_name] == genotype]) == 0:\n",
    "            print(f\"No samples found for genotype {genotype}. Skipping plotting.\")\n",
    "            continue\n",
    "\n",
    "        # Visualize age distribution for different genotypes in males\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        for sex in ['M', 'F']:\n",
    "            sns.histplot(filtered_df[(filtered_df['sex'] == sex) & (filtered_df[rs_name] == genotype)]['age'], kde=True, label=f'{sex_labels[sex]}')\n",
    "        plt.title(f'Age Distribution for Genotype {genotype} (Male vs Female)')\n",
    "        plt.xlabel('Age')\n",
    "        plt.ylabel('Density')\n",
    "        plt.legend(frameon=False)\n",
    "        ax = plt.gca()\n",
    "        ax.spines['left'].set_color('black')\n",
    "        ax.spines['bottom'].set_color('black')\n",
    "        # do not show the right and top spines\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['bottom'].set_linewidth(2)\n",
    "        ax.spines['left'].set_linewidth(2)\n",
    "        plt.grid(False)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'./download/{rs_name}_age_distribution_genotype_{genotype}_male_vs_female.pdf', dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "        # Visualize overall age distribution for different genotypes\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.histplot(filtered_df[filtered_df[rs_name] == genotype]['age'], kde=True)\n",
    "        plt.title(f'Overall Age Distribution for Genotype {genotype}')\n",
    "        plt.xlabel('Age')\n",
    "        plt.ylabel('Density')\n",
    "        plt.legend(frameon=False)\n",
    "        ax = plt.gca()\n",
    "        ax.spines['left'].set_color('black')\n",
    "        ax.spines['bottom'].set_color('black')\n",
    "        # do not show the right and top spines\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['bottom'].set_linewidth(2)\n",
    "        ax.spines['left'].set_linewidth(2)\n",
    "        plt.grid(False)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'./download/{rs_name}_age_distribution_genotype_{genotype}_overall.pdf', dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "    message = 'Plots for age distribution for different genotypes have been saved.'\n",
    "    return message\n",
    "def plot_age_distribution_for_genotypes(filtered_df, rs_name, pop_variable):\n",
    "    \"\"\"\n",
    "    Generate plots for age distribution for different genotypes in males, females, and overall.\n",
    "\n",
    "    Args:\n",
    "    filtered_df (pd.DataFrame): DataFrame containing the filtered genotype data.\n",
    "    rs_name (str): Name of the SNP.\n",
    "    pop_variable (str): Population variable.\n",
    "\n",
    "    Returns:\n",
    "    str: Message indicating that plots have been saved.\n",
    "    \"\"\"\n",
    "    # Convert genotypes to string\n",
    "    genotypes = [0, 1, 2]\n",
    "\n",
    "    # Sex labels mapping\n",
    "    sex_labels = {'M': 'Male', 'F': 'Female'}\n",
    "\n",
    "    # Visualize age distribution for different genotypes in males\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for genotype in genotypes:\n",
    "        sns.histplot(filtered_df[(filtered_df['sex'] == 'M') & (filtered_df[rs_name] == genotype)]['age'], kde=True, label=f'GT={genotype}')\n",
    "    plt.title('Age Distribution in Males for Different Genotypes without sex aggregation')\n",
    "    plt.xlabel('Age')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend(frameon=False)\n",
    "    ax = plt.gca()\n",
    "    ax.spines['left'].set_color('black')\n",
    "    ax.spines['bottom'].set_color('black')\n",
    "    # do not show the right and top spines\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['bottom'].set_linewidth(2)\n",
    "    ax.spines['left'].set_linewidth(2)\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./download/{rs_name}_{pop_variable}_age_Male_distribution_with_dif_Genotypes_without_sex_aggregation.pdf', dpi=300, facecolor='w')\n",
    "    plt.show()\n",
    "\n",
    "    # Visualize age distribution for different genotypes in females\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for genotype in genotypes:\n",
    "        sns.histplot(filtered_df[(filtered_df['sex'] == 'F') & (filtered_df[rs_name] == genotype)]['age'], kde=True, label=f'GT={genotype}')\n",
    "    plt.title('Age Distribution in Females for Different Genotypes without sex aggregation')\n",
    "    plt.xlabel('Age')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend(frameon=False)\n",
    "    ax = plt.gca()\n",
    "    ax.spines['left'].set_color('black')\n",
    "    ax.spines['bottom'].set_color('black')\n",
    "    # do not show the right and top spines\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['bottom'].set_linewidth(2)\n",
    "    ax.spines['left'].set_linewidth(2)\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./download/{rs_name}_{pop_variable}_age_Female_distribution_with_dif_Genotypes_without_sex_agg.pdf', dpi=300, facecolor='w')\n",
    "    plt.show()\n",
    "\n",
    "    # Visualize overall age distribution for different genotypes\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for genotype in genotypes:\n",
    "        sns.histplot(filtered_df[filtered_df[rs_name] == genotype]['age'], kde=True, label=f'GT={genotype}')\n",
    "    plt.title('Overall Age Distribution for Different Genotypes without sex agg')\n",
    "    plt.xlabel('Age')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend(frameon=False)\n",
    "    ax = plt.gca()\n",
    "    ax.spines['left'].set_color('black')\n",
    "    ax.spines['bottom'].set_color('black')\n",
    "    # do not show the right and top spines\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['bottom'].set_linewidth(2)\n",
    "    ax.spines['left'].set_linewidth(2)\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./download/{rs_name}_{pop_variable}_age_all_population_distribution_with_dif_Genotypes_without_sex_agg.pdf', dpi=300, facecolor='w')\n",
    "    plt.show()\n",
    "\n",
    "    message = f'Plots for age distribution for different genotypes have been saved.'\n",
    "    return message\n",
    "def merge_population_data(filtered_df, population):\n",
    "    \"\"\"\n",
    "    Merge population data with genotype data.\n",
    "\n",
    "    Args:\n",
    "    filtered_df (pd.DataFrame): DataFrame containing the filtered genotype data.\n",
    "    population (pd.DataFrame): DataFrame containing population data.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Combined DataFrame with genotype and population data.\n",
    "    str: Message indicating that population data has been merged.\n",
    "    str: Message indicating if any samples were removed after the merge.\n",
    "    \"\"\"\n",
    "\n",
    "    # Rename the column 'person_id' to 'id' in population_new\n",
    "    population_new = population.rename(columns={'person_id': 'id'})\n",
    "\n",
    "    # Ensure 'id' column in population_new is of the same data type as in filtered_df\n",
    "    population_new['id'] = population_new['id'].astype(str)\n",
    "\n",
    "    # Merge population_new with filtered_df on 'id' column\n",
    "    merged_df = pd.merge(filtered_df, population_new, on='id', how='left')\n",
    "\n",
    "    # Drop columns ending with '_x' or '_y' (resulting from merge)\n",
    "    merged_df = merged_df.loc[:, ~merged_df.columns.str.endswith('_x') & ~merged_df.columns.str.endswith('_y')]\n",
    "\n",
    "    # Check if any samples were removed after the merge\n",
    "    removed_samples = len(filtered_df) - len(merged_df)\n",
    "    if removed_samples > 0:\n",
    "        removed_message = f\"{removed_samples} samples were removed after the merge.\"\n",
    "    else:\n",
    "        removed_message = \"No samples were removed after the merge.\"\n",
    "\n",
    "    # Message indicating that population data has been merged\n",
    "    merge_message = \"Population data has been merged with genotype data.\"\n",
    "\n",
    "    return merged_df, merge_message, removed_message\n",
    "def filter_and_create_dataframes(merged_df, conditions_common, icd9cm=True, icd10cm=True):\n",
    "    \"\"\"\n",
    "    Filter the merged DataFrame based on common IDs and create separate DataFrames for ICD9CM and ICD10CM, or combine both.\n",
    "\n",
    "    Args:\n",
    "    merged_df (pd.DataFrame): Merged DataFrame containing genotype and population data.\n",
    "    conditions_common (pd.DataFrame): DataFrame containing condition data.\n",
    "    icd9cm (bool): Whether to create a DataFrame for ICD9CM (default is True).\n",
    "    icd10cm (bool): Whether to create a DataFrame for ICD10CM (default is True).\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Combined DataFrame with ICD9CM and ICD10CM data, or separate DataFrames based on user choice.\n",
    "    str: Message indicating how many data points were removed and how many remain.\n",
    "    \"\"\"\n",
    "\n",
    "    # Find filtered ids\n",
    "    final_data_ids = merged_df['id'].tolist()\n",
    "\n",
    "    # Filter the ids from conditions_common that are present in final_data\n",
    "    filtered_ids = conditions_common[conditions_common['id'].isin(final_data_ids)]\n",
    "    removed_count = len(conditions_common) - len(filtered_ids)\n",
    "\n",
    "    if icd9cm and icd10cm:\n",
    "        # Separate DataFrames for ICD9CM and ICD10CM\n",
    "        conditions_unique_ICD10CM = filtered_ids[filtered_ids['source_vocabulary'] == 'ICD10CM']\n",
    "        conditions_unique_ICD9CM = filtered_ids[filtered_ids['source_vocabulary'] == 'ICD9CM']\n",
    "\n",
    "        # Save separate DataFrames\n",
    "        save_conditions_unique_ICD9CM = conditions_unique_ICD9CM[['id', 'source_vocabulary', 'source_concept_code', 'count']]\n",
    "        save_conditions_unique_ICD10CM = conditions_unique_ICD10CM[['id', 'source_vocabulary', 'source_concept_code', 'count']]\n",
    "\n",
    "        # Combine ICD9CM and ICD10CM DataFrames\n",
    "        conditions_unique_10_9 = pd.concat([save_conditions_unique_ICD10CM, save_conditions_unique_ICD9CM], axis=0)\n",
    "        remaining_count = len(conditions_unique_10_9)\n",
    "\n",
    "        message = f\"{removed_count} Disease were removed. Disease points: {remaining_count}\"\n",
    "\n",
    "        return conditions_unique_10_9, message\n",
    "    elif icd9cm:\n",
    "        # Filter only ICD9CM data\n",
    "        conditions_unique_ICD9CM = filtered_ids[filtered_ids['source_vocabulary'] == 'ICD9CM']\n",
    "        remaining_count = len(conditions_unique_ICD9CM)\n",
    "\n",
    "        message = f\"{removed_count} Disease were removed. Disease points for ICD9CM: {remaining_count}\"\n",
    "\n",
    "        return conditions_unique_ICD9CM[['id', 'source_vocabulary', 'source_concept_code', 'count']], message\n",
    "    elif icd10cm:\n",
    "        # Filter only ICD10CM data\n",
    "        conditions_unique_ICD10CM = filtered_ids[filtered_ids['source_vocabulary'] == 'ICD10CM']\n",
    "        remaining_count = len(conditions_unique_ICD10CM)\n",
    "\n",
    "        message = f\"{removed_count} Disease were removed. Remaining Disease for ICD10CM: {remaining_count}\"\n",
    "\n",
    "        return conditions_unique_ICD10CM[['id', 'source_vocabulary', 'source_concept_code', 'count']], message\n",
    "    else:\n",
    "        # Combine ICD9CM and ICD10CM DataFrames if both icd9cm and icd10cm are False\n",
    "        conditions_unique_ICD10CM = filtered_ids[filtered_ids['source_vocabulary'] == 'ICD10CM']\n",
    "        conditions_unique_ICD9CM = filtered_ids[filtered_ids['source_vocabulary'] == 'ICD9CM']\n",
    "\n",
    "        # Save separate DataFrames\n",
    "        save_conditions_unique_ICD9CM = conditions_unique_ICD9CM[['id', 'source_vocabulary', 'source_concept_code', 'count']]\n",
    "        save_conditions_unique_ICD10CM = conditions_unique_ICD10CM[['id', 'source_vocabulary', 'source_concept_code', 'count']]\n",
    "\n",
    "        # Combine ICD9CM and ICD10CM DataFrames\n",
    "        conditions_unique_10_9 = pd.concat([save_conditions_unique_ICD10CM, save_conditions_unique_ICD9CM], axis=0)\n",
    "        remaining_count = len(conditions_unique_10_9)\n",
    "\n",
    "        message = f\"{removed_count} Disease were removed. Disease patients for ICD9CM and ICD10CM: {remaining_count}\"\n",
    "\n",
    "        return conditions_unique_10_9, message\n",
    "def create_pie_chart_after_filtering(genotype_counts, rs_name, pop_variable):\n",
    "    \"\"\"\n",
    "    Create a pie chart based on genotype counts.\n",
    "\n",
    "    Args:\n",
    "    genotype_counts (pd.Series): Series containing genotype counts.\n",
    "    rs_name (str): Name of the SNP.\n",
    "    pop_variable (str): Name of the population variable.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Replace values less than 20 with a placeholder\n",
    "    genotype_counts = genotype_counts.apply(lambda x: x if x >= 20 else '<20')\n",
    "\n",
    "    # Plot the pie chart\n",
    "    pie_chart = genotype_counts.plot(kind='pie', title='{}'.format(rs_name), legend=True)\n",
    "\n",
    "    # Add the genotype counts to the title\n",
    "    title_with_counts = '{} (0: {}, 1: {}, 2: {})'.format(rs_name, \n",
    "                                                         genotype_counts.get(0, 0),\n",
    "                                                         genotype_counts.get(1, 0),\n",
    "                                                         genotype_counts.get(2, 0))\n",
    "    pie_chart.set_title(title_with_counts)\n",
    "    \n",
    "\n",
    "    # Save the figure\n",
    "    plt.savefig('./download/{}_{}_pie_GT_my_data_after_filtering.pdf'.format(rs_name, pop_variable), dpi=300, facecolor='w')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "def create_genotype_files_and_plots(merged_df, rs_name, pop_variable):\n",
    "    \"\"\"\n",
    "    Create two files and two plots for genotype information from the merged DataFrame.\n",
    "    \n",
    "    Args:\n",
    "    merged_df (pd.DataFrame): DataFrame containing genotype and population data.\n",
    "    rs_name (str): Name of the genotype column.\n",
    "    pop_variable (str): Name of the population variable.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the merged_df is empty\n",
    "    if merged_df.empty:\n",
    "        print(\"Error: The merged DataFrame is empty.\")\n",
    "        return\n",
    "    \n",
    "    # Define the genotype values to count\n",
    "    genotypes_to_count = [0, 1, 2]\n",
    "\n",
    "    # Group by 'ancestry_pred' and aggregate the data\n",
    "    aggregated_data = merged_df.groupby('ancestry_pred').agg({\n",
    "        'sex': lambda x: x.value_counts().to_dict(),  # Count of each sex\n",
    "    })\n",
    "\n",
    "    # Count each genotype for each ancestry_pred group\n",
    "    for genotype in genotypes_to_count:\n",
    "        aggregated_data[f'M_gt_{genotype}'] = merged_df.loc[merged_df['sex'] == 'M'].groupby('ancestry_pred')[rs_name].apply(lambda x: (x == genotype).sum())\n",
    "        aggregated_data[f'F_gt_{genotype}'] = merged_df.loc[merged_df['sex'] == 'F'].groupby('ancestry_pred')[rs_name].apply(lambda x: (x == genotype).sum())\n",
    "    # Count each genotype for each ancestry_pred group\n",
    "    for genotype in genotypes_to_count:\n",
    "        aggregated_data[f'genotype_{genotype}_count'] = merged_df.groupby('ancestry_pred')[rs_name].apply(lambda x: (x == genotype).sum())\n",
    "\n",
    "    # Ensure counts for males ('M') and females ('F') are integers and replace NaN with 0\n",
    "    aggregated_data['male_count'] = aggregated_data['sex'].apply(lambda x: int(x.get('M', 0)) if isinstance(x, dict) else 0)\n",
    "    aggregated_data['female_count'] = aggregated_data['sex'].apply(lambda x: int(x.get('F', 0)) if isinstance(x, dict) else 0)\n",
    "\n",
    "    # Drop the original 'sex' column\n",
    "    aggregated_data = aggregated_data.drop('sex', axis=1)\n",
    "\n",
    "    aggregated_data.reset_index(inplace=True)\n",
    "    df1 = aggregated_data\n",
    "    # Now 'ancestry_pred' is a regular column\n",
    "    print(aggregated_data)\n",
    "    ancestry_pred = df1['ancestry_pred']\n",
    "    genotypes = ['0', '1', '2']\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Define bar width\n",
    "    bar_width = 0.15\n",
    "\n",
    "    # Define positions for each group of bars\n",
    "    r1 = range(len(ancestry_pred))\n",
    "    r2 = [x + bar_width for x in r1]\n",
    "    r3 = [x + bar_width for x in r2]\n",
    "    r4 = [x + bar_width for x in r3]\n",
    "    r5 = [x + bar_width for x in r4]\n",
    "    r6 = [x + bar_width for x in r5]\n",
    "\n",
    "    # Plot bars for each genotype and gender combination\n",
    "    plt.bar(r1, df1['M_gt_0'], color='b', width=bar_width, edgecolor='grey', label='M_gt_0')\n",
    "    plt.bar(r2, df1['F_gt_0'], color='g', width=bar_width, edgecolor='grey', label='F_gt_0')\n",
    "    plt.bar(r3, df1['M_gt_1'], color='r', width=bar_width, edgecolor='grey', label='M_gt_1')\n",
    "    plt.bar(r4, df1['F_gt_1'], color='c', width=bar_width, edgecolor='grey', label='F_gt_1')\n",
    "    plt.bar(r5, df1['M_gt_2'], color='m', width=bar_width, edgecolor='grey', label='M_gt_2')\n",
    "    plt.bar(r6, df1['F_gt_2'], color='y', width=bar_width, edgecolor='grey', label='F_gt_2')\n",
    "\n",
    "    # Add xticks on the middle of the group bars\n",
    "    plt.xlabel('Ancestry prediction', fontweight='bold')\n",
    "    plt.xticks([r + bar_width * 2.5 for r in range(len(ancestry_pred))], ancestry_pred)\n",
    "    plt.title(f'Number of genotype in all ancestry for {rs_name}')\n",
    "    # Add y label\n",
    "    plt.ylabel('Count')\n",
    "    ax = plt.gca()\n",
    "    ax.spines['left'].set_color('black')\n",
    "    ax.spines['bottom'].set_color('black')\n",
    "    # do not show the right and top spines\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['bottom'].set_linewidth(2)\n",
    "    ax.spines['left'].set_linewidth(2)\n",
    "    plt.grid(False)\n",
    "\n",
    "    # Create legend & Show graphic\n",
    "    plt.legend(frameon=False)\n",
    "    # save it \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./download/{}_{}_Number of genotype in all ancestry.pdf'.format(rs_name,pop_variable),dpi=300,facecolor='w')\n",
    "    plt.show()\n",
    "\n",
    "    # Define the genotype values to count\n",
    "    genotypes_to_count = [0, 1, 2]\n",
    "\n",
    "    # Group by 'ancestry_pred' and aggregate the data\n",
    "    aggregated_data_other = merged_df.groupby('ancestry_pred_other').agg({\n",
    "        'sex': lambda x: x.value_counts().to_dict(),  # Count of each sex\n",
    "    })\n",
    "\n",
    "    # Count each genotype for each ancestry_pred group\n",
    "    for genotype in genotypes_to_count:\n",
    "        aggregated_data_other[f'M_gt_{genotype}'] = merged_df.loc[merged_df['sex'] == 'M'].groupby('ancestry_pred_other')[rs_name].apply(lambda x: (x == genotype).sum())\n",
    "        aggregated_data_other[f'F_gt_{genotype}'] = merged_df.loc[merged_df['sex'] == 'F'].groupby('ancestry_pred_other')[rs_name].apply(lambda x: (x == genotype).sum())\n",
    "    # Count each genotype for each ancestry_pred group\n",
    "    for genotype in genotypes_to_count:\n",
    "        aggregated_data_other[f'genotype_{genotype}_count'] = merged_df.groupby('ancestry_pred_other')[rs_name].apply(lambda x: (x == genotype).sum())\n",
    "\n",
    "    # Ensure counts for males ('M') and females ('F') are integers and replace NaN with 0\n",
    "    aggregated_data_other['male_count'] = aggregated_data_other['sex'].apply(lambda x: int(x.get('M', 0)) if isinstance(x, dict) else 0)\n",
    "    aggregated_data_other['female_count'] = aggregated_data_other['sex'].apply(lambda x: int(x.get('F', 0)) if isinstance(x, dict) else 0)\n",
    "\n",
    "    # Drop the original 'sex' column\n",
    "    aggregated_data_other = aggregated_data_other.drop('sex', axis=1)\n",
    "\n",
    "    aggregated_data_other.reset_index(inplace=True)\n",
    "    df1 = aggregated_data_other\n",
    "    # Now 'ancestry_pred' is a regular column\n",
    "    print(aggregated_data_other)\n",
    "    ancestry_pred = df1['ancestry_pred_other']\n",
    "    genotypes = [0, 1, 2]\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Define bar width\n",
    "    bar_width = 0.15\n",
    "\n",
    "    # Define positions for each group of bars\n",
    "    r1 = range(len(ancestry_pred))\n",
    "    r2 = [x + bar_width for x in r1]\n",
    "    r3 = [x + bar_width for x in r2]\n",
    "    r4 = [x + bar_width for x in r3]\n",
    "    r5 = [x + bar_width for x in r4]\n",
    "    r6 = [x + bar_width for x in r5]\n",
    "\n",
    "    # Plot bars for each genotype and gender combination\n",
    "    plt.bar(r1, df1['M_gt_0'], color='b', width=bar_width, edgecolor='grey', label='M_gt_0')\n",
    "    plt.bar(r2, df1['F_gt_0'], color='g', width=bar_width, edgecolor='grey', label='F_gt_0')\n",
    "    plt.bar(r3, df1['M_gt_1'], color='r', width=bar_width, edgecolor='grey', label='M_gt_1')\n",
    "    plt.bar(r4, df1['F_gt_1'], color='c', width=bar_width, edgecolor='grey', label='F_gt_1')\n",
    "    plt.bar(r5, df1['M_gt_2'], color='m', width=bar_width, edgecolor='grey', label='M_gt_2')\n",
    "    plt.bar(r6, df1['F_gt_2'], color='y', width=bar_width, edgecolor='grey', label='F_gt_2')\n",
    "\n",
    "    # Add xticks on the middle of the group bars\n",
    "    plt.xlabel('Ancestry prediction', fontweight='bold')\n",
    "\n",
    "    plt.xticks([r + bar_width * 2.5 for r in range(len(ancestry_pred))], ancestry_pred)\n",
    "\n",
    "    plt.title(f'Number of genotype in all ancestry and other for {rs_name}')\n",
    "    # Add y label\n",
    "    plt.ylabel('Count')\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.spines['left'].set_color('black')\n",
    "    ax.spines['bottom'].set_color('black')\n",
    "    # do not show the right and top spines\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['bottom'].set_linewidth(2)\n",
    "    ax.spines['left'].set_linewidth(2)\n",
    "    plt.grid(False)\n",
    "\n",
    "    # Create legend & Show graphic\n",
    "    plt.legend(frameon=False)\n",
    "    # save it \n",
    "    plt.savefig('./download/{}_{}_Number of genotype in all ancestry with other.pdf'.format(rs_name,pop_variable),dpi=300,facecolor='w')\n",
    "    plt.show()\n",
    "    # Define a function to replace values less than 20 with '<20'\n",
    "    def replace_less_than_20(value):\n",
    "        return '<20' if value < 20 else value\n",
    "\n",
    "    # Iterate over the columns of the first dataframe (aggregated_data)\n",
    "    for column in aggregated_data.columns[1:]:  # Exclude the 'ancestry_pred' column\n",
    "        aggregated_data[column] = aggregated_data[column].apply(replace_less_than_20)\n",
    "\n",
    "    # Iterate over the columns of the second dataframe (aggregated_data_other)\n",
    "    for column in aggregated_data_other.columns[1:]:  # Exclude the 'ancestry_pred' column\n",
    "        aggregated_data_other[column] = aggregated_data_other[column].apply(replace_less_than_20)\n",
    "\n",
    "    # Save to CSV\n",
    "    aggregated_data.to_csv('download/{}_{} Count of Genotypes in ancestry.csv'.format(rs_name, pop_variable), index=False)\n",
    "    aggregated_data_other.to_csv('download/{}_{} Count of Genotypes in ancestry with other.csv'.format(rs_name, pop_variable), index=False)\n",
    "def generate_genotype_plots(merged_df, rs_name, pop_variable):\n",
    "    # Set the color palette for each genotype and specify the order of legend labels\n",
    "    \n",
    "    genotype_colors = {0: 'purple', 1: 'orange', 2: 'blue'}\n",
    "    genotype_order = [0, 1, 2]\n",
    "    \n",
    "    # Combine all genotypes for the violin plot\n",
    "    combined_genotypes = merged_df[merged_df[rs_name].isin(genotype_colors.keys())]\n",
    "\n",
    "    # Melt the DataFrame for easier plotting\n",
    "    melted_data = pd.melt(combined_genotypes, id_vars=rs_name, value_vars=[f'principal_component_{i}' for i in range(1, 17)])\n",
    "\n",
    "    # Initialize the figure and axes for the combined violin plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    # Create a violin plot for all genotypes\n",
    "    sns.violinplot(x=\"variable\", y=\"value\", hue=rs_name, data=melted_data, palette=genotype_colors.values(), inner='quartile', ax=ax)\n",
    "\n",
    "    # Set chart title and labels\n",
    "    ax.set_title(f'Violin Plot - PCA Values for All Genotypes for {rs_name}')\n",
    "    ax.set_xlabel('Principal Components')\n",
    "    ax.set_ylabel('PCA Values')\n",
    "    ax.set_xticks(range(0, 16))\n",
    "    ax.set_xticklabels(['PCA{}'.format(i) for i in range(1, 17)])\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "    ax = plt.gca()\n",
    "    ax.spines['left'].set_color('black')\n",
    "    ax.spines['bottom'].set_color('black')\n",
    "    # do not show the right and top spines\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['bottom'].set_linewidth(2)\n",
    "    ax.spines['left'].set_linewidth(2)\n",
    "    plt.grid(False)\n",
    "    \n",
    "    # Create a custom legend with the correct color-number combination\n",
    "    legend_elements = [plt.Line2D([0], [0], marker='o', color='w', label=f'Genotype {key}', markerfacecolor=value, markersize=10) for key, value in genotype_colors.items()]\n",
    "\n",
    "    # Add the custom legend\n",
    "    ax.legend(handles=legend_elements, title=rs_name, loc='upper right', bbox_to_anchor=(1.12, 1), labels=genotype_order,frameon=False)\n",
    "    plt.tight_layout()\n",
    "    # Save the combined plot\n",
    "    plt.savefig(f'./download/{rs_name}_All_Genotypes_Violin_Plot {pop_variable}.pdf', dpi=300, facecolor='w')\n",
    "def create_genotype_boxplot(merged_df, rs_name, pop_variable):\n",
    "    \"\"\"\n",
    "    Create a boxplot and swarmplot for genotypes.\n",
    "\n",
    "    Args:\n",
    "    merged_df (pd.DataFrame): DataFrame containing genotype and population data.\n",
    "    rs_name (str): Name of the genotype column.\n",
    "    pop_variable (str): Name of the population variable.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert genotype values to different colors\n",
    "    genotype_colors = {0: 'blue', 1: 'red', 2: 'orange'}\n",
    "\n",
    "    # Create a boxplot and swarmplot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(x='sex', y='age', data=merged_df, hue=rs_name, palette=genotype_colors)\n",
    "\n",
    "    # Add swarmplot (optional)\n",
    "    # sns.swarmplot(x='sex', y='age', data=all_data.sample(100), color='green', size=3, marker='o', label='Random Samples')\n",
    "\n",
    "    plt.title(f'Boxplot of Age by Sex and Genotype for {rs_name}')\n",
    "    plt.legend(frameon=False)\n",
    "    ax = plt.gca()\n",
    "    ax.spines['left'].set_color('black')\n",
    "    ax.spines['bottom'].set_color('black')\n",
    "    # do not show the right and top spines\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['bottom'].set_linewidth(2)\n",
    "    ax.spines['left'].set_linewidth(2)\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "    # Save the plot\n",
    "    plt.savefig(f'./download/{rs_name}_{pop_variable}_Boxplot_Swarmplot.pdf', dpi=300, facecolor='w')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "def read_data_information_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            data = file.read()\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        return \"File not found. Please make sure the file path is correct.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accumulate messages\n",
    "all_messages_first = \"\"\n",
    "bucket, genomic_location = initialize_hail_environment()\n",
    "# Output the bucket and genomic location\n",
    "print(\"Bucket:\", bucket)\n",
    "all_messages_first += f\"**Address of your Bucket:**\\n{bucket}\\n\\n\"\n",
    "print(\"Genomic Location:\", genomic_location)\n",
    "all_messages_first += f\"**Your Genomic Location that you using:**\\n{genomic_location}\\n\\n\"\n",
    "person_information_all, message = read_person_information()\n",
    "print(message)\n",
    "all_messages_first += f\"**Download information about the patient's conditions:**\\n{message}\\n\\n\"\n",
    "# print(person_information_all.head())\n",
    "person_df_all, message = read_person_information_df()\n",
    "print(message)\n",
    "all_messages_first += f\"**Download information about the patients:**\\n{message}\\n\\n\"\n",
    "# print(person_df_all.head())\n",
    "bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "copy_files_to_local(bucket)\n",
    "zip_code_socioeconomic_df, message = read_zip_code_socioeconomic_data()\n",
    "print(message)\n",
    "all_messages_first+= f\"**Download Zip-Code information about the patients:**\\n{message}\\n\\n\"\n",
    "# print(zip_code_socioeconomic_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Your Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test variables and information for pheWAS if neaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_messages = \"\"\n",
    "all_messages+=all_messages_first\n",
    "rs_name = 'rs439358' # SNP's Name \n",
    "rs_position = 'chr19:44908683-44908684' \n",
    "sex = 'None'  # Choose the sex variable ('Male', 'Female', or None)\n",
    "pop_variable = 'all'  # Choose the population variable ['afr', 'amr', 'eas','eur', 'mid', 'sas', 'all']\n",
    "ethnicity = 'None'  # Choose the ethnicity ('Hispanic or Latino' or 'Not Hispanic or Latino'), or None for classic run\n",
    "reference_allele= None #None\n",
    "alternative_allele= None\n",
    "GQ_threshold=20\n",
    "phecode_min=0\n",
    "icd9cm=True\n",
    "icd10cm=True\n",
    "all_messages += f\"**Population Information:** : ** {pop_variable} **\\n\\n\"\n",
    "# Print the text variable\n",
    "print(all_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_df, person_information, race_counts, hispanic_counts, population, race_counts_message, hispanic_counts_message, population_message, max_probability_message = run_analysis()\n",
    "print(race_counts_message)\n",
    "print(hispanic_counts_message)\n",
    "print(population_message)\n",
    "print(max_probability_message)\n",
    "all_messages += f\"**Race Counts:**\\n{race_counts_message}\\n\\n\"\n",
    "all_messages += f\"**Hispanic Counts:**\\n{hispanic_counts_message}\\n\\n\"\n",
    "all_messages += f\"**Population Message:**\\n{population_message}\\n\\n\"\n",
    "all_messages += f\"**Max Probability Message:**\\n{max_probability_message}\\n\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## do some filtering in the patients information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the common person_id values\n",
    "common_ids = set(person_df_all['person_id']).intersection(set(person_information['person_id']))\n",
    "\n",
    "# Filter both dataframes to keep only rows with common person_id\n",
    "person_df_all_filtered = person_df_all[person_df_all['person_id'].isin(common_ids)]\n",
    "person_information_filtered = person_information[person_information['person_id'].isin(common_ids)]\n",
    "\n",
    "# Optional: Sort the filtered dataframes again by person_id\n",
    "person_df_all_filtered = person_df_all_filtered.sort_values(by='person_id', ascending=True)\n",
    "person_information_filtered = person_information_filtered.sort_values(by='person_id', ascending=True)\n",
    "# # Display results\n",
    "# print(person_df_all_filtered)\n",
    "# print(person_information_filtered)\n",
    "# print(population.columns)\n",
    "# print(population)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## copy the dataframes to keep the originals the same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_df_all = person_df_all_filtered.copy()\n",
    "person_information = person_information_filtered.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read bacteria information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def read_gram_positive_data():\n",
    "    # This query represents dataset \"gram-positive\" for domain \"condition\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "    dataset_67733641_condition_sql = \"\"\"\n",
    "        SELECT\n",
    "            c_occurrence.person_id,\n",
    "            c_occurrence.condition_concept_id,\n",
    "            c_standard_concept.concept_name as standard_concept_name,\n",
    "            c_standard_concept.concept_code as standard_concept_code,\n",
    "            c_standard_concept.vocabulary_id as standard_vocabulary,\n",
    "            c_occurrence.condition_start_datetime,\n",
    "            c_occurrence.condition_end_datetime,\n",
    "            c_occurrence.condition_type_concept_id,\n",
    "            c_type.concept_name as condition_type_concept_name,\n",
    "            c_occurrence.stop_reason,\n",
    "            c_occurrence.visit_occurrence_id,\n",
    "            visit.concept_name as visit_occurrence_concept_name,\n",
    "            c_occurrence.condition_source_value,\n",
    "            c_occurrence.condition_source_concept_id,\n",
    "            c_source_concept.concept_name as source_concept_name,\n",
    "            c_source_concept.concept_code as source_concept_code,\n",
    "            c_source_concept.vocabulary_id as source_vocabulary,\n",
    "            c_occurrence.condition_status_source_value,\n",
    "            c_occurrence.condition_status_concept_id,\n",
    "            c_status.concept_name as condition_status_concept_name \n",
    "        FROM\n",
    "            ( SELECT\n",
    "                * \n",
    "            FROM\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".condition_occurrence` c_occurrence \n",
    "            WHERE\n",
    "                (\n",
    "                    condition_concept_id IN (SELECT\n",
    "                        DISTINCT c.concept_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                    JOIN\n",
    "                        (SELECT\n",
    "                            CAST(cr.id as string) AS id       \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "                        WHERE\n",
    "                            concept_id IN (37116366, 4111261, 4161193, 4248801, 43530753)       \n",
    "                            AND full_text LIKE '%_rank1]%'      ) a \n",
    "                            ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                            OR c.path LIKE CONCAT('%.', a.id) \n",
    "                            OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                            OR c.path = a.id) \n",
    "                    WHERE\n",
    "                        is_standard = 1 \n",
    "                        AND is_selectable = 1)\n",
    "                )) c_occurrence \n",
    "        LEFT JOIN\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_standard_concept \n",
    "                ON c_occurrence.condition_concept_id = c_standard_concept.concept_id \n",
    "        LEFT JOIN\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_type \n",
    "                ON c_occurrence.condition_type_concept_id = c_type.concept_id \n",
    "        LEFT JOIN\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".visit_occurrence` v \n",
    "                ON c_occurrence.visit_occurrence_id = v.visit_occurrence_id \n",
    "        LEFT JOIN\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` visit \n",
    "                ON v.visit_concept_id = visit.concept_id \n",
    "        LEFT JOIN\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_source_concept \n",
    "                ON c_occurrence.condition_source_concept_id = c_source_concept.concept_id \n",
    "        LEFT JOIN\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_status \n",
    "                ON c_occurrence.condition_status_concept_id = c_status.concept_id\"\"\"\n",
    "    \n",
    "    dataset_67733641_condition_df = pd.read_gbq(\n",
    "        dataset_67733641_condition_sql,\n",
    "        dialect=\"standard\",\n",
    "        use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "        progress_bar_type=\"tqdm_notebook\")\n",
    "# Filter the gram-positive data based on specific conditions\n",
    "    gram_positive = dataset_67733641_condition_df.dropna(subset=['source_vocabulary','source_concept_name'])\n",
    "    gram_positive = gram_positive[gram_positive['source_vocabulary'].str.contains('ICD9CM|ICD10CM', case=False)]\n",
    "    gram_positive_filtered = gram_positive.copy()\n",
    "#     gram_positive_filtered = gram_positive[gram_positive['source_concept_name'].str.contains('gram', case=False)]\n",
    "\n",
    "    # Extract information about the gram-positive dataset\n",
    "    gram_positive_unique_person_ids = gram_positive_filtered['person_id'].nunique()\n",
    "    gram_positive_unique_concept_codes = gram_positive_filtered['source_concept_code'].nunique()\n",
    "    gram_positive_unique_codes_list = gram_positive_filtered['source_concept_code'].unique()\n",
    "\n",
    "    # Display the gram-positive data and information\n",
    "    print(\"Gram-positive dataset:\")\n",
    "    print(\"Number of unique person_ids:\", gram_positive_unique_person_ids)\n",
    "    print(\"Number of unique source_concept_codes:\", gram_positive_unique_concept_codes)\n",
    "    print(\"Unique source_concept_codes:\", ', '.join(gram_positive_unique_codes_list))\n",
    "    print(gram_positive_filtered)\n",
    "    return gram_positive_filtered, gram_positive_unique_person_ids, gram_positive_unique_concept_codes, gram_positive_unique_codes_list\n",
    "# Call the function to read gram-positive data\n",
    "gram_positive_data = read_gram_positive_data()\n",
    "# gram_positive_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def gram_negative_data():\n",
    "    # This query represents dataset \"Gram-negative bacterial\" for domain \"condition\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "    dataset_41959053_condition_sql = \"\"\"\n",
    "        SELECT\n",
    "            c_occurrence.person_id,\n",
    "            c_occurrence.condition_concept_id,\n",
    "            c_standard_concept.concept_name as standard_concept_name,\n",
    "            c_standard_concept.concept_code as standard_concept_code,\n",
    "            c_standard_concept.vocabulary_id as standard_vocabulary,\n",
    "            c_occurrence.condition_start_datetime,\n",
    "            c_occurrence.condition_end_datetime,\n",
    "            c_occurrence.condition_type_concept_id,\n",
    "            c_type.concept_name as condition_type_concept_name,\n",
    "            c_occurrence.stop_reason,\n",
    "            c_occurrence.visit_occurrence_id,\n",
    "            visit.concept_name as visit_occurrence_concept_name,\n",
    "            c_occurrence.condition_source_value,\n",
    "            c_occurrence.condition_source_concept_id,\n",
    "            c_source_concept.concept_name as source_concept_name,\n",
    "            c_source_concept.concept_code as source_concept_code,\n",
    "            c_source_concept.vocabulary_id as source_vocabulary,\n",
    "            c_occurrence.condition_status_source_value,\n",
    "            c_occurrence.condition_status_concept_id,\n",
    "            c_status.concept_name as condition_status_concept_name \n",
    "        FROM\n",
    "            ( SELECT\n",
    "                * \n",
    "            FROM\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".condition_occurrence` c_occurrence \n",
    "            WHERE\n",
    "                (\n",
    "                    condition_concept_id IN (\n",
    "                        SELECT\n",
    "                            DISTINCT c.concept_id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                        JOIN\n",
    "                            (\n",
    "                                SELECT\n",
    "                                    CAST(cr.id as string) AS id       \n",
    "                                FROM\n",
    "                                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "                                WHERE\n",
    "                                    concept_id IN (\n",
    "                                        258180, 40493038, 4214520, 4252534, 4253013, 43530750, 435742, 438133, 46274129\n",
    "                                    )       \n",
    "                                    AND full_text LIKE '%_rank1]%'      \n",
    "                            ) a \n",
    "                                ON (\n",
    "                                    c.path LIKE CONCAT('%.',\n",
    "                                a.id,\n",
    "                                '.%') \n",
    "                                OR c.path LIKE CONCAT('%.',\n",
    "                                a.id) \n",
    "                                OR c.path LIKE CONCAT(a.id,\n",
    "                                '.%') \n",
    "                                OR c.path = a.id) \n",
    "                            WHERE\n",
    "                                is_standard = 1 \n",
    "                                AND is_selectable = 1\n",
    "                            )\n",
    "                    )  \n",
    "                    AND (\n",
    "                        c_occurrence.PERSON_ID IN (\n",
    "                            SELECT\n",
    "                                distinct person_id  \n",
    "                            FROM\n",
    "                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "                            WHERE\n",
    "                                cb_search_person.person_id IN (\n",
    "                                    SELECT\n",
    "                                        person_id \n",
    "                                    FROM\n",
    "                                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` p \n",
    "                                    WHERE\n",
    "                                        has_ehr_data = 1 \n",
    "                                ) \n",
    "                            )\n",
    "                    )\n",
    "                ) c_occurrence \n",
    "            LEFT JOIN\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_standard_concept \n",
    "                    ON c_occurrence.condition_concept_id = c_standard_concept.concept_id \n",
    "            LEFT JOIN\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_type \n",
    "                    ON c_occurrence.condition_type_concept_id = c_type.concept_id \n",
    "            LEFT JOIN\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".visit_occurrence` v \n",
    "                    ON c_occurrence.visit_occurrence_id = v.visit_occurrence_id \n",
    "            LEFT JOIN\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` visit \n",
    "                    ON v.visit_concept_id = visit.concept_id \n",
    "            LEFT JOIN\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_source_concept \n",
    "                    ON c_occurrence.condition_source_concept_id = c_source_concept.concept_id \n",
    "            LEFT JOIN\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_status \n",
    "                    ON c_occurrence.condition_status_concept_id = c_status.concept_id\"\"\"\n",
    "\n",
    "    gram_negative_df = pd.read_gbq(\n",
    "        dataset_41959053_condition_sql,\n",
    "        dialect=\"standard\",\n",
    "        use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "        progress_bar_type=\"tqdm_notebook\")\n",
    "   \n",
    "    return gram_negative_df\n",
    "gram_negative_data = gram_negative_data()\n",
    "# gram_negative_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Filter the E. coli data based on specific conditions\n",
    "gram_negative = gram_negative_data.dropna(subset=['source_vocabulary','source_concept_name'])\n",
    "gram_negative = gram_negative[gram_negative['source_vocabulary'].str.contains('ICD9CM|ICD10CM', case=False)]\n",
    "gram_negative_data_filtered =gram_negative.copy()\n",
    "# gram_negative_data_filtered = gram_negative_data_filtered[gram_negative_data_filtered['source_concept_name'].str.contains('Gram', case=False)]\n",
    "# gram_negative_data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract information about the E. coli dataset\n",
    "gram_negative_unique_person_ids = gram_negative_data_filtered['person_id'].nunique()\n",
    "gram_negative_unique_concept_codes = gram_negative_data_filtered['source_concept_code'].nunique()\n",
    "gram_negative_unique_codes_list = gram_negative_data_filtered['source_concept_code'].unique()\n",
    "\n",
    "# # Display the E. coli data and information\n",
    "# print(\"Escherichia coli dataset:\")\n",
    "# print(\"Number of unique person_ids:\", gram_negative_unique_person_ids)\n",
    "# print(\"Number of unique source_concept_codes:\", gram_negative_unique_concept_codes)\n",
    "# print(\"Unique source_concept_codes:\", ', '.join(gram_negative_unique_codes_list))\n",
    "# print(gram_negative_data_filtered)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# read the bacteria information and filter the data"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     14
    ]
   },
   "outputs": [],
   "source": [
    "gram_positive_icd_info = [\n",
    "    {'ICD-9': ['008.45', '041.83'], 'ICD-10': ['A04.7', 'B96.89'], 'Bacteria': 'Clostridium difficile'},\n",
    "    {'ICD-9': ['041.04', '041.82'], 'ICD-10': ['B95.2', 'B96.81'], 'Bacteria': 'Enterococcus faecalis'},\n",
    "    {'ICD-9': ['022.1', '022.2', '022.3'], 'ICD-10': ['A22.1', 'A22.2', 'A22.3'], 'Bacteria': 'Bacillus anthracis'},\n",
    "    {'ICD-9': ['027.0', '027.8', '027.9'], 'ICD-10': ['A32.0', 'A32.1', 'A32.9'], 'Bacteria': 'Listeria monocytogenes'},\n",
    "    {'ICD-9': ['032.0', '032.1', '032.2'], 'ICD-10': ['A36.0', 'A36.1', 'A36.2'], 'Bacteria': 'Corynebacterium diphtheriae'},\n",
    "    {'ICD-9': ['037.0', '037.9'], 'ICD-10': ['A35', 'A34'], 'Bacteria': 'Clostridium tetani'},\n",
    "    {'ICD-9': ['041.04', '041.82'], 'ICD-10': ['B95.0', 'B96.81'], 'Bacteria': 'Lactobacillus acidophilus'},\n",
    "    {'ICD-9': ['039.1', '039.8'], 'ICD-10': ['B95.89', 'A43.8'], 'Bacteria': 'Nocardia species'},\n",
    "    {'ICD-9': ['011.0', '011.1', '011.2'], 'ICD-10': ['A15.0', 'A15.1', 'A15.2'], 'Bacteria': 'Mycobacterium tuberculosis'},\n",
    "    {'ICD-9': ['039.0', '039.3', '039.9'], 'ICD-10': ['A42.0', 'A42.3', 'A42.9'], 'Bacteria': 'Actinomyces israelii'}\n",
    "]\n",
    "gram_positive_icd_info\n",
    "gram_negative_icd_info = [\n",
    "    {'ICD-9': ['041.3', '482.2'], 'ICD-10': ['B96.2', 'J15.0'], 'Bacteria': 'Klebsiella pneumoniae'},\n",
    "    {'ICD-9': ['041.49', '482.84'], 'ICD-10': ['B96.2', 'A41.9'], 'Bacteria': 'Acinetobacter baumannii'},\n",
    "    {'ICD-9': ['098.0', '098.11', '098.12'], 'ICD-10': ['A54.0', 'A54.1', 'A54.2'], 'Bacteria': 'Neisseria gonorrhoeae'},\n",
    "    {'ICD-9': ['036.0', '036.1'], 'ICD-10': ['A39.0', 'A39.2'], 'Bacteria': 'Neisseria meningitidis'},\n",
    "    {'ICD-9': ['041.5', '482.2'], 'ICD-10': ['B96.3', 'J14'], 'Bacteria': 'Haemophilus influenzae'},\n",
    "    {'ICD-9': ['003.0', '003.1', '003.2'], 'ICD-10': ['A02.0', 'A02.1', 'A02.2'], 'Bacteria': 'Salmonella enterica'},\n",
    "    {'ICD-9': ['004.0', '004.1', '004.2'], 'ICD-10': ['A03.0', 'A03.1', 'A03.2'], 'Bacteria': 'Shigella species'},\n",
    "    {'ICD-9': ['041.4', '599.0'], 'ICD-10': ['N39.0', 'B96.4'], 'Bacteria': 'Proteus mirabilis'},\n",
    "    {'ICD-9': ['008.43', '041.85'], 'ICD-10': ['A04.5', 'B96.82'], 'Bacteria': 'Campylobacter jejuni'},\n",
    "    {'ICD-9': ['020.0', '020.1', '020.2'], 'ICD-10': ['A20.0', 'A20.1', 'A20.2'], 'Bacteria': 'Yersinia pestis'}\n",
    "]\n",
    "# gram_negative_icd_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of ICD-9 and ICD-10 codes for gram-positive and gram-negative bacteria\n",
    "gram_positive_icd_9 = [code for entry in gram_positive_icd_info for code in entry['ICD-9']]\n",
    "gram_positive_icd_10 = [code for entry in gram_positive_icd_info for code in entry['ICD-10']]\n",
    "\n",
    "gram_negative_icd_9 = [code for entry in gram_negative_icd_info for code in entry['ICD-9']]\n",
    "gram_negative_icd_10 = [code for entry in gram_negative_icd_info for code in entry['ICD-10']]\n",
    "\n",
    "# Filter gram_positive_data\n",
    "gram_positive_data = gram_positive_data[0][gram_positive_data[0]['source_concept_code'].isin(gram_positive_icd_9 + gram_positive_icd_10)]\n",
    "# gram_positive_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter gram_negative_data_filtered\n",
    "gram_negative_data_filtered = gram_negative_data_filtered[gram_negative_data_filtered['source_concept_code'].isin(gram_negative_icd_9 + gram_negative_icd_10)]\n",
    "# gram_negative_data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gram_positive_data_filtered =gram_positive_data.copy()\n",
    "gram_negative_data = gram_negative_data_filtered.copy()\n",
    "gram_positive_unique_person_ids = gram_positive_data['person_id'].nunique()\n",
    "gram_negative_unique_person_ids = gram_negative_data_filtered['person_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def read_ecoli_data():\n",
    "    # Define the SQL query\n",
    "    dataset_11549975_condition_sql = \"\"\"\n",
    "        SELECT\n",
    "            c_occurrence.person_id,\n",
    "            c_occurrence.condition_concept_id,\n",
    "            c_standard_concept.concept_name as standard_concept_name,\n",
    "            c_standard_concept.concept_code as standard_concept_code,\n",
    "            c_standard_concept.vocabulary_id as standard_vocabulary,\n",
    "            c_occurrence.condition_start_datetime,\n",
    "            c_occurrence.condition_end_datetime,\n",
    "            c_occurrence.condition_type_concept_id,\n",
    "            c_type.concept_name as condition_type_concept_name,\n",
    "            c_occurrence.stop_reason,\n",
    "            c_occurrence.visit_occurrence_id,\n",
    "            visit.concept_name as visit_occurrence_concept_name,\n",
    "            c_occurrence.condition_source_value,\n",
    "            c_occurrence.condition_source_concept_id,\n",
    "            c_source_concept.concept_name as source_concept_name,\n",
    "            c_source_concept.concept_code as source_concept_code,\n",
    "            c_source_concept.vocabulary_id as source_vocabulary,\n",
    "            c_occurrence.condition_status_source_value,\n",
    "            c_occurrence.condition_status_concept_id,\n",
    "            c_status.concept_name as condition_status_concept_name \n",
    "        FROM\n",
    "            ( SELECT\n",
    "                * \n",
    "            FROM\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".condition_occurrence` c_occurrence \n",
    "            WHERE\n",
    "                (\n",
    "                    condition_concept_id IN (\n",
    "                        SELECT\n",
    "                            DISTINCT c.concept_id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                        JOIN\n",
    "                            (\n",
    "                                SELECT\n",
    "                                    CAST(cr.id as string) AS id       \n",
    "                                FROM\n",
    "                                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "                                WHERE\n",
    "                                    concept_id IN (\n",
    "                                        192815, 260430, 36715935, 40487064, 4070038, 4071727, 4116491, 4345206, 4345207, 4345208, 4345354, 4345355, 440320, 45757389, 45757690\n",
    "                                    )       \n",
    "                                    AND full_text LIKE '%_rank1]%'      \n",
    "                            ) a \n",
    "                                ON (\n",
    "                                    c.path LIKE CONCAT('%.',\n",
    "                                a.id,\n",
    "                                '.%') \n",
    "                                OR c.path LIKE CONCAT('%.',\n",
    "                                a.id) \n",
    "                                OR c.path LIKE CONCAT(a.id,\n",
    "                                '.%') \n",
    "                                OR c.path = a.id) \n",
    "                            WHERE\n",
    "                                is_standard = 1 \n",
    "                                AND is_selectable = 1\n",
    "                            )\n",
    "                    )  \n",
    "                    AND (\n",
    "                        c_occurrence.PERSON_ID IN (\n",
    "                            SELECT\n",
    "                                distinct person_id  \n",
    "                            FROM\n",
    "                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "                            WHERE\n",
    "                                cb_search_person.person_id IN (\n",
    "                                    SELECT\n",
    "                                        person_id \n",
    "                                    FROM\n",
    "                                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` p \n",
    "                                    WHERE\n",
    "                                        has_ehr_data = 1 \n",
    "                                ) \n",
    "                            )\n",
    "                    )\n",
    "                ) c_occurrence \n",
    "            LEFT JOIN\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_standard_concept \n",
    "                    ON c_occurrence.condition_concept_id = c_standard_concept.concept_id \n",
    "            LEFT JOIN\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_type \n",
    "                    ON c_occurrence.condition_type_concept_id = c_type.concept_id \n",
    "            LEFT JOIN\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".visit_occurrence` v \n",
    "                    ON c_occurrence.visit_occurrence_id = v.visit_occurrence_id \n",
    "            LEFT JOIN\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` visit \n",
    "                    ON v.visit_concept_id = visit.concept_id \n",
    "            LEFT JOIN\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_source_concept \n",
    "                    ON c_occurrence.condition_source_concept_id = c_source_concept.concept_id \n",
    "            LEFT JOIN\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_status \n",
    "                    ON c_occurrence.condition_status_concept_id = c_status.concept_id\"\"\"\n",
    "\n",
    "    # Execute the SQL query and return the DataFrame\n",
    "    ecoli_df = pd.read_gbq(\n",
    "        dataset_11549975_condition_sql,\n",
    "        dialect=\"standard\",\n",
    "        use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "        progress_bar_type=\"tqdm_notebook\")\n",
    "    \n",
    "    return ecoli_df\n",
    "# Call the function to read E. coli data\n",
    "ecoli_data = read_ecoli_data()\n",
    "# Filter the E. coli data based on specific conditions\n",
    "ecoli_data = ecoli_data.dropna(subset=['source_vocabulary','source_concept_name'])\n",
    "\n",
    "ecoli_data_filtered = ecoli_data[ecoli_data['source_vocabulary'].str.contains('ICD9CM|ICD10CM', case=False)]\n",
    "ecoli_data_filtered = ecoli_data_filtered[ecoli_data_filtered['source_concept_name'].str.contains('Escherichia coli', case=False)]\n",
    "\n",
    "# Extract information about the E. coli dataset\n",
    "ecoli_unique_person_ids = ecoli_data_filtered['person_id'].nunique()\n",
    "ecoli_unique_concept_codes = ecoli_data_filtered['source_concept_code'].nunique()\n",
    "ecoli_unique_codes_list = ecoli_data_filtered['source_concept_code'].unique()\n",
    "ecoli_data=ecoli_data_filtered.copy()\n",
    "ecoli_unique_name_list =ecoli_data_filtered['source_concept_name'].unique()\n",
    "# print(\"Unique source_concept_name:\", ', '.join(ecoli_unique_name_list))\n",
    "# # Display the E. coli data and information\n",
    "# print(\"Escherichia coli dataset:\")\n",
    "# print(\"Number of unique person_ids:\", ecoli_unique_person_ids)\n",
    "# print(\"Number of unique source_concept_codes:\", ecoli_unique_concept_codes)\n",
    "# print(\"Unique source_concept_codes:\", ', '.join(ecoli_unique_codes_list))\n",
    "# print(ecoli_data_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def read_staphylococcus_data():\n",
    "    # Define the SQL query\n",
    "    dataset_54672821_condition_sql = \"\"\"\n",
    "        SELECT\n",
    "            c_occurrence.person_id,\n",
    "            c_occurrence.condition_concept_id,\n",
    "            c_standard_concept.concept_name as standard_concept_name,\n",
    "            c_standard_concept.concept_code as standard_concept_code,\n",
    "            c_standard_concept.vocabulary_id as standard_vocabulary,\n",
    "            c_occurrence.condition_start_datetime,\n",
    "            c_occurrence.condition_end_datetime,\n",
    "            c_occurrence.condition_type_concept_id,\n",
    "            c_type.concept_name as condition_type_concept_name,\n",
    "            c_occurrence.stop_reason,\n",
    "            c_occurrence.visit_occurrence_id,\n",
    "            visit.concept_name as visit_occurrence_concept_name,\n",
    "            c_occurrence.condition_source_value,\n",
    "            c_occurrence.condition_source_concept_id,\n",
    "            c_source_concept.concept_name as source_concept_name,\n",
    "            c_source_concept.concept_code as source_concept_code,\n",
    "            c_source_concept.vocabulary_id as source_vocabulary,\n",
    "            c_occurrence.condition_status_source_value,\n",
    "            c_occurrence.condition_status_concept_id,\n",
    "            c_status.concept_name as condition_status_concept_name \n",
    "        FROM\n",
    "            ( SELECT\n",
    "                * \n",
    "            FROM\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".condition_occurrence` c_occurrence \n",
    "            WHERE\n",
    "                (\n",
    "                    condition_source_concept_id IN (\n",
    "                        SELECT\n",
    "                            DISTINCT c.concept_id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                        JOIN\n",
    "                            (\n",
    "                                SELECT\n",
    "                                    CAST(cr.id as string) AS id       \n",
    "                                FROM\n",
    "                                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "                                WHERE\n",
    "                                    concept_id IN (\n",
    "                                        1567453, 35205549, 35205550, 35206024, 35206025, 35206026, 35206027, 35206028, 35206029, 35206030, 35206031, 35206032, 35210490, 44819357, 44820361, 44823143, 44823773, 44823971, 44825094, 44825143, 44825147, 44825468, 44827488, 44829006, 44830920, 44834766, 44835610, 44835978, 45532833, 45533545, 45537779, 45552181, 45557620, 45567261, 45571485, 45576140, 45581112, 45590710, 45591550, 45600413, 45601122\n",
    "                                    )       \n",
    "                                    AND full_text LIKE '%_rank1]%'      \n",
    "                            ) a \n",
    "                                ON (\n",
    "                                    c.path LIKE CONCAT('%.',\n",
    "                                a.id,\n",
    "                                '.%') \n",
    "                                OR c.path LIKE CONCAT('%.',\n",
    "                                a.id) \n",
    "                                OR c.path LIKE CONCAT(a.id,\n",
    "                                '.%') \n",
    "                                OR c.path = a.id) \n",
    "                            WHERE\n",
    "                                is_standard = 0 \n",
    "                                AND is_selectable = 1\n",
    "                            )\n",
    "                    )  \n",
    "                    AND (\n",
    "                        c_occurrence.PERSON_ID IN (\n",
    "                            SELECT\n",
    "                                distinct person_id  \n",
    "                            FROM\n",
    "                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "                            WHERE\n",
    "                                cb_search_person.person_id IN (\n",
    "                                    SELECT\n",
    "                                        person_id \n",
    "                                    FROM\n",
    "                                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` p \n",
    "                                    WHERE\n",
    "                                        has_ehr_data = 1 \n",
    "                                ) \n",
    "                            )\n",
    "                    )\n",
    "                ) c_occurrence \n",
    "            LEFT JOIN\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_standard_concept \n",
    "                    ON c_occurrence.condition_concept_id = c_standard_concept.concept_id \n",
    "            LEFT JOIN\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_type \n",
    "                    ON c_occurrence.condition_type_concept_id = c_type.concept_id \n",
    "            LEFT JOIN\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".visit_occurrence` v \n",
    "                    ON c_occurrence.visit_occurrence_id = v.visit_occurrence_id \n",
    "            LEFT JOIN\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` visit \n",
    "                    ON v.visit_concept_id = visit.concept_id \n",
    "            LEFT JOIN\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_source_concept \n",
    "                    ON c_occurrence.condition_source_concept_id = c_source_concept.concept_id \n",
    "            LEFT JOIN\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_status \n",
    "                    ON c_occurrence.condition_status_concept_id = c_status.concept_id\"\"\"\n",
    "\n",
    "    # Execute the SQL query and return the DataFrame\n",
    "    staphylococcus_df = pd.read_gbq(\n",
    "        dataset_54672821_condition_sql,\n",
    "        dialect=\"standard\",\n",
    "        use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "        progress_bar_type=\"tqdm_notebook\")\n",
    "    \n",
    "    return staphylococcus_df\n",
    "# Call the function to read staphylococcus data\n",
    "staphylococcus_data = read_staphylococcus_data()\n",
    "\n",
    "# Filter the staphylococcus data based on specific conditions\n",
    "staphylococcus_data = staphylococcus_data[staphylococcus_data['source_vocabulary'].str.contains(('ICD9CM|ICD10CM'), case=False)]\n",
    "staphylococcus_data = staphylococcus_data[staphylococcus_data['source_concept_name'].str.contains('staphylococcus', case=False)]\n",
    "\n",
    "# Extract information about the staphylococcus dataset\n",
    "staphylococcus_unique_person_ids = staphylococcus_data['person_id'].nunique()\n",
    "staphylococcus_unique_concept_codes = staphylococcus_data['source_concept_code'].nunique()\n",
    "staphylococcus_unique_codes_list = staphylococcus_data['source_concept_code'].unique()\n",
    "\n",
    "# # Display the staphylococcus data and information\n",
    "# print(\"Staphylococcus dataset:\")\n",
    "# print(\"Number of unique person_ids:\", staphylococcus_unique_person_ids)\n",
    "# print(\"Number of unique source_concept_codes:\", staphylococcus_unique_concept_codes)\n",
    "# print(\"Unique source_concept_codes:\", ', '.join(staphylococcus_unique_codes_list))\n",
    "# staphylococcus_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def read_retrovirus_data():\n",
    "    # Define the SQL query for Retrovirus dataset\n",
    "    dataset_25209559_condition_sql = \"\"\"\n",
    "        SELECT\n",
    "            c_occurrence.person_id,\n",
    "            c_occurrence.condition_concept_id,\n",
    "            c_standard_concept.concept_name as standard_concept_name,\n",
    "            c_standard_concept.concept_code as standard_concept_code,\n",
    "            c_standard_concept.vocabulary_id as standard_vocabulary,\n",
    "            c_occurrence.condition_start_datetime,\n",
    "            c_occurrence.condition_end_datetime,\n",
    "            c_occurrence.condition_type_concept_id,\n",
    "            c_type.concept_name as condition_type_concept_name,\n",
    "            c_occurrence.stop_reason,\n",
    "            c_occurrence.visit_occurrence_id,\n",
    "            visit.concept_name as visit_occurrence_concept_name,\n",
    "            c_occurrence.condition_source_value,\n",
    "            c_occurrence.condition_source_concept_id,\n",
    "            c_source_concept.concept_name as source_concept_name,\n",
    "            c_source_concept.concept_code as source_concept_code,\n",
    "            c_source_concept.vocabulary_id as source_vocabulary,\n",
    "            c_occurrence.condition_status_source_value,\n",
    "            c_occurrence.condition_status_concept_id,\n",
    "            c_status.concept_name as condition_status_concept_name \n",
    "        FROM\n",
    "            ( SELECT\n",
    "                * \n",
    "            FROM\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".condition_occurrence` c_occurrence \n",
    "            WHERE\n",
    "                (\n",
    "                    condition_concept_id IN (\n",
    "                        SELECT\n",
    "                            DISTINCT c.concept_id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                        JOIN\n",
    "                            (\n",
    "                                SELECT\n",
    "                                    CAST(cr.id as string) AS id       \n",
    "                                FROM\n",
    "                                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "                                WHERE\n",
    "                                    concept_id IN (\n",
    "                                        196484, 196486, 37019071, 4034870, 4158313, 433694\n",
    "                                    )       \n",
    "                                    AND full_text LIKE '%_rank1]%'      \n",
    "                            ) a \n",
    "                                ON (\n",
    "                                    c.path LIKE CONCAT('%.',\n",
    "                                a.id,\n",
    "                                '.%') \n",
    "                                OR c.path LIKE CONCAT('%.',\n",
    "                                a.id) \n",
    "                                OR c.path LIKE CONCAT(a.id,\n",
    "                                '.%') \n",
    "                                OR c.path = a.id) \n",
    "                            WHERE\n",
    "                                is_standard = 1 \n",
    "                                AND is_selectable = 1\n",
    "                            ) \n",
    "                            OR  condition_source_concept_id IN (\n",
    "                                SELECT\n",
    "                                    DISTINCT c.concept_id \n",
    "                                FROM\n",
    "                                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                                JOIN\n",
    "                                    (\n",
    "                                        SELECT\n",
    "                                            CAST(cr.id as string) AS id       \n",
    "                                        FROM\n",
    "                                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "                                        WHERE\n",
    "                                            concept_id IN (\n",
    "                                                35205795, 44819384, 44821693, 44822121, 44828699, 44832092, 44832093, 44836099, 45539139, 45543962, 45553515, 45561777, 45566568, 45601817, 45605254, 45605255\n",
    "                                            )       \n",
    "                                            AND full_text LIKE '%_rank1]%'      \n",
    "                                    ) a \n",
    "                                        ON (\n",
    "                                            c.path LIKE CONCAT('%.',\n",
    "                                        a.id,\n",
    "                                        '.%') \n",
    "                                        OR c.path LIKE CONCAT('%.',\n",
    "                                        a.id) \n",
    "                                        OR c.path LIKE CONCAT(a.id,\n",
    "                                        '.%') \n",
    "                                        OR c.path = a.id) \n",
    "                                    WHERE\n",
    "                                        is_standard = 0 \n",
    "                                        AND is_selectable = 1\n",
    "                                    )\n",
    "                            )  \n",
    "                            AND (\n",
    "                                c_occurrence.PERSON_ID IN (\n",
    "                                    SELECT\n",
    "                                        distinct person_id  \n",
    "                                    FROM\n",
    "                                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "                                    WHERE\n",
    "                                        cb_search_person.person_id IN (\n",
    "                                            SELECT\n",
    "                                                person_id \n",
    "                                            FROM\n",
    "                                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` p \n",
    "                                            WHERE\n",
    "                                                has_ehr_data = 1 \n",
    "                                        ) \n",
    "                                    )\n",
    "                            )\n",
    "                        ) c_occurrence \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_standard_concept \n",
    "                            ON c_occurrence.condition_concept_id = c_standard_concept.concept_id \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_type \n",
    "                            ON c_occurrence.condition_type_concept_id = c_type.concept_id \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".visit_occurrence` v \n",
    "                            ON c_occurrence.visit_occurrence_id = v.visit_occurrence_id \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` visit \n",
    "                            ON v.visit_concept_id = visit.concept_id \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_source_concept \n",
    "                            ON c_occurrence.condition_source_concept_id = c_source_concept.concept_id \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_status \n",
    "                            ON c_occurrence.condition_status_concept_id = c_status.concept_id\"\"\"\n",
    "\n",
    "    # Execute the SQL query and return the DataFrame\n",
    "    retrovirus_df = pd.read_gbq(\n",
    "        dataset_25209559_condition_sql,\n",
    "        dialect=\"standard\",\n",
    "        use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "        progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "    # Select desired columns\n",
    "    selected_columns = ['person_id', 'source_concept_code', 'source_concept_name', 'source_vocabulary', 'condition_start_datetime']\n",
    "\n",
    "    # Create a boolean mask to filter out rows with NaN or NA values in the 'source_vocabulary' column\n",
    "    mask = retrovirus_df['source_vocabulary'].notna()\n",
    "\n",
    "    # Apply the boolean mask to filter the DataFrame\n",
    "    retrovirus_filtered = retrovirus_df[selected_columns][mask]\n",
    "\n",
    "    # Count the number of unique person_ids and unique source_concept_codes for Retrovirus dataset\n",
    "    retrovirus_unique_person_ids = retrovirus_filtered['person_id'].nunique()\n",
    "    retrovirus_unique_concept_codes = retrovirus_filtered['source_concept_code'].nunique()\n",
    "    retrovirus_unique_codes_list = retrovirus_filtered['source_concept_code'].unique()\n",
    "\n",
    "    # Construct the message\n",
    "    retrovirus_message = f\"Retrovirus dataset:\\nNumber of unique person_ids: {retrovirus_unique_person_ids}\\nNumber of unique source_concept_codes: {retrovirus_unique_concept_codes}\\nUnique source_concept_codes: {', '.join(retrovirus_unique_codes_list)}\"\n",
    "\n",
    "    # Return the filtered DataFrame and message\n",
    "    return retrovirus_filtered, retrovirus_message, retrovirus_unique_person_ids, retrovirus_unique_concept_codes, retrovirus_unique_codes_list\n",
    "retrovirus_data = read_retrovirus_data()\n",
    "# retrovirus_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the Retrovirus data based on specific conditions\n",
    "retrovirus_data_filtered = retrovirus_data[0].dropna(subset=['source_vocabulary', 'source_concept_name'])\n",
    "retrovirus_data_filtered = retrovirus_data_filtered[retrovirus_data_filtered['source_vocabulary'].str.contains('ICD9CM|ICD10CM', case=False)]\n",
    "# retrovirus_data_filtered = retrovirus_data_filtered[retrovirus_data_filtered['source_concept_name'].str.contains('Retro', case=False)]\n",
    "\n",
    "# Extract information about the Retrovirus dataset\n",
    "retrovirus_unique_person_ids = retrovirus_data_filtered['person_id'].nunique()\n",
    "retrovirus_unique_concept_codes = retrovirus_data_filtered['source_concept_code'].nunique()\n",
    "retrovirus_unique_codes_list = retrovirus_data_filtered['source_concept_code'].unique()\n",
    "retrovirus_unique_name_list =retrovirus_data_filtered['source_concept_name'].unique()\n",
    "# print(\"Unique source_concept_name:\", ', '.join(retrovirus_unique_name_list))\n",
    "# # Display the Retrovirus data and information\n",
    "# print(\"Retrovirus dataset:\")\n",
    "# print(\"Number of unique person_ids:\", retrovirus_unique_person_ids)\n",
    "# print(\"Number of unique source_concept_codes:\", retrovirus_unique_concept_codes)\n",
    "# print(\"Unique source_concept_codes:\", ', '.join(retrovirus_unique_codes_list))\n",
    "\n",
    "# print(retrovirus_data_filtered)\n",
    "retrovirus_data=retrovirus_data_filtered.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     7,
     145
    ]
   },
   "outputs": [],
   "source": [
    "def read_data_information_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            data = file.read()\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        return \"File not found. Please make sure the file path is correct.\"\n",
    "def read_pseudomonas_data():\n",
    "    # Define the SQL query to retrieve the Pseudomonas dataset\n",
    "    dataset_13876108_condition_sql = \"\"\"\n",
    "        SELECT\n",
    "            c_occurrence.person_id,\n",
    "            c_occurrence.condition_concept_id,\n",
    "            c_standard_concept.concept_name as standard_concept_name,\n",
    "            c_standard_concept.concept_code as standard_concept_code,\n",
    "            c_standard_concept.vocabulary_id as standard_vocabulary,\n",
    "            c_occurrence.condition_start_datetime,\n",
    "            c_occurrence.condition_end_datetime,\n",
    "            c_occurrence.condition_type_concept_id,\n",
    "            c_type.concept_name as condition_type_concept_name,\n",
    "            c_occurrence.stop_reason,\n",
    "            c_occurrence.visit_occurrence_id,\n",
    "            visit.concept_name as visit_occurrence_concept_name,\n",
    "            c_occurrence.condition_source_value,\n",
    "            c_occurrence.condition_source_concept_id,\n",
    "            c_source_concept.concept_name as source_concept_name,\n",
    "            c_source_concept.concept_code as source_concept_code,\n",
    "            c_source_concept.vocabulary_id as source_vocabulary,\n",
    "            c_occurrence.condition_status_source_value,\n",
    "            c_occurrence.condition_status_concept_id,\n",
    "            c_status.concept_name as condition_status_concept_name \n",
    "        FROM\n",
    "            ( SELECT\n",
    "                * \n",
    "            FROM\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".condition_occurrence` c_occurrence \n",
    "            WHERE\n",
    "                (\n",
    "                    condition_concept_id IN (\n",
    "                        SELECT\n",
    "                            DISTINCT c.concept_id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                        JOIN\n",
    "                            (\n",
    "                                SELECT\n",
    "                                    CAST(cr.id as string) AS id       \n",
    "                                FROM\n",
    "                                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "                                WHERE\n",
    "                                    concept_id IN (\n",
    "                                        195462, 37016370, 4008261, 4145468, 437492, 438064, 443542\n",
    "                                    )       \n",
    "                                    AND full_text LIKE '%_rank1]%'      \n",
    "                            ) a \n",
    "                                ON (\n",
    "                                    c.path LIKE CONCAT('%.',\n",
    "                                a.id,\n",
    "                                '.%') \n",
    "                                OR c.path LIKE CONCAT('%.',\n",
    "                                a.id) \n",
    "                                OR c.path LIKE CONCAT(a.id,\n",
    "                                '.%') \n",
    "                                OR c.path = a.id) \n",
    "                            WHERE\n",
    "                                is_standard = 1 \n",
    "                                AND is_selectable = 1\n",
    "                            ) \n",
    "                            OR  condition_source_concept_id IN (\n",
    "                                SELECT\n",
    "                                    DISTINCT c.concept_id \n",
    "                                FROM\n",
    "                                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                                JOIN\n",
    "                                    (\n",
    "                                        SELECT\n",
    "                                            CAST(cr.id as string) AS id       \n",
    "                                        FROM\n",
    "                                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "                                        WHERE\n",
    "                                            concept_id IN (\n",
    "                                                44827490, 44834387\n",
    "                                            )       \n",
    "                                            AND full_text LIKE '%_rank1]%'      \n",
    "                                    ) a \n",
    "                                        ON (\n",
    "                                            c.path LIKE CONCAT('%.',\n",
    "                                        a.id,\n",
    "                                        '.%') \n",
    "                                        OR c.path LIKE CONCAT('%.',\n",
    "                                        a.id) \n",
    "                                        OR c.path LIKE CONCAT(a.id,\n",
    "                                        '.%') \n",
    "                                        OR c.path = a.id) \n",
    "                                    WHERE\n",
    "                                        is_standard = 0 \n",
    "                                        AND is_selectable = 1\n",
    "                                    )\n",
    "                            )\n",
    "                        ) c_occurrence \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_standard_concept \n",
    "                            ON c_occurrence.condition_concept_id = c_standard_concept.concept_id \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_type \n",
    "                            ON c_occurrence.condition_type_concept_id = c_type.concept_id \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".visit_occurrence` v \n",
    "                            ON c_occurrence.visit_occurrence_id = v.visit_occurrence_id \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` visit \n",
    "                            ON v.visit_concept_id = visit.concept_id \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_source_concept \n",
    "                            ON c_occurrence.condition_source_concept_id = c_source_concept.concept_id \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_status \n",
    "                            ON c_occurrence.condition_status_concept_id = c_status.concept_id\"\"\"\n",
    "\n",
    "    # Read the Pseudomonas dataset from BigQuery\n",
    "    dataset_13876108_condition_df = pd.read_gbq(\n",
    "        dataset_13876108_condition_sql,\n",
    "        dialect=\"standard\",\n",
    "        use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "        progress_bar_type=\"tqdm_notebook\"\n",
    "    )\n",
    "\n",
    "    # Select desired columns\n",
    "    selected_columns = ['person_id', 'source_concept_code', 'source_concept_name', 'source_vocabulary', 'condition_start_datetime']\n",
    "\n",
    "    # Create a boolean mask to filter out rows with NaN or NA values in the 'source_vocabulary' column\n",
    "    mask = dataset_13876108_condition_df['source_vocabulary'].notna()\n",
    "\n",
    "    # Apply the boolean mask to filter the DataFrame\n",
    "    pseudomonas = dataset_13876108_condition_df[selected_columns][mask]\n",
    "\n",
    "    # Count the number of unique person_ids and unique source_concept_codes for Pseudomonas dataset\n",
    "    pseudomonas_unique_person_ids = pseudomonas['person_id'].nunique()\n",
    "    pseudomonas_unique_concept_codes = pseudomonas['source_concept_code'].nunique()\n",
    "    pseudomonas_unique_codes_list = pseudomonas['source_concept_code'].unique()\n",
    "\n",
    "    # Create a message about Pseudomonas dataset\n",
    "    pseudomonas_message = f\"\\nPseudomonas dataset:\\nNumber of unique person_ids: {pseudomonas_unique_person_ids}\\nNumber of unique source_concept_codes: {pseudomonas_unique_concept_codes}\\nUnique source_concept_codes: {', '.join(pseudomonas_unique_codes_list)}\"\n",
    "\n",
    "    return pseudomonas, pseudomonas_message, pseudomonas_unique_person_ids, pseudomonas_unique_concept_codes, pseudomonas_unique_codes_list\n",
    "def read_alzheimers_data():\n",
    "    # Define the SQL query to retrieve the Alzheimer's Disease dataset\n",
    "    dataset_44170505_condition_sql = \"\"\"\n",
    "        SELECT\n",
    "            c_occurrence.person_id,\n",
    "            c_occurrence.condition_concept_id,\n",
    "            c_standard_concept.concept_name as standard_concept_name,\n",
    "            c_standard_concept.concept_code as standard_concept_code,\n",
    "            c_standard_concept.vocabulary_id as standard_vocabulary,\n",
    "            c_occurrence.condition_start_datetime,\n",
    "            c_occurrence.condition_end_datetime,\n",
    "            c_occurrence.condition_type_concept_id,\n",
    "            c_type.concept_name as condition_type_concept_name,\n",
    "            c_occurrence.stop_reason,\n",
    "            c_occurrence.visit_occurrence_id,\n",
    "            visit.concept_name as visit_occurrence_concept_name,\n",
    "            c_occurrence.condition_source_value,\n",
    "            c_occurrence.condition_source_concept_id,\n",
    "            c_source_concept.concept_name as source_concept_name,\n",
    "            c_source_concept.concept_code as source_concept_code,\n",
    "            c_source_concept.vocabulary_id as source_vocabulary,\n",
    "            c_occurrence.condition_status_source_value,\n",
    "            c_occurrence.condition_status_concept_id,\n",
    "            c_status.concept_name as condition_status_concept_name \n",
    "        FROM\n",
    "            ( SELECT\n",
    "                * \n",
    "            FROM\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".condition_occurrence` c_occurrence \n",
    "            WHERE\n",
    "                (\n",
    "                    condition_concept_id IN (\n",
    "                        SELECT\n",
    "                            DISTINCT c.concept_id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                        JOIN\n",
    "                            (\n",
    "                                SELECT\n",
    "                                    CAST(cr.id as string) AS id       \n",
    "                                FROM\n",
    "                                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "                                WHERE\n",
    "                                    concept_id IN (\n",
    "                                        35608576, 37018688, 37109056, 37110513, 37117145, 372241, 37312035, 374888, 375791, 376085, 376095, 376946, 377254, 377527, 377788, 378125, 378419, 378726, 379778, 379784, 380701, 380986, 381832, 4009647, 4043378, 4046090, 4047745, 4047747, 40483103, 4048875, 4092747, 4101137, 4103534, 4139421, 4182210, 4196433, 4218017, 4220313, 4228133, 42538857, 4277444, 4278830, 43021816, 43530664, 43530666, 441002, 441535, 443605, 443790, 443864, 444091, 44782432, 44782763, 44782771, 762497\n",
    "                                    )       \n",
    "                                    AND full_text LIKE '%_rank1]%'      \n",
    "                            ) a \n",
    "                                ON (\n",
    "                                    c.path LIKE CONCAT('%.',\n",
    "                                a.id,\n",
    "                                '.%') \n",
    "                                OR c.path LIKE CONCAT('%.',\n",
    "                                a.id) \n",
    "                                OR c.path LIKE CONCAT(a.id,\n",
    "                                '.%') \n",
    "                                OR c.path = a.id) \n",
    "                            WHERE\n",
    "                                is_standard = 1 \n",
    "                                AND is_selectable = 1\n",
    "                            ) \n",
    "                            OR  condition_source_concept_id IN (\n",
    "                                SELECT\n",
    "                                    DISTINCT c.concept_id \n",
    "                                FROM\n",
    "                                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                                JOIN\n",
    "                                    (\n",
    "                                        SELECT\n",
    "                                            CAST(cr.id as string) AS id       \n",
    "                                        FROM\n",
    "                                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "                                        WHERE\n",
    "                                            concept_id IN (\n",
    "                                                1568088, 1568090, 1568293, 1568295, 35207114, 35207356, 35207357, 35207358, 35207359, 44819534, 44819535, 44820708, 44820709, 44821810, 44821811, 44821814, 44824105, 44824106, 44824152, 44826489, 44826537, 44827641, 44827644, 44829914, 44829915, 44829917, 44831078, 44831079, 44831083, 44831122, 44832219, 44833435, 44834581, 44835772, 44835773, 44835825, 44836954, 44836959, 45538000, 45538103, 45547675, 45547690, 45547730, 45552458, 45566776, 45591073, 45591076, 45595842, 45595843, 45600684, 45605533\n",
    "                                            )       \n",
    "                                            AND full_text LIKE '%_rank1]%'      \n",
    "                                    ) a \n",
    "                                        ON (\n",
    "                                            c.path LIKE CONCAT('%.',\n",
    "                                        a.id,\n",
    "                                        '.%') \n",
    "                                        OR c.path LIKE CONCAT('%.',\n",
    "                                        a.id) \n",
    "                                        OR c.path LIKE CONCAT(a.id,\n",
    "                                        '.%') \n",
    "                                        OR c.path = a.id) \n",
    "                                    WHERE\n",
    "                                        is_standard = 0 \n",
    "                                        AND is_selectable = 1\n",
    "                                    )\n",
    "                            )\n",
    "                        ) c_occurrence \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_standard_concept \n",
    "                            ON c_occurrence.condition_concept_id = c_standard_concept.concept_id \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_type \n",
    "                            ON c_occurrence.condition_type_concept_id = c_type.concept_id \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".visit_occurrence` v \n",
    "                            ON c_occurrence.visit_occurrence_id = v.visit_occurrence_id \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` visit \n",
    "                            ON v.visit_concept_id = visit.concept_id \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_source_concept \n",
    "                            ON c_occurrence.condition_source_concept_id = c_source_concept.concept_id \n",
    "                    LEFT JOIN\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_status \n",
    "                            ON c_occurrence.condition_status_concept_id = c_status.concept_id\"\"\"\n",
    "\n",
    "    # Read the Alzheimer's Disease data from BigQuery\n",
    "    alzheimer_df = pd.read_gbq(\n",
    "        dataset_44170505_condition_sql,\n",
    "        dialect=\"standard\",\n",
    "        use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "        progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "    # Select desired columns\n",
    "    selected_columns = ['person_id', 'source_concept_code', 'source_concept_name', 'source_vocabulary', 'condition_start_datetime']\n",
    "\n",
    "    # Create a boolean mask to filter out rows with NaN or NA values in the 'source_vocabulary' column\n",
    "    mask = alzheimer_df['source_vocabulary'].notna()\n",
    "\n",
    "    # Apply the boolean mask to filter the DataFrame\n",
    "    alzheimer_filtered = alzheimer_df[selected_columns][mask]\n",
    "\n",
    "    # Count the number of unique person_ids and unique source_concept_codes for Alzheimer's dataset\n",
    "    alzheimer_unique_person_ids = alzheimer_filtered['person_id'].nunique()\n",
    "    alzheimer_unique_concept_codes = alzheimer_filtered['source_concept_code'].nunique()\n",
    "    alzheimer_unique_codes_list = alzheimer_filtered['source_concept_code'].unique()\n",
    "\n",
    "    # Construct the message\n",
    "    alzheimer_message = f\"Alzheimer's dataset:\\nNumber of unique person_ids: {alzheimer_unique_person_ids}\\nNumber of unique source_concept_codes: {alzheimer_unique_concept_codes}\\nUnique source_concept_codes: {', '.join(alzheimer_unique_codes_list)}\"\n",
    "\n",
    "    # Return the filtered DataFrame and message\n",
    "    return alzheimer_filtered, alzheimer_message, alzheimer_unique_person_ids, alzheimer_unique_concept_codes, alzheimer_unique_codes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def read_streptococcus_data():\n",
    "    # Define the SQL query\n",
    "    dataset_50428675_condition_sql = \"\"\"\n",
    "        SELECT\n",
    "            c_occurrence.person_id,\n",
    "            c_occurrence.condition_concept_id,\n",
    "            c_standard_concept.concept_name as standard_concept_name,\n",
    "            c_standard_concept.concept_code as standard_concept_code,\n",
    "            c_standard_concept.vocabulary_id as standard_vocabulary,\n",
    "            c_occurrence.condition_start_datetime,\n",
    "            c_occurrence.condition_end_datetime,\n",
    "            c_occurrence.condition_type_concept_id,\n",
    "            c_type.concept_name as condition_type_concept_name,\n",
    "            c_occurrence.stop_reason,\n",
    "            c_occurrence.visit_occurrence_id,\n",
    "            visit.concept_name as visit_occurrence_concept_name,\n",
    "            c_occurrence.condition_source_value,\n",
    "            c_occurrence.condition_source_concept_id,\n",
    "            c_source_concept.concept_name as source_concept_name,\n",
    "            c_source_concept.concept_code as source_concept_code,\n",
    "            c_source_concept.vocabulary_id as source_vocabulary,\n",
    "            c_occurrence.condition_status_source_value,\n",
    "            c_occurrence.condition_status_concept_id,\n",
    "            c_status.concept_name as condition_status_concept_name \n",
    "        FROM\n",
    "            ( SELECT\n",
    "                * \n",
    "            FROM\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".condition_occurrence` c_occurrence \n",
    "            WHERE\n",
    "                (\n",
    "                    condition_source_concept_id IN (\n",
    "                        SELECT\n",
    "                            DISTINCT c.concept_id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                        JOIN\n",
    "                            (\n",
    "                                SELECT\n",
    "                                    CAST(cr.id as string) AS id       \n",
    "                                FROM\n",
    "                                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "                                WHERE\n",
    "                                    concept_id IN (\n",
    "                                        1567453, 35205543, 35205544, 35205545, 35206024, 35206025, 35206026, 35206027, 35206028, 35206029, 35206030, 35206031, 35206032, 35207938, 35207942, 35207959, 44819743, 44820548, 44820886, 44821669, 44821983, 44822816, 44823772, 44825146, 44825467, 44828677, 44829735, 44830730, 44832417, 44833226, 44833607, 44834423, 44835607, 45537779, 45571485, 45572911, 45576141, 45577677, 45582601, 45609916, 766415\n",
    "                                    )       \n",
    "                                    AND full_text LIKE '%_rank1]%'      \n",
    "                            ) a \n",
    "                                ON (\n",
    "                                    c.path LIKE CONCAT('%.',\n",
    "                                a.id,\n",
    "                                '.%') \n",
    "                                OR c.path LIKE CONCAT('%.',\n",
    "                                a.id) \n",
    "                                OR c.path LIKE CONCAT(a.id,\n",
    "                                '.%') \n",
    "                                OR c.path = a.id) \n",
    "                            WHERE\n",
    "                                is_standard = 0 \n",
    "                                AND is_selectable = 1\n",
    "                            )\n",
    "                    )  \n",
    "                    AND (\n",
    "                        c_occurrence.PERSON_ID IN (\n",
    "                            SELECT\n",
    "                                distinct person_id  \n",
    "                            FROM\n",
    "                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "                            WHERE\n",
    "                                cb_search_person.person_id IN (\n",
    "                                    SELECT\n",
    "                                        person_id \n",
    "                                    FROM\n",
    "                                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` p \n",
    "                                    WHERE\n",
    "                                        has_ehr_data = 1 \n",
    "                                ) \n",
    "                            )\n",
    "                    )\n",
    "                ) c_occurrence \n",
    "            LEFT JOIN\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_standard_concept \n",
    "                    ON c_occurrence.condition_concept_id = c_standard_concept.concept_id \n",
    "            LEFT JOIN\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_type \n",
    "                    ON c_occurrence.condition_type_concept_id = c_type.concept_id \n",
    "            LEFT JOIN\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".visit_occurrence` v \n",
    "                    ON c_occurrence.visit_occurrence_id = v.visit_occurrence_id \n",
    "            LEFT JOIN\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` visit \n",
    "                    ON v.visit_concept_id = visit.concept_id \n",
    "            LEFT JOIN\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_source_concept \n",
    "                    ON c_occurrence.condition_source_concept_id = c_source_concept.concept_id \n",
    "            LEFT JOIN\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_status \n",
    "                    ON c_occurrence.condition_status_concept_id = c_status.concept_id\"\"\"\n",
    "\n",
    "    # Execute the SQL query and return the DataFrame\n",
    "    streptococcus_df = pd.read_gbq(\n",
    "        dataset_50428675_condition_sql,\n",
    "        dialect=\"standard\",\n",
    "        use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "        progress_bar_type=\"tqdm_notebook\")\n",
    "    \n",
    "     # Select desired columns\n",
    "    selected_columns = ['person_id', 'source_concept_code', 'source_concept_name', 'source_vocabulary',\"\" 'condition_start_datetime']\n",
    "\n",
    "    # Create a boolean mask to filter out rows with NaN or NA values in the 'source_vocabulary' column\n",
    "    mask = streptococcus_df['source_vocabulary'].notna()\n",
    "\n",
    "    # Apply the boolean mask to filter the DataFrame\n",
    "    streptococcus_filtered =streptococcus_df[selected_columns][mask]\n",
    "\n",
    "    # Count the number of unique person_ids and unique source_concept_codes for Alzheimer's dataset\n",
    "    streptococcus_unique_person_ids = streptococcus_filtered['person_id'].nunique()\n",
    "    streptococcus_unique_concept_codes = streptococcus_filtered['source_concept_code'].nunique()\n",
    "    streptococcus_unique_codes_list =  streptococcus_filtered['source_concept_code'].unique()\n",
    "\n",
    "    # Construct the message\n",
    "    streptococcus_message = f\"Streptococcus's dataset:\\nNumber of unique person_ids: {streptococcus_unique_person_ids}\\nNumber of unique source_concept_codes: {streptococcus_unique_concept_codes}\\nUnique source_concept_codes: {', '.join(streptococcus_unique_codes_list)}\"\n",
    "\n",
    "    # Return the filtered DataFrame and message\n",
    "    return streptococcus_filtered, streptococcus_message, streptococcus_unique_person_ids, streptococcus_unique_concept_codes, streptococcus_unique_codes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to read Alzheimer's Disease data\n",
    "streptococcus_data, streptococcus_info, streptococcus_unique_person_ids, streptococcus_unique_concept_codes, streptococcus_unique_codes_list = read_streptococcus_data()\n",
    "streptococcus_data = streptococcus_data[streptococcus_data['source_concept_name'].str.contains('Streptoco', case=False)]\n",
    "streptococcus_data = streptococcus_data[streptococcus_data['source_vocabulary'].str.contains(('ICD9CM|ICD10CM'), case=False)]\n",
    "\n",
    "# # Display the Alzheimer's Disease data and information\n",
    "# print(streptococcus_info)\n",
    "# print(streptococcus_data)\n",
    "# print(\"Unique Person IDs:\", streptococcus_unique_person_ids)\n",
    "# print(\"Unique Concept Codes:\", streptococcus_unique_concept_codes)\n",
    "# print(\"Unique Codes List:\", streptococcus_unique_codes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to read Pseudomonas data\n",
    "pseudomonas_data, pseudomonas_info, pseudomonas_unique_person_ids, pseudomonas_unique_concept_codes, pseudomonas_unique_codes_list = read_pseudomonas_data()\n",
    "pseudomonas_data = pseudomonas_data[pseudomonas_data['source_concept_name'].str.contains('Pseu', case=False)]\n",
    "pseudomonas_data = pseudomonas_data[pseudomonas_data['source_vocabulary'].str.contains(('ICD9CM|ICD10CM'), case=False)]\n",
    "# # Display the Pseudomonas data and information\n",
    "# print(pseudomonas_info)\n",
    "# print(pseudomonas_data)\n",
    "# print(\"Unique Person IDs:\", pseudomonas_unique_person_ids)\n",
    "# print(\"Unique Concept Codes:\", pseudomonas_unique_concept_codes)\n",
    "# print(\"Unique Codes List:\", pseudomonas_unique_codes_list)\n",
    "# pseudomonas_unique_name_list =pseudomonas_data['source_concept_name'].unique()\n",
    "# print(\"Unique source_concept_name:\", ', '.join(pseudomonas_unique_name_list))\n",
    "# print(pseudomonas_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to read Alzheimer's Disease data\n",
    "alzheimer_data, alzheimer_info, alzheimer_unique_person_ids, alzheimer_unique_concept_codes, alzheimer_unique_codes_list = read_alzheimers_data()\n",
    "\n",
    "alzheimer_data = alzheimer_data[alzheimer_data['source_vocabulary'].str.contains(('ICD9CM|ICD10CM'), case=False)]\n",
    "postconcussion_data = alzheimer_data[alzheimer_data['source_concept_name'].str.contains('Post|concussion',case=False)]\n",
    "postconcussion_data\n",
    "# alzheimer_data = alzheimer_data[alzheimer_data['source_concept_name'].str.contains('Alz', case=False)]\n",
    "alzheimer_data = alzheimer_data[alzheimer_data['source_concept_name'].str.contains('Alz|Demen', case=False)]\n",
    "alzheimer_data = alzheimer_data[~alzheimer_data['source_concept_name'].str.contains('Postconcussion','Postconcussional')]\n",
    "alzheimer_data\n",
    "alzheimer_unique_name_list =alzheimer_data['source_concept_name'].unique()\n",
    "# # Display the Alzheimer's Disease data and information\n",
    "# print(alzheimer_info)\n",
    "# print(alzheimer_data)\n",
    "# print(\"Unique Person IDs:\", alzheimer_unique_person_ids)\n",
    "# print(\"Unique Concept Codes:\", alzheimer_unique_concept_codes)\n",
    "# print(\"Unique Codes List:\", alzheimer_unique_codes_list)\n",
    "# print(\"Unique source_concept_name:\", ', '.join(alzheimer_unique_name_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check what phecodes we have in each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_top_concepts_to_csv(disease, unique_person_ids, person_information):\n",
    "    # Filter conditions_common DataFrame for only the person IDs present in unique_person_ids\n",
    "    filtered_conditions = person_information[person_information['person_id'].isin(unique_person_ids)]\n",
    "\n",
    "    # Group by source_concept_code and source_concept_name, count unique person IDs for each concept, and sort by count\n",
    "    top_concepts = filtered_conditions.groupby(['source_concept_code', 'source_concept_name'])['person_id'].nunique().reset_index(name='unique_ids_count').sort_values(by='unique_ids_count', ascending=False)\n",
    "\n",
    "    # Select the top 100 most common concepts\n",
    "    top_100_concepts = top_concepts.head(100)\n",
    "\n",
    "    # Reset the index of the top 100 concepts DataFrame\n",
    "    top_100_concepts.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Replace counts less than 20 with \"<20\"\n",
    "    top_100_concepts['unique_ids_count'] = top_100_concepts['unique_ids_count'].apply(lambda x: '<20' if x < 20 else x)\n",
    "\n",
    "    # Create a new DataFrame with the modified counts\n",
    "    new_df = top_100_concepts.copy()\n",
    "\n",
    "    # Save the new DataFrame to a CSV file\n",
    "#     new_df.to_csv(f'./download/{disease}_top_100_concepts.csv', index=False)\n",
    "\n",
    "disease = 'gram_negative'\n",
    "gram_negative_unique_person_ids = gram_negative_data['person_id'].unique().tolist()\n",
    "save_top_concepts_to_csv(disease, gram_negative_unique_person_ids, person_information)\n",
    "disease = 'gram_negative_filtered'\n",
    "gram_negative_unique_person_ids = gram_negative_data_filtered['person_id'].unique().tolist()\n",
    "save_top_concepts_to_csv(disease, gram_negative_unique_person_ids, person_information)\n",
    "\n",
    "disease = 'staphylococcus'\n",
    "staphylococcus_unique_person_ids = staphylococcus_data['person_id'].unique().tolist()\n",
    "save_top_concepts_to_csv(disease, staphylococcus_unique_person_ids, person_information)\n",
    "\n",
    "disease='streptococcus'\n",
    "streptococcus_unique_person_ids =streptococcus_data['person_id'].unique().tolist()\n",
    "save_top_concepts_to_csv(disease, streptococcus_unique_person_ids, person_information)\n",
    "\n",
    "disease= 'pseudomonas'\n",
    "pseudomonas_unique_person_ids = pseudomonas_data['person_id'].unique().tolist()\n",
    "save_top_concepts_to_csv(disease, pseudomonas_unique_person_ids, person_information)\n",
    "\n",
    "disease='alzheimer'\n",
    "alzheimer_unique_person_ids = alzheimer_data['person_id'].unique().tolist()\n",
    "save_top_concepts_to_csv(disease, alzheimer_unique_person_ids, person_information)\n",
    "\n",
    "disease = 'ecoli'\n",
    "ecoli_unique_person_ids = ecoli_data['person_id'].unique().tolist()\n",
    "save_top_concepts_to_csv(disease, ecoli_unique_person_ids, person_information)\n",
    "disease = 'gram_positive'\n",
    "gram_positive_unique_person_ids = gram_positive_data['person_id'].unique().tolist()\n",
    "# gram_positive_unique_person_ids = gram_positive_data[0]['person_id'].unique().tolist()\n",
    "save_top_concepts_to_csv(disease, gram_positive_unique_person_ids, person_information)\n",
    "retrovirus_unique_person_ids = retrovirus_data['person_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create dataframes that have the earliest onset age onset for each of the Infection or disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     23
    ]
   },
   "outputs": [],
   "source": [
    "# Define a custom aggregation function to select the row with the oldest condition_start_datetime\n",
    "def oldest_condition_start_datetime(group):\n",
    "    oldest_row_index = group['condition_start_datetime'].idxmin()\n",
    "    return group.loc[oldest_row_index]\n",
    "\n",
    "# Group by 'person_id' and aggregate to keep the oldest condition_start_datetime and other columns\n",
    "ecoli_aggregated_df = ecoli_data.groupby('person_id').apply(oldest_condition_start_datetime).reset_index(drop=True)\n",
    "# ecoli_aggregated_df\n",
    "# Group by 'person_id' and aggregate to keep the oldest condition_start_datetime and other columns\n",
    "retrovirus_aggregated_df = retrovirus_data_filtered.groupby('person_id').apply(oldest_condition_start_datetime).reset_index(drop=True)\n",
    "# retrovirus_aggregated_df\n",
    "# Group by 'person_id' and aggregate to keep the oldest condition_start_datetime and other columns\n",
    "gram_negative_aggregated_df = gram_negative_data_filtered.groupby('person_id').apply(oldest_condition_start_datetime).reset_index(drop=True)\n",
    "# gram_negative_aggregated_df\n",
    "\n",
    "# Group by 'person_id' and aggregate to keep the oldest condition_start_datetime and other columns\n",
    "streptococcus_aggregated_df = streptococcus_data.groupby('person_id').apply(oldest_condition_start_datetime).reset_index(drop=True)\n",
    "# streptococcus_aggregated_df\n",
    "\n",
    "# Group by 'person_id' and aggregate to keep the oldest condition_start_datetime and other columns\n",
    "pseudomonas_aggregated_df = pseudomonas_data.groupby('person_id').apply(oldest_condition_start_datetime).reset_index(drop=True)\n",
    "# pseudomonas_aggregated_df\n",
    "\n",
    "# Group by 'person_id' and aggregate to keep the oldest condition_start_datetime and other columns\n",
    "# aggregated_df = alzheimer_data.groupby('person_id').apply(oldest_condition_start_datetime).reset_index(drop=True)\n",
    "alzheimer_aggregated_df = alzheimer_data.groupby('person_id').apply(oldest_condition_start_datetime).reset_index(drop=True)\n",
    "# alzheimer_aggregated_df\n",
    "\n",
    "# Group by 'person_id' and aggregate to keep the oldest condition_start_datetime and other columns\n",
    "staphylococcus_aggregated_df = staphylococcus_data.groupby('person_id').apply(oldest_condition_start_datetime).reset_index(drop=True)\n",
    "staphylococcus_aggregated_df = staphylococcus_aggregated_df[['person_id', 'source_concept_code', 'source_concept_name', 'source_vocabulary', 'condition_start_datetime']]\n",
    "# staphylococcus_aggregated_df\n",
    "\n",
    "gram_positive_aggregated_df = gram_positive_data.groupby('person_id').apply(oldest_condition_start_datetime).reset_index(drop=True)\n",
    "# gram_positive_aggregated_df\n",
    "# Group by 'person_id' and aggregate to keep the oldest condition_start_datetime and other columns\n",
    "retrovirus_aggregated_df = retrovirus_data_filtered.groupby('person_id').apply(oldest_condition_start_datetime).reset_index(drop=True)\n",
    "# retrovirus_aggregated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the patients that have the Diseases and what PheCodes they have "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_person_ids = {\n",
    "    'staphylococcus': staphylococcus_unique_person_ids,\n",
    "    'alzheimer': alzheimer_unique_person_ids,\n",
    "    'pseudomonas': pseudomonas_unique_person_ids,\n",
    "    'streptococcus': streptococcus_unique_person_ids,\n",
    "    'ecoli': ecoli_unique_person_ids,\n",
    "    'gram_negative' : gram_negative_unique_person_ids,\n",
    "    'gram_positive': gram_positive_unique_person_ids,\n",
    "    'retrovirus': retrovirus_unique_person_ids\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty set to store unique person IDs\n",
    "unique_person_ids = set()\n",
    "\n",
    "# Iterate over each disease and update the set of unique person IDs\n",
    "for disease, person_ids in disease_person_ids.items():\n",
    "    # Ensure person_ids is iterable by converting to a set\n",
    "    if isinstance(person_ids, (int, float)):  # If it's a single value\n",
    "        person_ids = {person_ids}  # Convert it to a set\n",
    "    unique_person_ids.update(person_ids)  # Update the set with person_ids\n",
    "\n",
    "# Create a dataframe with one column containing unique person IDs\n",
    "unique_ids = pd.DataFrame({'person_id': list(unique_person_ids)})\n",
    "\n",
    "# # Display the dataframe\n",
    "# print(unique_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diseases = ['alzheimer', 'gram_negative', 'staphylococcus',  'pseudomonas', 'streptococcus','ecoli', 'gram_positive',\"retrovirus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store the count of unique IDs for each disease\n",
    "unique_ids_count = {}\n",
    "\n",
    "# Iterate over the diseases\n",
    "for disease in diseases:\n",
    "    # Get the list of unique person IDs for the current disease\n",
    "    unique_person_ids = disease_person_ids.get(disease, [])\n",
    "    \n",
    "    # Ensure unique_person_ids is iterable\n",
    "    if isinstance(unique_person_ids, (int, float)):  # If it's a single value\n",
    "        unique_person_ids = {unique_person_ids}  # Convert it to a set\n",
    "    \n",
    "    # Count the number of unique IDs\n",
    "    unique_count = len(set(unique_person_ids))\n",
    "    \n",
    "    # Store the count in the dictionary\n",
    "    unique_ids_count[disease] = unique_count\n",
    "\n",
    "# Print the counts\n",
    "for disease, count in unique_ids_count.items():\n",
    "    print(f\"{disease}: {count} unique IDs\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create a dataframe with the unique codes for each disease"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store unique source_concept_codes\n",
    "unique_codes_dict = {}\n",
    "\n",
    "# List of diseases\n",
    "diseases = ['alzheimer', 'gram_negative', 'staphylococcus',  'pseudomonas', 'streptococcus','ecoli', 'gram_positive',\"retrovirus\"]\n",
    "# Iterate over each disease and its corresponding dataframe\n",
    "for disease in diseases:\n",
    "    data = globals()[f\"{disease}_aggregated_df\"]  # Accessing dataframes dynamically\n",
    "    unique_codes = data['source_concept_code'].unique()\n",
    "    unique_codes_dict[disease] = unique_codes\n",
    "\n",
    "# Find the maximum number of unique codes\n",
    "max_length = max(len(codes) for codes in unique_codes_dict.values())\n",
    "\n",
    "# Fill in None values for diseases with fewer unique codes\n",
    "for disease, codes in unique_codes_dict.items():\n",
    "    if len(codes) < max_length:\n",
    "        unique_codes_dict[disease] = list(codes) + [None] * (max_length - len(codes))\n",
    "\n",
    "# Create a dataframe from the dictionary\n",
    "unique_codes_df = pd.DataFrame(unique_codes_dict)\n",
    "# Map the column names to their corresponding dataframes\n",
    "aggregated_dfs = {\n",
    "    'alzheimer': alzheimer_aggregated_df,\n",
    "    'gram_negative': gram_negative_aggregated_df,\n",
    "    'staphylococcus': staphylococcus_aggregated_df,\n",
    "    'pseudomonas': pseudomonas_aggregated_df,\n",
    "    'streptococcus': streptococcus_aggregated_df,\n",
    "    'ecoli': ecoli_aggregated_df,\n",
    "    'gram_positive': gram_positive_aggregated_df,\n",
    "    'retrovirus': retrovirus_aggregated_df\n",
    "}\n",
    "\n",
    "# Iterate through each column and match codes to meanings\n",
    "for column, dataframe in aggregated_dfs.items():\n",
    "    # Create a dictionary mapping codes to their meanings\n",
    "    code_to_meaning = dataframe.set_index('source_concept_code')['source_concept_name'].to_dict()\n",
    "    \n",
    "    # Map the meanings to the unique_codes_df\n",
    "    unique_codes_df[f\"{column}_ICD9_10_meaning\"] = unique_codes_df[column].map(code_to_meaning)\n",
    "\n",
    "# Display the resulting dataframe\n",
    "print(unique_codes_df)\n",
    "unique_codes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sabe the dataframe \n",
    "unique_codes_df.to_csv('./download/unique_codes_df.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the dataframes to enrich the information of the patientts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge person_df_all with person_information on person_id\n",
    "merged_person = pd.merge(person_df_all[['person_id', 'date_of_birth','sex_at_birth']], person_information, on='person_id', how='inner')\n",
    "\n",
    "# Convert date_of_birth to datetime\n",
    "merged_person['date_of_birth'] = pd.to_datetime(merged_person['date_of_birth'])\n",
    "\n",
    "# Calculate age_onset by subtracting date_of_birth from condition_start_datetime\n",
    "merged_person['age_onset'] = (merged_person['condition_start_datetime'] - merged_person['date_of_birth']).dt.days / 365.25\n",
    "\n",
    "merged_person =merged_person[['person_id', 'date_of_birth', \n",
    "        'standard_concept_name',  'condition_start_datetime', 'condition_source_value', \n",
    "        'source_concept_name', 'source_concept_code', 'source_vocabulary', 'age_onset']]\n",
    "merged_person.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_person"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep data with EHR more than 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of entries for each person_id\n",
    "count_person_entries = person_information['person_id'].value_counts()\n",
    "\n",
    "# Filter out the person_ids that have more than 10 entries\n",
    "person_ids_more_than_10 = count_person_entries[count_person_entries > 10].index.tolist()\n",
    "\n",
    "# Filter the person_df_all DataFrame using the list of person_ids\n",
    "merged_person_df = person_df_all[person_df_all['person_id'].isin(person_ids_more_than_10)].copy()\n",
    "\n",
    "# print(\"Filtered merged_person_df:\")\n",
    "# print(merged_person_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create columns if they have or not the Disease (1=Have, 0 = Not have)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns for each disease and initialize to 0\n",
    "for disease in diseases:\n",
    "    merged_person_df[disease] = 0\n",
    "\n",
    "# Update the disease columns based on the unique IDs\n",
    "for disease, unique_ids in disease_person_ids.items():\n",
    "    merged_person_df.loc[merged_person_df['person_id'].isin(unique_ids), disease] = 1\n",
    "\n",
    "# # Display the new dataframe\n",
    "# print(merged_person_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_person_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set the disease name and start the analysis using all Patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di='Dementia'"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Filter the data for the disease"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the aggregated dataframes\n",
    "aggregated_dataframes = {\n",
    "    \"gram_positive_aggregated_df\": gram_positive_aggregated_df,\n",
    "    \"staphylococcus_aggregated_df\": staphylococcus_aggregated_df,\n",
    "    \"alzheimer_aggregated_df\": alzheimer_aggregated_df,\n",
    "    \"pseudomonas_aggregated_df\": pseudomonas_aggregated_df,\n",
    "    \"streptococcus_aggregated_df\": streptococcus_aggregated_df,\n",
    "    \"gram_negative_aggregated_df\": gram_negative_aggregated_df,\n",
    "    \"ecoli_aggregated_df\": ecoli_aggregated_df,\n",
    "    \"retrovirus_aggregated_df\": retrovirus_aggregated_df\n",
    "}\n",
    "# Merge each dataframe with `person_df_all` to add `date_of_birth`\n",
    "dataframes_with_dob = {\n",
    "    name: df.merge(person_df_all[['person_id', 'date_of_birth']], on=\"person_id\", how=\"left\")\n",
    "    for name, df in aggregated_dataframes.items()\n",
    "}\n",
    "# Define the columns to keep in all dataframes\n",
    "columns_to_keep = [\n",
    "    \"person_id\", \"condition_start_datetime\", \"source_concept_name\",\n",
    "    \"source_concept_code\", \"source_vocabulary\", \"date_of_birth\"\n",
    "]\n",
    "# Keep only the desired columns in each dataframe\n",
    "cleaned_dataframes_with_selected_columns = {\n",
    "    name: df[columns_to_keep]\n",
    "    for name, df in dataframes_with_dob.items()\n",
    "    if all(col in df.columns for col in columns_to_keep)\n",
    "}\n",
    "\n",
    "# Fix `date_of_birth` column conflicts if necessary\n",
    "dataframes_with_dob_fixed = {\n",
    "    name: df.rename(columns={\"date_of_birth_y\": \"date_of_birth\"}).drop(columns=[\"date_of_birth_x\"], errors=\"ignore\")\n",
    "    for name, df in dataframes_with_dob.items()\n",
    "}\n",
    "# Ensure all desired columns are present\n",
    "cleaned_dataframes_with_selected_columns_fixed = {\n",
    "    name: df[columns_to_keep]\n",
    "    for name, df in dataframes_with_dob_fixed.items()\n",
    "    if all(col in df.columns for col in columns_to_keep)\n",
    "}\n",
    "# Calculate the `age_onset` column for each dataframe\n",
    "cleaned_dataframes_with_age_onset = {\n",
    "    name: df.assign(age_onset=(\n",
    "            (pd.to_datetime(df[\"condition_start_datetime\"]) - pd.to_datetime(df[\"date_of_birth\"])).dt.days / 365.25\n",
    "    ).round(2))\n",
    "    for name, df in cleaned_dataframes_with_selected_columns_fixed.items()\n",
    "    if \"condition_start_datetime\" in df.columns and \"date_of_birth\" in df.columns\n",
    "}\n",
    "# Assign cleaned dataframes for future analysis\n",
    "ecoli_df = cleaned_dataframes_with_age_onset[\"ecoli_aggregated_df\"]\n",
    "alzheimer_df = cleaned_dataframes_with_age_onset[\"alzheimer_aggregated_df\"]\n",
    "gram_negative_df = cleaned_dataframes_with_age_onset[\"gram_negative_aggregated_df\"]\n",
    "staphylococcus_df = cleaned_dataframes_with_age_onset[\"staphylococcus_aggregated_df\"]\n",
    "pseudomonas_df = cleaned_dataframes_with_age_onset[\"pseudomonas_aggregated_df\"]\n",
    "streptococcus_df = cleaned_dataframes_with_age_onset[\"streptococcus_aggregated_df\"]\n",
    "gram_positive_df = cleaned_dataframes_with_age_onset[\"gram_positive_aggregated_df\"]\n",
    "retrovirus_df = cleaned_dataframes_with_age_onset[\"retrovirus_aggregated_df\"]\n",
    "\n",
    "# Define a function to add `age_onset_{disease}` columns to the filtered dataframe\n",
    "def add_age_onset_columns(filtered_df, disease_dfs):\n",
    "    \"\"\"\n",
    "    Add age_onset columns for each disease to the filtered dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "        filtered_df (DataFrame): The main filtered dataframe.\n",
    "        disease_dfs (dict): Dictionary of disease dataframes with age_onset values.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Updated dataframe with new age_onset columns.\n",
    "    \"\"\"\n",
    "    for disease, df in disease_dfs.items():\n",
    "        if disease in [\"gram_negative\", \"gram_positive\"]:\n",
    "            age_onset_col = f\"age_onset_{disease.split('_')[0]}_{disease.split('_')[1]}\"\n",
    "        else:\n",
    "            age_onset_col = f\"age_onset_{disease.split('_')[0]}\"\n",
    "\n",
    "        if \"age_onset\" in df.columns:\n",
    "            filtered_df[age_onset_col] = filtered_df[\"person_id\"].map(\n",
    "                df.set_index(\"person_id\")[\"age_onset\"]\n",
    "            )\n",
    "        else:\n",
    "            filtered_df[age_onset_col] = None\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "# Define disease dataframes\n",
    "disease_dfs = {\n",
    "    \"ecoli\": cleaned_dataframes_with_age_onset.get(\"ecoli_aggregated_df\"),\n",
    "    \"alzheimer\": cleaned_dataframes_with_age_onset.get(\"alzheimer_aggregated_df\"),\n",
    "    \"gram_negative\": cleaned_dataframes_with_age_onset.get(\"gram_negative_aggregated_df\"),\n",
    "    \"staphylococcus\": cleaned_dataframes_with_age_onset.get(\"staphylococcus_aggregated_df\"),\n",
    "    \"pseudomonas\": cleaned_dataframes_with_age_onset.get(\"pseudomonas_aggregated_df\"),\n",
    "    \"streptococcus\": cleaned_dataframes_with_age_onset.get(\"streptococcus_aggregated_df\"),\n",
    "    \"gram_positive\": cleaned_dataframes_with_age_onset.get(\"gram_positive_aggregated_df\"),\n",
    "    \"retrovirus\": cleaned_dataframes_with_age_onset.get(\"retrovirus_aggregated_df\")\n",
    "}\n",
    "columns_to_keep_in_merged = [\n",
    "    \"person_id\", \"date_of_birth\", \"sex_at_birth\",\n",
    "    \"alzheimer\",  \"gram_negative\", \"staphylococcus\",\n",
    "    \"pseudomonas\", \"streptococcus\",\n",
    "    \"gram_positive\",\"ecoli\", \"retrovirus\"\n",
    "]\n",
    "\n",
    "# # Filter and create the merged dataframe\n",
    "# filtered_merged_person_df = merged_person_df[columns_to_keep_in_merged]\n",
    "\n",
    "filtered_merged_person_df = merged_person_df[columns_to_keep_in_merged]\n",
    "filtered_merged_person_df\n",
    "\n",
    "# Add `age_onset_{disease}` columns to the filtered dataframe\n",
    "final_filtered_df = add_age_onset_columns(filtered_merged_person_df, disease_dfs)\n",
    "\n",
    "# Identify people in `person_df_all` not in `final_filtered_df`\n",
    "remaining_people = person_df_all[~person_df_all['person_id'].isin(final_filtered_df['person_id'])]\n",
    "\n",
    "# Create a dataframe for remaining people with default values\n",
    "remaining_people_with_defaults = remaining_people.copy()\n",
    "disease_columns = ['alzheimer',  'gram_negative', 'staphylococcus',\n",
    "                   'pseudomonas', 'streptococcus', 'ecoli', 'gram_positive', 'retrovirus']\n",
    "for col in disease_columns:\n",
    "    remaining_people_with_defaults[col] = 0\n",
    "\n",
    "age_difference_columns = [col for col in final_filtered_df.columns if col.startswith(\"Age_difference_AD_\")]\n",
    "for col in age_difference_columns:\n",
    "    remaining_people_with_defaults[col] = np.nan\n",
    "\n",
    "# Ensure disease columns are strictly binary in final_combined_df\n",
    "def ensure_binary(df, columns):\n",
    "    for col in columns:\n",
    "        df[col] = df[col].fillna(0).astype(int)\n",
    "    return df\n",
    "\n",
    "# Merge datasets\n",
    "final_combined_df = pd.concat([\n",
    "    ensure_binary(final_filtered_df, disease_columns),\n",
    "    ensure_binary(remaining_people_with_defaults, disease_columns)\n",
    "], ignore_index=True)\n",
    "\n",
    "final_filtered_df = add_age_onset_columns(filtered_merged_person_df, disease_dfs)\n",
    "\n",
    "# Calculate `Age_difference_AD_{disease}` for each disease\n",
    "for disease in disease_dfs.keys():\n",
    "    age_onset_col = f\"age_onset_{disease}\"\n",
    "    if age_onset_col in final_filtered_df.columns:\n",
    "        # Calculate the age difference between Alzheimer's and the disease\n",
    "        final_filtered_df[f\"Age_difference_AD_{disease}\"] = (\n",
    "                final_filtered_df[\"age_onset_alzheimer\"] - final_filtered_df[age_onset_col]\n",
    "        )\n",
    "\n",
    "# Identify people in `person_df_all` not in `final_filtered_df`\n",
    "remaining_people = person_df_all[~person_df_all['person_id'].isin(final_filtered_df['person_id'])]\n",
    "\n",
    "# Create a dataframe for remaining people with default values\n",
    "remaining_people_with_defaults = remaining_people.copy()\n",
    "disease_columns = ['alzheimer',  'gram_negative', 'staphylococcus',\n",
    "                   'pseudomonas', 'streptococcus', 'ecoli', 'gram_positive', 'retrovirus']\n",
    "for col in disease_columns:\n",
    "    remaining_people_with_defaults[col] = 0\n",
    "\n",
    "# Add `Age_difference_AD_{disease}` columns with NaN for remaining people\n",
    "for disease in disease_dfs.keys():\n",
    "    remaining_people_with_defaults[f\"Age_difference_AD_{disease}\"] = np.nan\n",
    "\n",
    "# Merge datasets\n",
    "final_combined_df = pd.concat([\n",
    "    ensure_binary(final_filtered_df, disease_columns),\n",
    "    ensure_binary(remaining_people_with_defaults, disease_columns)\n",
    "], ignore_index=True)\n",
    "\n",
    "# Standardize `date_of_birth` to timezone-naive\n",
    "final_combined_df['date_of_birth'] = pd.to_datetime(final_combined_df['date_of_birth']).dt.tz_localize(None)\n",
    "\n",
    "# Calculate current age\n",
    "# final_combined_df['age'] = (pd.Timestamp.now().tz_localize(None) - final_combined_df['date_of_birth']).dt.days / 365.25\n",
    "# Define the cutoff date\n",
    "cutoff_date = pd.Timestamp('2022-07-01')\n",
    "\n",
    "# Calculate age as of the cutoff date\n",
    "final_combined_df['age'] = (cutoff_date - final_combined_df['date_of_birth']).dt.days / 365.25\n",
    "\n",
    "# Define age groups\n",
    "age_bins = [0, 60, 70, 100]\n",
    "age_labels = ['<60', '60-70', '>70']\n",
    "final_combined_df['age_group'] = pd.cut(final_combined_df['age'], bins=age_bins, labels=age_labels, include_lowest=True)\n",
    "\n",
    "# Ensure every value in disease columns is 0 or 1\n",
    "for col in disease_columns:\n",
    "    final_combined_df[col] = final_combined_df[col].astype(int)\n",
    "\n",
    "# # Output final_combined_df\n",
    "# final_combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove the EHR less than 10 after finding the ages\n",
    "\n",
    "## If you do want all data commend this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filter the final_combined_df to keep only the patients with more than 10 entries\n",
    "final_combined_df = final_combined_df[final_combined_df['person_id'].isin(person_ids_more_than_10)].copy()\n",
    "\n",
    "# # Output the filtered final_combined_df\n",
    "# print(\"Filtered final_combined_df (patients with >10 entries):\")\n",
    "# print(final_combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_combined_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the CDR age of the min of the dataset (example we want the patient when they gave the data to be more than 60 with richer EHR data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering patients with Alzheimer's disease onset age > 60\n",
    "final_combined_df = final_combined_df[final_combined_df[\"age\"] > 60]\n",
    "ad_over_60_df = final_combined_df[final_combined_df[\"age_onset_alzheimer\"] > 0]\n",
    "# ad_over_60_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now that we cleaned the data due to Dataframe manipulations it is nice to keep the list of the patients that we are interesting to Research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all person_id values into a list\n",
    "person_id_list = final_combined_df['person_id'].tolist()\n",
    "print(f'The length of those that pass the conditions we set are: {len(person_id_list)}')\n",
    "#___________- make a list with our creteria!!!!!__________#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enrichment Analysis if those patients with Dementia/or AD have enrichment in the diseases or the infections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Filtering patients with Alzheimer's disease onset age > 60\n",
    "# ad_over_60_df = final_combined_df[final_combined_df[\"age_onset_alzheimer\"] > 60]\n",
    "\n",
    "# Defining diseases for enrichment analysis\n",
    "disease_columns = ['alzheimer', 'gram_negative', 'staphylococcus',\n",
    "                   'pseudomonas', 'streptococcus', 'ecoli', 'gram_positive','retrovirus']\n",
    "\n",
    "# Prepare results\n",
    "results = []\n",
    "\n",
    "# Perform enrichment analysis using Hail's fisher_exact_test\n",
    "for disease in disease_columns:\n",
    "    # Create contingency table values\n",
    "    ad_over_60_with_disease = int(ad_over_60_df[disease].sum())\n",
    "    ad_over_60_without_disease = int(len(ad_over_60_df) - ad_over_60_with_disease)\n",
    "    rest_with_disease = int(final_combined_df[disease].sum() - ad_over_60_with_disease)\n",
    "    rest_without_disease = int(len(final_combined_df) - len(ad_over_60_df) - rest_with_disease)\n",
    "    \n",
    "    # Print the numbers for the enrichment test\n",
    "    print(f\"{disease}:\")\n",
    "    print(f\"AD with disease: {ad_over_60_with_disease}\")\n",
    "    print(f\"AD without disease: {ad_over_60_without_disease}\")\n",
    "    print(f\"Rest with disease: {rest_with_disease}\")\n",
    "    print(f\"Rest without disease: {rest_without_disease}\")\n",
    "    \n",
    "    # Apply Fisher's Exact Test using Hail\n",
    "    test_result = hl.eval(\n",
    "        hl.fisher_exact_test(\n",
    "            hl.int32(ad_over_60_with_disease),\n",
    "            hl.int32(ad_over_60_without_disease),\n",
    "            hl.int32(rest_with_disease),\n",
    "            hl.int32(rest_without_disease)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Collect the results\n",
    "    results.append({\n",
    "        \"Disease\": disease,\n",
    "        f\"{di}_With_Disease\": ad_over_60_with_disease,\n",
    "        f\"{di}_Without_Disease\": ad_over_60_without_disease,\n",
    "        \"Rest_With_Disease\": rest_with_disease,\n",
    "        \"Rest_Without_Disease\": rest_without_disease,\n",
    "        \"Odds_Ratio\": test_result.odds_ratio,\n",
    "        \"P_Value\": test_result.p_value,\n",
    "        \"CI_95_Lower\": test_result.ci_95_lower,\n",
    "        \"CI_95_Upper\": test_result.ci_95_upper\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "enrichment_results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the enrichment results with contingency numbers to a TSV file\n",
    "enrichment_results_path = f\"./download/{di}_enrichment_results_with_numbers_hail.tsv\"\n",
    "enrichment_results_df.to_csv(enrichment_results_path, sep='\\t', index=False)\n",
    "enrichment_results_df\n",
    "# Save another simplified TSV with only Odds Ratio, CI, and Adjusted P-Value\n",
    "simplified_results_df = enrichment_results_df[[\"Disease\",\"P_Value\", \"Odds_Ratio\", \"CI_95_Lower\", \"CI_95_Upper\"]]\n",
    "simplified_results_path = f\"./download/{di}_enrichment_results_simplified_hail.tsv\"\n",
    "# simplified_results_df.to_csv(simplified_results_path, sep='\\t', index=False)\n",
    "\n",
    "# Print file paths and display results\n",
    "print(f\"Enrichment results saved to: {enrichment_results_path}\")\n",
    "print(f\"Simplified enrichment results saved to: {simplified_results_path}\")\n",
    "enrichment_hail_df=enrichment_results_df.copy()\n",
    "enrichment_hail_df_all=enrichment_results_df.copy()\n",
    "# enrichment_hail_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save another simplified TSV with only Odds Ratio, CI, and Adjusted P-Value\n",
    "simplified_results_df = enrichment_results_df[[\"Disease\", \"P_Value\",\"Odds_Ratio\", \"CI_95_Lower\", \"CI_95_Upper\"]]\n",
    "# simplified_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct the order of diseases in the desired order and relabel appropriately\n",
    "desired_order = ['ecoli', 'pseudomonas', 'gram_negative', 'gram_positive', 'staphylococcus', 'streptococcus','retrovirus']\n",
    "y_labels = [\n",
    "    \"E. coli\", \"Pseudomonas\", \"Gram-negative\", \n",
    "    \"Gram-positive\", \"Staphylococcus\", \"Streptococcus\",\"Retrovirus\"\n",
    "]\n",
    "\n",
    "# Sort the dataframe by the desired disease order\n",
    "sorted_df = enrichment_hail_df.set_index('Disease').loc[desired_order].reset_index()\n",
    "\n",
    "# Create the forest plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Extract data for plotting\n",
    "odds_ratios = sorted_df['Odds_Ratio']\n",
    "ci_lower = sorted_df['CI_95_Lower']\n",
    "ci_upper = sorted_df['CI_95_Upper']\n",
    "\n",
    "# Calculate x-errors for error bars\n",
    "xerr = [odds_ratios - ci_lower, ci_upper - odds_ratios]\n",
    "\n",
    "# Plot error bars\n",
    "y_positions = range(len(sorted_df))\n",
    "plt.errorbar(odds_ratios, y_positions, xerr=xerr, fmt='o', color='gray', ecolor='black', capsize=3)\n",
    "\n",
    "# Highlight statistically significant points\n",
    "colors = ['blue' if p < 0.05 else 'salmon' for p in sorted_df['P_Value']]\n",
    "for i, color in enumerate(colors):\n",
    "    plt.scatter(odds_ratios.iloc[i], y_positions[i], color=color, zorder=3)\n",
    "\n",
    "# Add vertical reference line\n",
    "plt.axvline(x=1, color='red', linestyle='--', zorder=1)\n",
    "\n",
    "# Customize axes\n",
    "plt.yticks(y_positions, y_labels)\n",
    "plt.xlabel('Odds Ratio')\n",
    "plt.title(f'Forest Plot: Bacteria enrichment analysis for {di.lower()} with age of patients more than 60')\n",
    "plt.grid(axis='y', linestyle='--', linewidth=0.5)\n",
    "# remove top and right spines \n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "# make the bottom and left spines thicker and darker\n",
    "plt.gca().spines['left'].set_linewidth(2)\n",
    "plt.gca().spines['bottom'].set_linewidth(2)\n",
    "plt.gca().spines['left'].set_color('black')\n",
    "plt.gca().spines['bottom'].set_color('black')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save and show the plot\n",
    "forest_plot_path = f\"./download/enrichment_forest_plot_correct_order_{di}.pdf\"\n",
    "plt.savefig(forest_plot_path)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enrichment analysis for All, Male and Female "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Function to perform enrichment analysis using Hail's Fisher's exact test\n",
    "def enrichment_analysis_by_group_hail(df, group_name):\n",
    "    # Define diseases for enrichment analysis\n",
    "    disease_columns = ['alzheimer', 'gram_negative', 'staphylococcus',\n",
    "                       'pseudomonas', 'streptococcus', 'ecoli', 'gram_positive','retrovirus']\n",
    "\n",
    "    # Filtering patients with Alzheimer's disease onset age > 60\n",
    "    ad_over_60_df = df[df[\"age_onset_alzheimer\"] > 0]\n",
    "\n",
    "    # Prepare results\n",
    "    results = []\n",
    "\n",
    "    for disease in disease_columns:\n",
    "        # Create contingency table values\n",
    "        ad_over_60_with_disease = int(ad_over_60_df[disease].sum())\n",
    "        ad_over_60_without_disease = int(len(ad_over_60_df) - ad_over_60_with_disease)\n",
    "        rest_with_disease = int(df[disease].sum() - ad_over_60_with_disease)\n",
    "        rest_without_disease = int(len(df) - len(ad_over_60_df) - rest_with_disease)\n",
    "\n",
    "        # Print for debugging\n",
    "        print(f\"{group_name} - {disease}:\")\n",
    "        print(f\"AD with disease: {ad_over_60_with_disease}\")\n",
    "        print(f\"AD without disease: {ad_over_60_without_disease}\")\n",
    "        print(f\"Rest with disease: {rest_with_disease}\")\n",
    "        print(f\"Rest without disease: {rest_without_disease}\")\n",
    "\n",
    "        # Skip tests if any value in the contingency table is zero\n",
    "        if any(val == 0 for val in [ad_over_60_with_disease, ad_over_60_without_disease, rest_with_disease, rest_without_disease]):\n",
    "            print(f\"Skipping {group_name} - {disease} due to insufficient data.\")\n",
    "            continue\n",
    "\n",
    "        # Apply Fisher's Exact Test using Hail\n",
    "        test_result = hl.eval(\n",
    "            hl.fisher_exact_test(\n",
    "                hl.int32(ad_over_60_with_disease),\n",
    "                hl.int32(ad_over_60_without_disease),\n",
    "                hl.int32(rest_with_disease),\n",
    "                hl.int32(rest_without_disease)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Collect the results\n",
    "        results.append({\n",
    "            \"Group\": group_name,\n",
    "            \"Disease\": disease,\n",
    "            f\"{group_name}_With_Disease\": ad_over_60_with_disease,\n",
    "            f\"{group_name}_Without_Disease\": ad_over_60_without_disease,\n",
    "            \"Rest_With_Disease\": rest_with_disease,\n",
    "            \"Rest_Without_Disease\": rest_without_disease,\n",
    "            \"Odds_Ratio\": test_result.odds_ratio,\n",
    "            \"P_Value\": test_result.p_value,\n",
    "            \"CI_95_Lower\": test_result.ci_95_lower,\n",
    "            \"CI_95_Upper\": test_result.ci_95_upper\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Perform enrichment analysis for all groups\n",
    "male_df = final_combined_df[final_combined_df[\"sex_at_birth\"] == \"Male\"]\n",
    "female_df = final_combined_df[final_combined_df[\"sex_at_birth\"] == \"Female\"]\n",
    "\n",
    "male_results_df = enrichment_analysis_by_group_hail(male_df, \"Male\")\n",
    "female_results_df = enrichment_analysis_by_group_hail(female_df, \"Female\")\n",
    "all_results_df = enrichment_analysis_by_group_hail(final_combined_df, \"All\")\n",
    "\n",
    "# Combine results\n",
    "combined_results_df = pd.concat([male_results_df, female_results_df, all_results_df])\n",
    "\n",
    "# Save results for each group\n",
    "male_results_path = \"./download/enrichment_results_male.tsv\"\n",
    "female_results_path = \"./download/enrichment_results_female.tsv\"\n",
    "all_results_path = \"./download/enrichment_results_all.tsv\"\n",
    "\n",
    "male_results_df.to_csv(male_results_path, sep='\\t', index=False)\n",
    "female_results_df.to_csv(female_results_path, sep='\\t', index=False)\n",
    "all_results_df.to_csv(all_results_path, sep='\\t', index=False)\n",
    "\n",
    "# Save combined results\n",
    "combined_results_path = \"./download/enrichment_results_combined.tsv\"\n",
    "combined_results_df.to_csv(combined_results_path, sep='\\t', index=False)\n",
    "\n",
    "# Simplified results\n",
    "simplified_results_path = \"./download/enrichment_results_simplified.tsv\"\n",
    "simplified_results_df = combined_results_df[[\"Group\", \"Disease\", \"P_Value\", \"Odds_Ratio\", \"CI_95_Lower\", \"CI_95_Upper\"]]\n",
    "simplified_results_df.to_csv(simplified_results_path, sep='\\t', index=False)\n",
    "\n",
    "# Print file paths\n",
    "print(f\"Male results saved to: {male_results_path}\")\n",
    "print(f\"Female results saved to: {female_results_path}\")\n",
    "print(f\"All population results saved to: {all_results_path}\")\n",
    "print(f\"Combined enrichment results saved to: {combined_results_path}\")\n",
    "print(f\"Simplified enrichment results saved to: {simplified_results_path}\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Plot the results of the enrichment"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.lines as mlines\n",
    "# from statsmodels.stats.multitest import multipletests\n",
    "# Define the order of diseases and labels\n",
    "desired_order = [\"ecoli\", \"pseudomonas\", \"gram_negative\", \"gram_positive\", \"staphylococcus\", \"streptococcus\",'retrovirus']\n",
    "y_labels = [\"E. coli\", \"Pseudomonas\", \"Gram-negative\", \"Gram-positive\", \"Staphylococcus\", \"Streptococcus\",'Retrovirus']\n",
    "\n",
    "# Filter and sort results for males, females, and all\n",
    "sorted_df_male = combined_results_df[combined_results_df[\"Group\"] == \"Male\"].set_index(\"Disease\").loc[desired_order].reset_index()\n",
    "sorted_df_female = combined_results_df[combined_results_df[\"Group\"] == \"Female\"].set_index(\"Disease\").loc[desired_order].reset_index()\n",
    "sorted_df_all = combined_results_df[combined_results_df[\"Group\"] == \"All\"].set_index(\"Disease\").loc[desired_order].reset_index()\n",
    "\n",
    "# Extract data for plotting\n",
    "# Male\n",
    "odds_ratios_male = sorted_df_male[\"Odds_Ratio\"]\n",
    "ci_lower_male = sorted_df_male[\"CI_95_Lower\"]\n",
    "ci_upper_male = sorted_df_male[\"CI_95_Upper\"]\n",
    "xerr_male = [odds_ratios_male - ci_lower_male, ci_upper_male - odds_ratios_male]\n",
    "colors_male = [\"cornflowerblue\" if p < 0.05 else \"salmon\" for p in sorted_df_male[\"P_Value\"]]\n",
    "\n",
    "# Female\n",
    "odds_ratios_female = sorted_df_female[\"Odds_Ratio\"]\n",
    "ci_lower_female = sorted_df_female[\"CI_95_Lower\"]\n",
    "ci_upper_female = sorted_df_female[\"CI_95_Upper\"]\n",
    "xerr_female = [odds_ratios_female - ci_lower_female, ci_upper_female - odds_ratios_female]\n",
    "colors_female = [\"cornflowerblue\" if p < 0.05 else \"salmon\" for p in sorted_df_female[\"P_Value\"]]\n",
    "\n",
    "# All\n",
    "odds_ratios_all = sorted_df_all[\"Odds_Ratio\"]\n",
    "ci_lower_all = sorted_df_all[\"CI_95_Lower\"]\n",
    "ci_upper_all = sorted_df_all[\"CI_95_Upper\"]\n",
    "xerr_all = [odds_ratios_all - ci_lower_all, ci_upper_all - odds_ratios_all]\n",
    "colors_all = [\"cornflowerblue\" if p < 0.05 else \"salmon\" for p in sorted_df_all[\"P_Value\"]]\n",
    "\n",
    "\n",
    "legend_handles = [\n",
    "    mlines.Line2D([], [], color=\"black\", marker=\"^\", linestyle=\"None\", markersize=8, label=\"All population\"),\n",
    "    mlines.Line2D([], [], color=\"black\", marker=\"o\", linestyle=\"None\", markersize=8, label=\"Female\"),\n",
    "    mlines.Line2D([], [], color=\"black\", marker=\"s\", linestyle=\"None\", markersize=8, label=\"Male\"),\n",
    "    mlines.Line2D([], [], color=\"cornflowerblue\", marker=\"o\", linestyle=\"None\", markersize=8, label=\"Significant\"),\n",
    "    mlines.Line2D([], [], color=\"salmon\", marker=\"o\", linestyle=\"None\", markersize=8, label=\"Not significant\"),\n",
    "    mlines.Line2D([], [], color=\"red\", linestyle=\"--\", markersize=8, label=\"No significant effect (OR = 1)\")\n",
    "]\n",
    "\n",
    "\n",
    "# Adjust y_positions to center the labels between the three groups\n",
    "y_positions = np.arange(len(desired_order)) * 1.2  # Add spacing between groups\n",
    "y_tick_positions = y_positions + 0.2  # Center the labels\n",
    "\n",
    "# Plot configurations\n",
    "plt.figure(figsize=(14, 10))\n",
    "y_positions = np.arange(len(desired_order))\n",
    "\n",
    "# Plot Male group (square markers)\n",
    "plt.errorbar(odds_ratios_male, y_positions, xerr=xerr_male, fmt=\"s\", color=\"black\", ecolor=\"black\", capsize=3, label=\"Male\")\n",
    "for i, color in enumerate(colors_male):\n",
    "    plt.scatter(odds_ratios_male.iloc[i], y_positions[i], color=color, marker=\"s\", zorder=3)\n",
    "\n",
    "# Plot Female group (circle markers)\n",
    "plt.errorbar(odds_ratios_female, y_positions + 0.2, xerr=xerr_female, fmt=\"o\", color=\"black\", ecolor=\"black\", capsize=3, label=\"Female\")\n",
    "for i, color in enumerate(colors_female):\n",
    "    plt.scatter(odds_ratios_female.iloc[i], y_positions[i] + 0.2, color=color, marker=\"o\", zorder=3)\n",
    "\n",
    "# Plot All group (triangle markers)\n",
    "plt.errorbar(odds_ratios_all, y_positions + 0.4, xerr=xerr_all, fmt=\"^\", color=\"black\", ecolor=\"black\", capsize=3, label=\"All Population\")\n",
    "for i, color in enumerate(colors_all):\n",
    "    plt.scatter(odds_ratios_all.iloc[i], y_positions[i] + 0.4, color=color, marker=\"^\", zorder=3)\n",
    "\n",
    "# Add vertical reference line\n",
    "plt.axvline(x=1, color=\"red\", linestyle=\"--\", zorder=1, label=\"No Effect (OR = 1)\")\n",
    "\n",
    "# Customize axes and legend\n",
    "plt.yticks(y_positions, y_labels)\n",
    "plt.xlabel(\"Odds Ratio\")\n",
    "plt.title(\"Forest Plot: Enrichment Analysis for Males, Females, and All Population\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", linewidth=0.5)\n",
    "plt.legend(handles=legend_handles, loc=\"upper right\", title=\"Legend\", frameon=False, bbox_to_anchor=(1.2, 1.1))\n",
    "\n",
    "# Remove top and right spines\n",
    "plt.gca().spines[\"right\"].set_visible(False)\n",
    "plt.gca().spines[\"top\"].set_visible(False)\n",
    "\n",
    "# Make the bottom and left spines thicker and darker\n",
    "plt.gca().spines[\"left\"].set_linewidth(2)\n",
    "plt.gca().spines[\"bottom\"].set_linewidth(2)\n",
    "plt.gca().spines[\"left\"].set_color(\"black\")\n",
    "plt.gca().spines[\"bottom\"].set_color(\"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save and show the plot\n",
    "forest_plot_path_combined = f\"./download/{di}_combined_enrichment_analysis_forest_plot_updated_legend.pdf\"\n",
    "plt.savefig(forest_plot_path_combined)\n",
    "plt.show()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Add spacing between diseases to make each set of error bars visually distinct"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add spacing between diseases to make each set of error bars visually distinct\n",
    "spacing = 1.5  # Adjust this value for more or less space\n",
    "y_positions = np.arange(len(desired_order)) * spacing  # Add spacing between groups\n",
    "\n",
    "# Plot configurations\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Plot All Population group (triangle markers at the top)\n",
    "plt.errorbar(odds_ratios_all, y_positions + 0.4, xerr=xerr_all, fmt=\"^\", color=\"black\", ecolor=\"black\", capsize=3, label=\"All Population\")\n",
    "for i, color in enumerate(colors_all):\n",
    "    plt.scatter(odds_ratios_all.iloc[i], y_positions[i] + 0.4, color=color, marker=\"^\", zorder=3)\n",
    "\n",
    "# Plot Female group (circle markers in the middle with y_labels aligned)\n",
    "plt.errorbar(odds_ratios_female, y_positions, xerr=xerr_female, fmt=\"o\", color=\"black\", ecolor=\"black\", capsize=3, label=\"Female\")\n",
    "for i, color in enumerate(colors_female):\n",
    "    plt.scatter(odds_ratios_female.iloc[i], y_positions[i], color=color, marker=\"o\", zorder=3)\n",
    "\n",
    "# Plot Male group (square markers at the bottom)\n",
    "plt.errorbar(odds_ratios_male, y_positions - 0.4, xerr=xerr_male, fmt=\"s\", color=\"black\", ecolor=\"black\", capsize=3, label=\"Male\")\n",
    "for i, color in enumerate(colors_male):\n",
    "    plt.scatter(odds_ratios_male.iloc[i], y_positions[i] - 0.4, color=color, marker=\"s\", zorder=3)\n",
    "\n",
    "# Add vertical reference line\n",
    "plt.axvline(x=1, color=\"red\", linestyle=\"--\", zorder=1, label=\"No Effect (OR = 1)\")\n",
    "\n",
    "# Customize axes and legend\n",
    "plt.yticks(y_positions, y_labels)  # Align labels with Female in the middle\n",
    "plt.xlabel(\"Odds Ratio\",fontsize=16)\n",
    "plt.title(f\"Forest Plot: Bacteria enrichment analysis for males, females, and all population in {di} and age>60\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", linewidth=0.5)\n",
    "plt.legend(handles=legend_handles, loc=\"upper right\", title=\"Legend\", frameon=False, bbox_to_anchor=(1.2, 1.1),fontsize=10)\n",
    "# make x-labels more readable and bigger\n",
    "plt.xticks(fontsize=14)\n",
    "# make y-labels more readable and bigger\n",
    "plt.yticks(fontsize=14)\n",
    "# Remove top and right spines\n",
    "plt.gca().spines[\"right\"].set_visible(False)\n",
    "plt.gca().spines[\"top\"].set_visible(False)\n",
    "\n",
    "# Make the bottom and left spines thicker and darker\n",
    "plt.gca().spines[\"left\"].set_linewidth(2)\n",
    "plt.gca().spines[\"bottom\"].set_linewidth(2)\n",
    "plt.gca().spines[\"left\"].set_color(\"black\")\n",
    "plt.gca().spines[\"bottom\"].set_color(\"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save and show the plot\n",
    "forest_plot_path_spaced = f\"./download/{di}_spaced_combined_enrichment_analysis_forest_plot.pdf\"\n",
    "plt.savefig(forest_plot_path_spaced)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(enrichment_results_df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Filter disease dataframes based on the Dementia or the Alzheimer's Disease\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alzheimer_data_filtered=alzheimer_data.copy()\n",
    "alzheimer_data_filtered.columns\n",
    "\n",
    "# Diseases and their respective dataframes\n",
    "disease_dataframes = {\n",
    "    \"alzheimer\": alzheimer_data_filtered,\n",
    "    \"gram_negative\": gram_negative_data_filtered,\n",
    "    \"staphylococcus\": staphylococcus_data,\n",
    "    \"pseudomonas\": pseudomonas_data,\n",
    "    \"streptococcus\": streptococcus_data,\n",
    "    \"ecoli\": ecoli_data_filtered,\n",
    "    \"gram_positive\": gram_positive_data,\n",
    "    'retrovirus':retrovirus_data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter disease dataframes based on the person_id list from final_combined_df\n",
    "person_id_list = final_combined_df[\"person_id\"].tolist()\n",
    "\n",
    "disease_dataframes_filtered = {\n",
    "    disease: df[df[\"person_id\"].isin(person_id_list)].copy()\n",
    "    for disease, df in disease_dataframes.items()\n",
    "}\n",
    "\n",
    "# Function to count unique phecodes per month for each disease\n",
    "def count_unique_phecodes_per_month(data, disease_name):\n",
    "    \"\"\"\n",
    "    Count unique phecodes per person, grouped by month, for a specific disease.\n",
    "    A person's phecodes in the same month are counted as 1.\n",
    "\n",
    "    Parameters:\n",
    "        data (DataFrame): The disease dataframe with person_id, source_concept_code, and condition_start_datetime.\n",
    "        disease_name (str): Name of the disease for column naming.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Contains person_id and count of unique months with phecodes for this disease.\n",
    "    \"\"\"\n",
    "    # Ensure condition_start_datetime is in datetime format\n",
    "    data[\"condition_start_datetime\"] = pd.to_datetime(data[\"condition_start_datetime\"])\n",
    "\n",
    "    # Group by person_id and month-year (as 'year_month')\n",
    "    data[\"year_month\"] = data[\"condition_start_datetime\"].dt.to_period(\"M\")\n",
    "\n",
    "    # Group by person_id and year_month, then count unique phecodes (source_concept_code)\n",
    "    grouped = (\n",
    "        data.groupby([\"person_id\", \"year_month\"])[\"source_concept_code\"]\n",
    "        .nunique()  # Count unique phecodes per month\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # For each person, count the total number of months with phecodes\n",
    "    person_month_count = (\n",
    "        grouped.groupby(\"person_id\")[\"year_month\"]\n",
    "        .count()  # Count unique months\n",
    "        .reset_index()\n",
    "        .rename(columns={\"year_month\": f\"{disease_name}_count\"})\n",
    "    )\n",
    "\n",
    "    return person_month_count\n",
    "\n",
    "# Process each disease to calculate counts of unique phecodes per month\n",
    "phecode_counts_list = []\n",
    "for disease, df in disease_dataframes_filtered.items():\n",
    "    disease_counts = count_unique_phecodes_per_month(df, disease)\n",
    "    phecode_counts_list.append(disease_counts)\n",
    "\n",
    "# Combine all the disease-specific counts into a single dataframe\n",
    "from functools import reduce\n",
    "\n",
    "combined_phecode_counts = reduce(\n",
    "    lambda left, right: pd.merge(left, right, on=\"person_id\", how=\"outer\"),\n",
    "    phecode_counts_list,\n",
    ")\n",
    "# Step 4: Fill NaN values with 0\n",
    "combined_phecode_counts.fillna(0, inplace=True)\n",
    "# combined_phecode_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_id_with_alzheimer = combined_phecode_counts[combined_phecode_counts['alzheimer_count'] > 0]['person_id'].unique()\n",
    "len(person_id_with_alzheimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "person_id_with_alzheimer_pseudomonas = combined_phecode_counts[(combined_phecode_counts['alzheimer_count'] > 0) & (combined_phecode_counts['pseudomonas_count'] > 0)]['person_id'].unique()\n",
    "len(person_id_with_alzheimer_pseudomonas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_id_with_alzheimer_retrovirus = combined_phecode_counts[(combined_phecode_counts['alzheimer_count'] > 0) & (combined_phecode_counts['retrovirus_count'] > 0)]['person_id'].unique()\n",
    "len(person_id_with_alzheimer_retrovirus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Add a column for total infection count\n",
    "# Specify infection-related diseases\n",
    "infection_columns = [\"gram_negative_count\", \"staphylococcus_count\", \"pseudomonas_count\", \n",
    "                     \"streptococcus_count\", \"ecoli_count\", \"gram_positive_count\"]\n",
    "\n",
    "# Calculate the total infections for each person\n",
    "combined_phecode_counts[\"total_infections\"] = combined_phecode_counts[infection_columns].sum(axis=1)\n",
    "\n",
    "# Step 2: Add a column to classify individuals by infection level\n",
    "def classify_infection_level(row):\n",
    "    if row[\"total_infections\"] == 0:\n",
    "        return \"No infection\"\n",
    "    elif row[\"total_infections\"] == 1:\n",
    "        return \"1 infection\"\n",
    "    elif row[\"total_infections\"] == 2:\n",
    "        return \"2 infections\"\n",
    "    else:\n",
    "        return \"3+ infections\"\n",
    "\n",
    "combined_phecode_counts[\"infection_level\"] = combined_phecode_counts.apply(classify_infection_level, axis=1)\n",
    "\n",
    "# Step 3: Filter for individuals with Alzheimer's Disease\n",
    "ad_with_infections = combined_phecode_counts[combined_phecode_counts[\"alzheimer_count\"] > 0]\n",
    "\n",
    "# Step 4: Count individuals by infection level\n",
    "infection_summary = ad_with_infections[\"infection_level\"].value_counts().reset_index()\n",
    "infection_summary.columns = [\"Infection Level\", \"Count\"]\n",
    "\n",
    "# # Step 5: Display the results\n",
    "# print(infection_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Add a column for total infection count\n",
    "infection_columns = [\n",
    "    \"gram_negative_count\", \"staphylococcus_count\", \"pseudomonas_count\",\n",
    "    \"streptococcus_count\", \"ecoli_count\", \"gram_positive_count\"\n",
    "]\n",
    "\n",
    "# Calculate the total infections for each person\n",
    "combined_phecode_counts[\"total_infections\"] = combined_phecode_counts[infection_columns].sum(axis=1)\n",
    "\n",
    "# Correct the apply call to use the total_infections column directly\n",
    "def classify_infection_level(total_infections):\n",
    "    if total_infections == 0:\n",
    "        return \"No infection\"\n",
    "    elif total_infections == 1:\n",
    "        return \"1 infection\"\n",
    "    else:\n",
    "        return \"2+ infections\"\n",
    "\n",
    "# Apply the classification function to the total_infections column\n",
    "combined_phecode_counts[\"infection_level\"] = combined_phecode_counts[\"total_infections\"].apply(classify_infection_level)\n",
    "\n",
    "# Step 3: Filter for individuals with Alzheimer's Disease\n",
    "ad_with_infections = combined_phecode_counts[combined_phecode_counts[\"alzheimer_count\"] > 0]\n",
    "\n",
    "# Step 4: Count individuals by infection level\n",
    "infection_summary = ad_with_infections[\"infection_level\"].value_counts()\n",
    "\n",
    "# Step 5: Create a pie chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Define colors for each group\n",
    "colors = {\n",
    "    \"No infection\":\"#ff9999\",  # Red\n",
    "    \"1 infection\": \"#66b3ff\" , # Green\n",
    "    \"2+ infections\": \"#99ff99\" # Blue\n",
    "}\n",
    "\n",
    "# Plot the pie chart\n",
    "wedges, texts, autotexts = plt.pie(\n",
    "    infection_summary,\n",
    "    labels=infection_summary.index,\n",
    "    autopct='%1.1f%%',\n",
    "    colors=[colors[group] for group in infection_summary.index if group in colors],\n",
    "    startangle=90\n",
    ")\n",
    "plt.title(f'Distribution of infection in {di.lower()} patients with CDR age more than 60', fontsize=14)\n",
    "\n",
    "\n",
    "# Add a legend with the number of unique patients for each level\n",
    "legend_labels = [\n",
    "    f\"{level}, n={infection_summary[level]}\"\n",
    "    for level in [\"No infection\", \"1 infection\", \"2+ infections\",]\n",
    "]\n",
    "plt.legend(wedges, legend_labels, loc='upper right', bbox_to_anchor=(1, 0, 0.5, 1),frameon=False, fontsize=12)\n",
    "plt.tight_layout()\n",
    "# Save the pie chart\n",
    "output_path = f'./download/PIE_infection_levels_{di}.pdf'\n",
    "plt.savefig(output_path, dpi=300,bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# print(f'Pie chart saved at: {output_path}')\n",
    "print(f'The total amount of patients are : {len(final_combined_df)}')\n",
    "total_ad_patients = final_combined_df[final_combined_df[\"alzheimer\"] == 1][\"person_id\"].nunique()\n",
    "print(f\"Total Alzheimer's patients in final_combined_df: {total_ad_patients}\")\n",
    "# Filter Alzheimer's patients\n",
    "ad_combined_counts = combined_phecode_counts[combined_phecode_counts[\"person_id\"].isin(\n",
    "    final_combined_df[final_combined_df[\"alzheimer\"] == 1][\"person_id\"]\n",
    ")]\n",
    "\n",
    "# Count patients with \"No infection\"\n",
    "no_infection_count = ad_combined_counts[ad_combined_counts[\"total_infections\"] == 0][\"person_id\"].nunique()\n",
    "print(f\"Alzheimer's patients with 'No infection': {no_infection_count}\")\n",
    "\n",
    "\n",
    "\n",
    "# Recalculate total infections\n",
    "combined_phecode_counts[\"total_infections\"] = combined_phecode_counts[infection_columns].sum(axis=1)\n",
    "\n",
    "# Classify infection levels\n",
    "combined_phecode_counts[\"infection_level\"] = combined_phecode_counts[\"total_infections\"].apply(classify_infection_level)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Calculate the total non-Alzheimer patients\n",
    "total_patients = len(final_combined_df)\n",
    "total_ad_patients = final_combined_df[final_combined_df[\"alzheimer\"] == 1][\"person_id\"].nunique()\n",
    "total_no_ad_patients = total_patients - total_ad_patients\n",
    "\n",
    "print(f\"Total patients: {total_patients}\")\n",
    "print(f\"Total Alzheimer's patients: {total_ad_patients}\")\n",
    "print(f\"Total non-Alzheimer's patients: {total_no_ad_patients}\")\n",
    "\n",
    "# Step 2: Identify patients with no AD and no infections\n",
    "bacteria_columns = [\"gram_negative\", \"staphylococcus\", \"pseudomonas\", \"streptococcus\", \"ecoli\", \"gram_positive\", \"alzheimer\"]\n",
    "no_ad_no_infections_ids = final_combined_df[final_combined_df[bacteria_columns].sum(axis=1) == 0][\"person_id\"]\n",
    "\n",
    "print(f\"Patients with no AD and no infections: {len(no_ad_no_infections_ids)}\")\n",
    "\n",
    "# Step 3: Filter combined_phecode_counts for non-Alzheimer individuals\n",
    "no_ad_ids = final_combined_df[final_combined_df[\"alzheimer\"] == 0][\"person_id\"]\n",
    "no_alzheimer_counts = combined_phecode_counts[combined_phecode_counts[\"person_id\"].isin(no_ad_ids)].copy()\n",
    "\n",
    "# Step 4: Calculate total infections for these individuals\n",
    "infection_columns = [\"gram_negative_count\", \"staphylococcus_count\", \"pseudomonas_count\",\n",
    "                     \"streptococcus_count\", \"ecoli_count\", \"gram_positive_count\"]\n",
    "\n",
    "# Fill missing values in infection columns with 0\n",
    "no_alzheimer_counts[infection_columns] = no_alzheimer_counts[infection_columns].fillna(0)\n",
    "no_alzheimer_counts[\"total_infections\"] = no_alzheimer_counts[infection_columns].sum(axis=1)\n",
    "\n",
    "# Step 5: Classify infection levels\n",
    "def classify_infection_level(total_infections):\n",
    "    if total_infections == 0:\n",
    "        return \"No infection\"\n",
    "    elif total_infections == 1:\n",
    "        return \"1 infection\"\n",
    "    else:\n",
    "        return \"2+ infections\"\n",
    "\n",
    "no_alzheimer_counts[\"infection_level\"] = no_alzheimer_counts[\"total_infections\"].apply(classify_infection_level)\n",
    "\n",
    "# Step 6: Count individuals by infection level\n",
    "infection_summary_no_ad = no_alzheimer_counts[\"infection_level\"].value_counts()\n",
    "\n",
    "# Step 7: Adjust \"No infection\" count to include individuals with no AD or bacterial infections\n",
    "infection_summary_no_ad[\"No infection\"] += len(no_ad_no_infections_ids)\n",
    "\n",
    "# Step 8: Create a pie chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Define colors for each group\n",
    "colors = {\n",
    "    \"No infection\": \"#66b3ff\",  \n",
    "    \"1 infection\": \"#ff9999\",  \n",
    "    \"2+ infections\": \"#99ff99\" \n",
    "}\n",
    "\n",
    "# Plot the pie chart\n",
    "wedges, texts, autotexts = plt.pie(\n",
    "    infection_summary_no_ad,\n",
    "    labels=infection_summary_no_ad.index,\n",
    "    autopct='%1.1f%%',\n",
    "    colors=[colors[group] for group in infection_summary_no_ad.index if group in colors],\n",
    "    startangle=90\n",
    ")\n",
    "\n",
    "plt.title(f'Distribution of infection in non-{di.lower()} patients with CDR age more than 60', fontsize=14)\n",
    "# Add a legend with the number of unique patients for each level\n",
    "legend_labels = [\n",
    "    f\"{level}, n={infection_summary[level]}\"\n",
    "    for level in [\"No infection\", \"1 infection\", \"2+ infections\"]\n",
    "]\n",
    "plt.legend(wedges, legend_labels, loc='upper right', bbox_to_anchor=(1, 0, 0.5, 1),frameon=False, fontsize=12)\n",
    "plt.tight_layout()\n",
    "# Save the pie chart\n",
    "output_path = './download/PIE_infection_levels_no_alzheimer.pdf'\n",
    "plt.savefig(output_path, dpi=300,bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Pie chart saved at: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_age_at_diagnosis(data, disease_name, person_info):\n",
    "    \"\"\"\n",
    "    Calculate the age at disease diagnosis for each person, ensuring no duplicate diagnoses in the same month.\n",
    "    \"\"\"\n",
    "    # Ensure `condition_start_datetime` and `date_of_birth` are in datetime format\n",
    "    data['condition_start_datetime'] = pd.to_datetime(data['condition_start_datetime'], errors='coerce')\n",
    "    person_info['date_of_birth'] = pd.to_datetime(person_info['date_of_birth'], errors='coerce')\n",
    "\n",
    "    # Drop rows where `condition_start_datetime` could not be parsed\n",
    "    data = data.dropna(subset=['condition_start_datetime'])\n",
    "\n",
    "    # Convert both to timezone-naive\n",
    "    data['condition_start_datetime'] = data['condition_start_datetime'].dt.tz_localize(None)\n",
    "    person_info['date_of_birth'] = person_info['date_of_birth'].dt.tz_localize(None)\n",
    "\n",
    "    # Extract the year and month of diagnosis\n",
    "    data['diagnosis_year_month'] = data['condition_start_datetime'].dt.to_period('M')\n",
    "\n",
    "    # Drop duplicate diagnoses for the same person and disease in the same month\n",
    "    data = data.drop_duplicates(subset=['person_id', 'diagnosis_year_month'])\n",
    "\n",
    "    # Merge with `person_info` to get date_of_birth and age\n",
    "    merged_data = data.merge(person_info, on='person_id', how='left')\n",
    "\n",
    "    # Calculate the age at diagnosis\n",
    "    merged_data['age_at_diagnosis'] = (\n",
    "        (merged_data['condition_start_datetime'] - merged_data['date_of_birth']).dt.days / 365.25\n",
    "    )\n",
    "\n",
    "    # Add disease name for clarity\n",
    "    merged_data['disease_name'] = disease_name\n",
    "\n",
    "    # Select relevant columns\n",
    "    age_data = merged_data[['person_id', 'age_at_diagnosis', 'disease_name', 'age', 'diagnosis_year_month','date_of_birth']]\n",
    "\n",
    "    return age_data\n",
    "\n",
    "\n",
    "\n",
    "# Assume `person_info` contains `person_id`, `date_of_birth`, and `age`\n",
    "person_info = final_combined_df[['person_id', 'date_of_birth', 'age']].copy()\n",
    "\n",
    "# Calculate age at diagnosis for each disease and combine results\n",
    "all_diagnoses = []\n",
    "for disease, df in disease_dataframes.items():\n",
    "    age_data = calculate_age_at_diagnosis(df, disease, person_info)\n",
    "    all_diagnoses.append(age_data)\n",
    "\n",
    "# Combine all diseases into a single DataFrame\n",
    "combined_age_data = pd.concat(all_diagnoses, ignore_index=True)\n",
    "\n",
    "# Remove rows with NaN values in the 'age' or 'age_at_diagnosis' columns\n",
    "combined_age_data_cleaned = combined_age_data.dropna(subset=['age', 'age_at_diagnosis'])\n",
    "# combined_age_data_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter out rows with retrovirus-related infections or disease we want to remove from the counting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows with retrovirus-related infections\n",
    "disease_keywords = ['retrovirus']  # Define retrovirus-related keywords\n",
    "disease_pattern = '|'.join(disease_keywords)  # Create a regex pattern for filtering\n",
    "\n",
    "# Remove rows where 'disease_name' contains retrovirus-related terms\n",
    "combined_age_data_filtered = combined_age_data[\n",
    "    ~combined_age_data['disease_name'].str.contains(disease_pattern, case=False, na=False)\n",
    "]\n",
    "# combined_age_data_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove those that are not in the list of age we picked before :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Remove rows where 'person_id' is not in 'person_id_list'\n",
    "combined_age_data_filtered = combined_age_data_filtered[\n",
    "    combined_age_data_filtered['person_id'].isin(person_id_list)\n",
    "]\n",
    "\n",
    "# Verify the updated dataset\n",
    "print(f\"Total rows after filtering: {len(combined_age_data_filtered)}\")\n",
    "print(f\"Unique person_id count: {combined_age_data_filtered['person_id'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Kaplan-Meier plot and survival data\n",
    "group_survival_data = {}\n",
    "group_labels = {\n",
    "    \"0\": \"0 Infections\",\n",
    "    \"1\": \"1 Infection\",\n",
    "    \"2\": \"2 Infections\",\n",
    "    \"3+\": \"3+ Infections\"\n",
    "}\n",
    "# for group in ['0', '1', '2', '3+']:\n",
    "#     group_data = ad_first_diagnosis[ad_first_diagnosis['infection_group'] == group]\n",
    "#     group_survival_data[group] = group_data['first_ad_age']\n",
    "#     kmf.fit(\n",
    "#         durations=group_data['first_ad_age'], \n",
    "#         event_observed=[1] * len(group_data),  # Assume all events observed\n",
    "#         label=f\"{group_labels[group]}, n={len(group_data)}\"\n",
    "#     )\n",
    "#     kmf.plot_survival_function(color=colors[group], ci_show=False)\n",
    "\n",
    "# Log-Rank Test\n",
    "log_rank_results = []\n",
    "groups = ['0', '1', '2', '3+']\n",
    "for i in range(len(groups)):\n",
    "    for j in range(i + 1, len(groups)):\n",
    "        group_1, group_2 = groups[i], groups[j]\n",
    "        if group_1 in group_survival_data and group_2 in group_survival_data:\n",
    "            result = logrank_test(\n",
    "                group_survival_data[group_1],\n",
    "                group_survival_data[group_2]\n",
    "            )\n",
    "            log_rank_results.append((group_1, group_2, result.p_value))\n",
    "\n",
    "log_rank_comparisons = pd.DataFrame(\n",
    "    log_rank_results,\n",
    "    columns=[\"Group_1\", \"Group_2\", \"P_Value\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Count total occurrences for each infection\n",
    "infection_counts = combined_age_data_filtered['disease_name'].value_counts()\n",
    "\n",
    "# Step 2: Filter individuals with and without Alzheimer's diagnosis\n",
    "# Identify individuals with Alzheimer's\n",
    "alzheimers_patients = combined_age_data_filtered.loc[\n",
    "    combined_age_data_filtered['disease_name'].str.contains('alzheimer', case=False), 'person_id'\n",
    "].unique()\n",
    "\n",
    "# Split data into with and without Alzheimer's\n",
    "with_alzheimers = combined_age_data_filtered[combined_age_data_filtered['person_id'].isin(alzheimers_patients)]\n",
    "without_alzheimers = combined_age_data_filtered[~combined_age_data_filtered['person_id'].isin(alzheimers_patients)]\n",
    "\n",
    "# Step 3: Count infections for each person and classify by infection count\n",
    "def classify_infections(df):\n",
    "    infection_counts_per_person = df.groupby('person_id')['disease_name'].nunique()\n",
    "    one_infection = infection_counts_per_person[infection_counts_per_person == 1].count()\n",
    "    two_or_more_infections = infection_counts_per_person[infection_counts_per_person >= 2].count()\n",
    "    return one_infection, two_or_more_infections\n",
    "\n",
    "# Classify infections for individuals with Alzheimer's\n",
    "with_alz_one_infection, with_alz_two_or_more = classify_infections(with_alzheimers)\n",
    "\n",
    "# Classify infections for individuals without Alzheimer's\n",
    "without_alz_one_infection, without_alz_two_or_more = classify_infections(without_alzheimers)\n",
    "\n",
    "# Results\n",
    "print(\"Total infections:\")\n",
    "print(infection_counts)\n",
    "\n",
    "print(\"\\nWith Alzheimer's:\")\n",
    "print(f\"  Individuals with one infection: {with_alz_one_infection}\")\n",
    "print(f\"  Individuals with two or more infections: {with_alz_two_or_more}\")\n",
    "\n",
    "print(\"\\nWithout Alzheimer's:\")\n",
    "print(f\"  Individuals with one infection: {without_alz_one_infection}\")\n",
    "print(f\"  Individuals with two or more infections: {without_alz_two_or_more}\")\n",
    "# Step 1: Count total occurrences for each infection\n",
    "infection_counts = combined_age_data_filtered['disease_name'].value_counts()\n",
    "\n",
    "# Step 2: Filter individuals with and without Alzheimer's diagnosis\n",
    "# Identify individuals with Alzheimer's\n",
    "alzheimers_patients = combined_age_data_filtered.loc[\n",
    "    combined_age_data_filtered['disease_name'].str.contains('alzheimer', case=False), 'person_id'\n",
    "].unique()\n",
    "\n",
    "# Split data into with and without Alzheimer's\n",
    "with_alzheimers = combined_age_data_filtered[combined_age_data_filtered['person_id'].isin(alzheimers_patients)]\n",
    "without_alzheimers = combined_age_data_filtered[~combined_age_data_filtered['person_id'].isin(alzheimers_patients)]\n",
    "\n",
    "# Step 3: Count infections for each person and classify by infection count\n",
    "def classify_infections(df):\n",
    "    infection_counts_per_person = df.groupby('person_id')['disease_name'].nunique()\n",
    "    one_infection = infection_counts_per_person[infection_counts_per_person == 1].count()\n",
    "    two_or_more_infections = infection_counts_per_person[infection_counts_per_person >= 2].count()\n",
    "    return one_infection, two_or_more_infections\n",
    "\n",
    "# Classify infections for individuals with Alzheimer's\n",
    "with_alz_one_infection, with_alz_two_or_more = classify_infections(with_alzheimers)\n",
    "\n",
    "# Classify infections for individuals without Alzheimer's\n",
    "without_alz_one_infection, without_alz_two_or_more = classify_infections(without_alzheimers)\n",
    "\n",
    "# Results\n",
    "print(\"Total infections:\")\n",
    "print(infection_counts)\n",
    "\n",
    "print(\"\\nWith Alzheimer's:\")\n",
    "print(f\"  Individuals with one infection: {with_alz_one_infection}\")\n",
    "print(f\"  Individuals with two or more infections: {with_alz_two_or_more}\")\n",
    "\n",
    "print(\"\\nWithout Alzheimer's:\")\n",
    "print(f\"  Individuals with one infection: {without_alz_one_infection}\")\n",
    "print(f\"  Individuals with two or more infections: {without_alz_two_or_more}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "# Step 4: Classify individuals by disease for 1 infection or 2+ infections\n",
    "def classify_infections_by_disease(df):\n",
    "    results = defaultdict(lambda: {'one_infection': 0, 'two_or_more': 0})\n",
    "    grouped = df.groupby(['person_id', 'disease_name'])['disease_name'].count()\n",
    "\n",
    "    for person_disease, count in grouped.items():  # Updated from iteritems() to items()\n",
    "        _, disease = person_disease\n",
    "        if count == 1:\n",
    "            results[disease]['one_infection'] += 1\n",
    "        else:\n",
    "            results[disease]['two_or_more'] += 1\n",
    "    return results\n",
    "\n",
    "# With Alzheimer's: Classify individuals by disease\n",
    "with_alz_results = classify_infections_by_disease(with_alzheimers)\n",
    "\n",
    "# Without Alzheimer's: Classify individuals by disease\n",
    "without_alz_results = classify_infections_by_disease(without_alzheimers)\n",
    "\n",
    "# Convert the results to a more readable format\n",
    "def format_results(results):\n",
    "    formatted = []\n",
    "    for disease, counts in results.items():\n",
    "        formatted.append({\n",
    "            'Disease': disease,\n",
    "            'One Infection': counts['one_infection'],\n",
    "            'Two or More Infections': counts['two_or_more'],\n",
    "        })\n",
    "    return pd.DataFrame(formatted)\n",
    "\n",
    "with_alz_df = format_results(with_alz_results)\n",
    "without_alz_df = format_results(without_alz_results)\n",
    "\n",
    "# Display the results\n",
    "print(\"With Alzheimer's:\")\n",
    "display(with_alz_df)\n",
    "\n",
    "print(\"\\nWithout Alzheimer's:\")\n",
    "display(without_alz_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the infection levels into the dataset\n",
    "infection_levels = combined_phecode_counts[[\"person_id\", \"infection_level\"]]\n",
    "ad_first_diagnosis = ad_first_diagnosis.merge(infection_levels, on=\"person_id\", how=\"left\")\n",
    "\n",
    "# Categorize infection groups for consistency\n",
    "ad_first_diagnosis[\"infection_group\"] = ad_first_diagnosis[\"infection_level\"]\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Count bacterial infections for each person\n",
    "bacteria_list = ['staphylococcus', 'ecoli', 'pseudomonas', 'gram_negative', 'gram_positive', 'streptococcus']\n",
    "bacteria_counts = (\n",
    "    combined_age_data_cleaned[\n",
    "        combined_age_data_cleaned['disease_name'].isin(bacteria_list)\n",
    "    ]\n",
    "    .groupby('person_id')['disease_name']\n",
    "    .nunique()\n",
    "    .reset_index()\n",
    "    .rename(columns={'disease_name': 'bacteria_infections'})\n",
    ")\n",
    "\n",
    "# Step 2: Identify the first AD diagnosis for each person\n",
    "ad_data = combined_age_data_cleaned[combined_age_data_cleaned['disease_name'] == 'alzheimer']\n",
    "ad_first_diagnosis = (\n",
    "    ad_data.groupby('person_id')['age_at_diagnosis']\n",
    "    .min()\n",
    "    .reset_index()\n",
    "    .rename(columns={'age_at_diagnosis': 'first_ad_age'})\n",
    ")\n",
    "\n",
    "# Step 3: Merge bacterial infection counts with first AD diagnosis age\n",
    "ad_first_diagnosis = ad_first_diagnosis.merge(bacteria_counts, on='person_id', how='left').fillna(0)\n",
    "\n",
    "# Step 4: Filter by minimum age at first AD diagnosis\n",
    "min_first_ad_age = 0\n",
    "ad_first_diagnosis = ad_first_diagnosis[ad_first_diagnosis['first_ad_age'] > min_first_ad_age]\n",
    "\n",
    "# Step 5: Categorize into infection groups\n",
    "ad_first_diagnosis['infection_group'] = ad_first_diagnosis['bacteria_infections'].apply(\n",
    "    lambda x: '0' if x == 0 else ('1' if x == 1 else ('2' if x == 2 else \"3+\"))\n",
    ")\n",
    "\n",
    "# Step 6: Perform Kaplan-Meier Analysis\n",
    "kmf = KaplanMeierFitter()\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = {'0': 'blue', '1': 'purple', '2': 'green', '3+': 'red'}\n",
    "\n",
    "# Add general dementia line\n",
    "kmf.fit(\n",
    "    durations=ad_first_diagnosis['first_ad_age'],\n",
    "    event_observed=[1] * len(ad_first_diagnosis),\n",
    "    label=\"Dementia (All Patients)\"\n",
    ")\n",
    "kmf.plot_survival_function(color='black', linestyle='--', linewidth=2, ci_show=False)\n",
    "\n",
    "# Prepare Kaplan-Meier plot and survival data\n",
    "group_survival_data = {}\n",
    "group_labels = {\n",
    "    \"0\": \"0 Infections\",\n",
    "    \"1\": \"1 Infection\",\n",
    "    \"2\": \"2 Infections\",\n",
    "    \"3+\": \"3+ Infections\"\n",
    "}\n",
    "for group in ['0', '1', '2', '3+']:\n",
    "    group_data = ad_first_diagnosis[ad_first_diagnosis['infection_group'] == group]\n",
    "    group_survival_data[group] = group_data['first_ad_age']\n",
    "    kmf.fit(\n",
    "        durations=group_data['first_ad_age'], \n",
    "        event_observed=[1] * len(group_data),  # Assume all events observed\n",
    "        label=f\"{group_labels[group]}, n={len(group_data)}\"\n",
    "    )\n",
    "    kmf.plot_survival_function(color=colors[group], ci_show=False)\n",
    "\n",
    "# Log-Rank Test\n",
    "log_rank_results = []\n",
    "groups = ['0', '1', '2', '3+']\n",
    "for i in range(len(groups)):\n",
    "    for j in range(i + 1, len(groups)):\n",
    "        group_1, group_2 = groups[i], groups[j]\n",
    "        if group_1 in group_survival_data and group_2 in group_survival_data:\n",
    "            result = logrank_test(\n",
    "                group_survival_data[group_1],\n",
    "                group_survival_data[group_2]\n",
    "            )\n",
    "            log_rank_results.append((group_1, group_2, result.p_value))\n",
    "\n",
    "log_rank_comparisons = pd.DataFrame(\n",
    "    log_rank_results,\n",
    "    columns=[\"Group_1\", \"Group_2\", \"P_Value\"]\n",
    ")\n",
    "\n",
    "# Enhance the plot\n",
    "plt.title('Kaplan-Meier Plot for First AD Diagnosis Age by Infection Group', fontsize=16)\n",
    "plt.xlabel('Age at First AD Diagnosis', fontsize=14)\n",
    "plt.ylabel('Survival Probability', fontsize=14)\n",
    "plt.legend(title='Infection Group', fontsize=12, frameon=False)\n",
    "plt.grid(False)\n",
    "\n",
    "# Customize plot aesthetics\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_color('black')\n",
    "ax.spines['bottom'].set_color('black')\n",
    "ax.spines['left'].set_linewidth(2)\n",
    "ax.spines['bottom'].set_linewidth(2)\n",
    "\n",
    "# Save the plot\n",
    "output_path = \"./download/first_ad_diagnosis_by_infection_group_with_logrank.pdf\"\n",
    "plt.savefig(output_path, bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"Kaplan-Meier plot saved at:\", output_path)\n",
    "\n",
    "# Display log-rank test results\n",
    "print(\"\\nLog-Rank Test Results:\")\n",
    "print(log_rank_comparisons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_first_ad_age = 0\n",
    "# Step 1: Count total bacterial infections for each person\n",
    "bacteria_list = ['staphylococcus', 'ecoli', 'pseudomonas', 'gram_negative', 'gram_positive', 'streptococcus']\n",
    "bacteria_counts = (\n",
    "    combined_age_data_cleaned[\n",
    "        combined_age_data_cleaned['disease_name'].isin(bacteria_list)\n",
    "    ]\n",
    "    .groupby('person_id')['disease_name']\n",
    "    .count()  # Count total infections (including duplicates)\n",
    "    .reset_index()\n",
    "    .rename(columns={'disease_name': 'bacteria_infections'})\n",
    ")\n",
    "\n",
    "# Step 2: Identify the first AD diagnosis for each person\n",
    "ad_data = combined_age_data_cleaned[combined_age_data_cleaned['disease_name'] == 'alzheimer']\n",
    "ad_first_diagnosis = (\n",
    "    ad_data.groupby('person_id')['age_at_diagnosis']\n",
    "    .min()\n",
    "    .reset_index()\n",
    "    .rename(columns={'age_at_diagnosis': 'first_ad_age'})\n",
    ")\n",
    "\n",
    "# Step 3: Merge bacterial infection counts with first AD diagnosis age\n",
    "ad_first_diagnosis = ad_first_diagnosis.merge(bacteria_counts, on='person_id', how='left').fillna(0)\n",
    "\n",
    "# Step 4: Filter by minimum age at first AD diagnosis\n",
    "\n",
    "ad_first_diagnosis = ad_first_diagnosis[ad_first_diagnosis['first_ad_age'] > min_first_ad_age]\n",
    "\n",
    "# Step 5: Categorize into infection groups\n",
    "ad_first_diagnosis['infection_group'] = ad_first_diagnosis['bacteria_infections'].apply(\n",
    "    lambda x: '0' if x == 0 else ('1' if x == 1 else ('2' if x == 2 else \"3+\"))\n",
    ")\n",
    "\n",
    "# Step 6: Perform Kaplan-Meier Analysis\n",
    "kmf = KaplanMeierFitter()\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = {'0': 'blue', '1': 'purple', '2': 'green', '3+': 'red'}\n",
    "# Add general dementia line\n",
    "kmf.fit(\n",
    "    durations=ad_first_diagnosis['first_ad_age'],\n",
    "    event_observed=[1] * len(ad_first_diagnosis),\n",
    "    label=f\"{di}\"\n",
    ")\n",
    "kmf.plot_survival_function(color='black', linestyle='--', linewidth=2,ci_show=False)\n",
    "# Log-Rank Test\n",
    "log_rank_results = []\n",
    "groups = ['0', '1', '2', '3+']\n",
    "for i in range(len(groups)):\n",
    "    for j in range(i + 1, len(groups)):\n",
    "        group_1, group_2 = groups[i], groups[j]\n",
    "        if group_1 in group_survival_data and group_2 in group_survival_data:\n",
    "            result = logrank_test(\n",
    "                group_survival_data[group_1],\n",
    "                group_survival_data[group_2]\n",
    "            )\n",
    "            log_rank_results.append((group_1, group_2, result.p_value))\n",
    "\n",
    "log_rank_comparisons = pd.DataFrame(\n",
    "    log_rank_results,\n",
    "    columns=[\"Group_1\", \"Group_2\", \"P_Value\"]\n",
    ")\n",
    "\n",
    "# Create custom legend labels with p-values\n",
    "group_labels = {}\n",
    "for group in groups:\n",
    "    if group == '0':\n",
    "        group_labels[group] = f\"{group} Infections (n={len(ad_first_diagnosis[ad_first_diagnosis['infection_group'] == group])})\"\n",
    "    else:\n",
    "        p_val = min([res[2] for res in log_rank_results if res[0] == '0' and res[1] == group])\n",
    "        group_labels[group] = f\"{group} Infections (n={len(ad_first_diagnosis[ad_first_diagnosis['infection_group'] == group])}, p={p_val:.4e})\"\n",
    "\n",
    "# Prepare Kaplan-Meier plot and survival data\n",
    "group_survival_data = {}\n",
    "for group in ['0', '1', '2', '3+']:\n",
    "    group_data = ad_first_diagnosis[ad_first_diagnosis['infection_group'] == group]\n",
    "    group_survival_data[group] = group_data['first_ad_age']\n",
    "    kmf.fit(\n",
    "        durations=group_data['first_ad_age'], \n",
    "        event_observed=[1] * len(group_data),  # Assume all events observed\n",
    "        label=group_labels[group]\n",
    "    )\n",
    "    kmf.plot_survival_function(color=colors[group], ci_show=False)\n",
    "\n",
    "# Enhance the plot\n",
    "plt.title(f'Kaplan-Meier plot for first {di} diagnosis age by infection group', fontsize=16)\n",
    "plt.xlabel(f'Age at first {di} diagnosis', fontsize=14)\n",
    "plt.ylabel('Survival probability', fontsize=14)\n",
    "plt.legend(title='Infection group', fontsize=12, frameon=False)\n",
    "plt.grid(False)\n",
    "\n",
    "# Customize plot aesthetics\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_color('black')\n",
    "ax.spines['bottom'].set_color('black')\n",
    "ax.spines['left'].set_linewidth(2)\n",
    "ax.spines['bottom'].set_linewidth(2)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "reversed_survival_plot_path = f\"./download/first_ad_diagnosis_by_infection_group_with_logrank_{di}.pdf\"\n",
    "plt.savefig(reversed_survival_plot_path, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Group data by 'infection_group'\n",
    "summary_stats = (\n",
    "    ad_first_diagnosis.groupby('infection_group')['first_ad_age']\n",
    "    .agg(\n",
    "        Mean='mean',\n",
    "        Median='median',\n",
    "        Min='min',\n",
    "        Count='count'\n",
    "    )\n",
    "    .reset_index()\n",
    "    .rename(columns={'infection_group': 'Infection Group'})\n",
    ")\n",
    "\n",
    "# Display the summary statistics table\n",
    "print(summary_stats)\n",
    "\n",
    "# Save the table to a CSV file for further use if needed\n",
    "summary_stats_path = f\"./download/summary_statistics_first_dementia_by_infection_group_{di}.csv\"\n",
    "summary_stats.to_csv(summary_stats_path, index=False)\n",
    "print(f\"Summary statistics saved to: {summary_stats_path}\")\n",
    "# summary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom aggregation function to compute additional statistics\n",
    "def extended_stats(group):\n",
    "    return pd.Series({\n",
    "        'Mean': group.mean(),\n",
    "        'Median': group.median(),\n",
    "        'Min': group.min(),\n",
    "        'Max': group.max(),\n",
    "        'Std Dev': group.std(),\n",
    "        'Variance': group.var(),\n",
    "        '25th Percentile': group.quantile(0.25),\n",
    "        '75th Percentile': group.quantile(0.75),\n",
    "        'IQR': group.quantile(0.75) - group.quantile(0.25),\n",
    "        'Skewness': skew(group),\n",
    "        'Kurtosis': kurtosis(group),\n",
    "        'Mode': group.mode().iloc[0] if not group.mode().empty else None,\n",
    "        'Count': group.count()\n",
    "    })\n",
    "\n",
    "# Apply the function to each infection group\n",
    "detailed_stats = (\n",
    "    ad_first_diagnosis.groupby('infection_group')['first_ad_age']\n",
    "    .apply(extended_stats)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Display the detailed statistics table\n",
    "print(detailed_stats)\n",
    "\n",
    "# Save the detailed statistics to a CSV file\n",
    "detailed_stats_path = f\"./download/detailed_statistics_first_dementia_by_infection_group_{di}.csv\"\n",
    "detailed_stats.to_csv(detailed_stats_path, index=False)\n",
    "print(f\"Detailed statistics saved to: {detailed_stats_path}\")\n",
    "\n",
    "\n",
    "# Create the box plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(\n",
    "    data=ad_first_diagnosis,\n",
    "    x='infection_group',\n",
    "    y='first_ad_age',\n",
    "    palette='coolwarm',\n",
    "    order=['0', '1', '2', '3+']  # Ensure consistent order\n",
    ")\n",
    "\n",
    "# Enhance the aesthetics\n",
    "plt.title(\"Dementia Onset Age by Infection Group\", fontsize=16)\n",
    "plt.xlabel(\"Infection Group\", fontsize=14)\n",
    "plt.ylabel(\"Age at First Dementia Diagnosis\", fontsize=14)\n",
    "\n",
    "# Add annotations for descriptive statistics\n",
    "for i, group in enumerate(['0', '1', '2', '3+']):\n",
    "    group_data = ad_first_diagnosis[ad_first_diagnosis['infection_group'] == group]['first_ad_age']\n",
    "    mean_age = group_data.mean()\n",
    "    median_age = group_data.median()\n",
    "#     plt.text(i, mean_age, f\"Mean: {mean_age:.1f}\", color=\"black\", ha=\"center\", va=\"top\", fontsize=10)\n",
    "#     plt.text(i, median_age, f\"Median: {median_age:.1f}\", color=\"blue\", ha=\"center\", va=\"bottom\", fontsize=10)\n",
    "\n",
    "# Customize gridlines and spines\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_color('black')\n",
    "ax.spines['bottom'].set_color('black')\n",
    "ax.spines['left'].set_linewidth(2)\n",
    "ax.spines['bottom'].set_linewidth(2)\n",
    "\n",
    "# Adjust tick parameters\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# Save the plot\n",
    "output_path = \"./download/dementia_onset_age_by_infection_group_boxplot.pdf\"\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_path, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Box plot saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) One-Way ANOVA (for more than two groups): Checks for significant differences in mean dementia onset age among all infection groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import f_oneway\n",
    "# from scipy.stats import skew, kurtosis\n",
    "# from lifelines import KaplanMeierFitter\n",
    "# import matplotlib.lines as mlines\n",
    "# from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Group ages by infection groups\n",
    "group_ages = [ad_first_diagnosis[ad_first_diagnosis['infection_group'] == group]['first_ad_age']\n",
    "              for group in ['0', '1', '2', '3+']]\n",
    "\n",
    "# Perform ANOVA\n",
    "anova_result = f_oneway(*group_ages)\n",
    "\n",
    "print(f\"ANOVA Results: F-statistic = {anova_result.statistic:.4f}, P-value = {anova_result.pvalue:.4e}\")\n",
    "\n",
    "if anova_result.pvalue < 0.05:\n",
    "    print(\"Significant difference in dementia onset age between infection groups.\")\n",
    "else:\n",
    "    print(\"No significant difference in dementia onset age between infection groups.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# # Perform Tukey HSD test\n",
    "# tukey_result = pairwise_tukeyhsd(\n",
    "#     ad_first_diagnosis['first_ad_age'], ad_first_diagnosis['infection_group']\n",
    "# )\n",
    "\n",
    "# print(tukey_result)\n",
    "\n",
    "# # Plot Tukey results\n",
    "# tukey_result.plot_simultaneous()\n",
    "# plt.title(\"Tukey HSD: Dementia Onset Age by Infection Group\", fontsize=16)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "# from scipy.stats import f_oneway\n",
    "# from scipy.stats import skew, kurtosis\n",
    "# from lifelines import KaplanMeierFitter\n",
    "# import matplotlib.lines as mlines\n",
    "# from statsmodels.stats.multitest import multipletests\n",
    "# Perform Tukey HSD test\n",
    "tukey_result = pairwise_tukeyhsd(\n",
    "    ad_first_diagnosis['first_ad_age'], ad_first_diagnosis['infection_group']\n",
    ")\n",
    "\n",
    "print(tukey_result)\n",
    "\n",
    "# Plot Tukey results\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "tukey_result.plot_simultaneous(ax=ax, figsize=(10, 6))\n",
    "\n",
    "# Enhance plot aesthetics\n",
    "ax.set_title(f\"Tukey HSD: {di} onset age by infection group\", fontsize=16)\n",
    "ax.set_xlabel(f\"Mean difference onset age of {di} (95% CI)\", fontsize=14)\n",
    "ax.set_ylabel(\"Infection group comparison\", fontsize=14)\n",
    "ax.grid(False)  # Remove grid\n",
    "\n",
    "# Customize spines\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_color('black')\n",
    "ax.spines['bottom'].set_color('black')\n",
    "ax.spines['left'].set_linewidth(2)\n",
    "ax.spines['bottom'].set_linewidth(2)\n",
    "\n",
    "# Adjust ticks\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "# Save the plot\n",
    "output_path = f\"./download/Tukey_pairwise_comparison_{di}.pdf\"\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_path, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# print(f\"Tukey HSD plot saved to: {output_path}\")\n",
    "# detailed_stats_path = f\"./download/Tukey HSD analysis for the mean {di}.tsv\"\n",
    "# tukey_result.to_csv(detailed_stats_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If i want to test the median age : I need a different approach because Tukey HSD does not work with medians. Medians are often used when:\n",
    "IF :\n",
    "The data is not normally distributed.\n",
    "There are outliers that heavily skew the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import mannwhitneyu\n",
    "# import itertools\n",
    "# from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "# from scipy.stats import f_oneway\n",
    "# from scipy.stats import skew, kurtosis\n",
    "# from lifelines import KaplanMeierFitter\n",
    "# import matplotlib.lines as mlines\n",
    "# from statsmodels.stats.multitest import multipletests\n",
    "# Get unique groups\n",
    "groups = ad_first_diagnosis['infection_group'].unique()\n",
    "\n",
    "# Perform pairwise Wilcoxon (Mann-Whitney U) tests\n",
    "results = []\n",
    "for group1, group2 in itertools.combinations(groups, 2):\n",
    "    group1_data = ad_first_diagnosis[ad_first_diagnosis['infection_group'] == group1]['first_ad_age']\n",
    "    group2_data = ad_first_diagnosis[ad_first_diagnosis['infection_group'] == group2]['first_ad_age']\n",
    "    stat, p_value = mannwhitneyu(group1_data, group2_data, alternative='two-sided')\n",
    "    results.append((group1, group2, stat, p_value))\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results, columns=['Group 1', 'Group 2', 'Statistic', 'P-Value'])\n",
    "print(results_df)\n",
    "# Save the detailed statistics to a CSV file\n",
    "detailed_stats_path = f\"./download/pairwise Wilcoxon (Mann-Whitney U) analysis for the median_{di}.tsv\"\n",
    "results_df.to_csv(detailed_stats_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statsmodels.formula.api as smf\n",
    "# from scipy.stats import mannwhitneyu\n",
    "# import itertools\n",
    "# from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "# from scipy.stats import f_oneway\n",
    "# from scipy.stats import skew, kurtosis\n",
    "# from lifelines import KaplanMeierFitter\n",
    "# import matplotlib.lines as mlines\n",
    "# from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Perform quantile regression for the median\n",
    "model = smf.quantreg('first_ad_age ~ C(infection_group)', ad_first_diagnosis).fit(q=0.5)\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_patients = len(final_combined_df)\n",
    "total_ad_patients = final_combined_df[final_combined_df[\"alzheimer\"] == 1][\"person_id\"].nunique()\n",
    "total_no_ad_patients = total_patients - total_ad_patients\n",
    "total_no_ad_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bacterial_data_age = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "# import statsmodels.formula.api as smf\n",
    "# from scipy.stats import mannwhitneyu\n",
    "# import itertools\n",
    "# from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "# from scipy.stats import f_oneway\n",
    "# from scipy.stats import skew, kurtosis\n",
    "# from lifelines import KaplanMeierFitter\n",
    "# import matplotlib.lines as mlines\n",
    "# from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "\n",
    "# Step 1: Define bacterial infections\n",
    "bacterial_infections = ['staphylococcus', 'ecoli', 'pseudomonas', \n",
    "                        'gram_negative', 'gram_positive', 'streptococcus']\n",
    "\n",
    "# Step 2: Filter bacterial data for individuals older than 65\n",
    "bacterial_data = combined_age_data_filtered[\n",
    "    (combined_age_data_filtered['disease_name'].str.contains('|'.join(bacterial_infections), case=False, na=False)) &\n",
    "    (combined_age_data_filtered['age'] > bacterial_data_age)  # Age filter\n",
    "]\n",
    "\n",
    "# Step 3: Identify individuals with Alzheimer's\n",
    "alzheimers_patients = combined_age_data_filtered.loc[\n",
    "    (combined_age_data_filtered['disease_name'].str.contains('alzheimer', case=False, na=False)) &\n",
    "    (combined_age_data_filtered['age'] > bacterial_data_age),  # Age filter for Alzheimer's patients\n",
    "    'person_id'\n",
    "].unique()\n",
    "# Step 4: Split bacterial data into with and without Alzheimer's\n",
    "with_alzheimers = bacterial_data[bacterial_data['person_id'].isin(alzheimers_patients)]\n",
    "without_alzheimers = bacterial_data[~bacterial_data['person_id'].isin(alzheimers_patients)]\n",
    "\n",
    "# Step 5: Identify individuals with Alzheimer's but no bacterial infections\n",
    "alz_with_no_infections = set(alzheimers_patients) - set(with_alzheimers['person_id'])\n",
    "\n",
    "# Step 6: Count infections and classify\n",
    "def classify_infections_v2(df, total_patients):\n",
    "    infection_counts = df.groupby(['person_id', 'disease_name']).size()\n",
    "    grouped_counts = infection_counts.groupby(level=0).sum()  # Total infections per person\n",
    "    multiple_same_disease = infection_counts[infection_counts > 1].groupby(level=0).count()  # Patients with >1 infection of same disease\n",
    "\n",
    "    one_infection = grouped_counts[grouped_counts == 1].index\n",
    "    two_or_more_infections = set(grouped_counts[grouped_counts > 1].index) | set(multiple_same_disease.index)\n",
    "\n",
    "    zero_infections = set(total_patients) - set(df['person_id'])\n",
    "\n",
    "    return len(zero_infections), len(one_infection), len(two_or_more_infections)\n",
    "\n",
    "# Total unique Alzheimers patients\n",
    "total_alz_patients = set(alzheimers_patients)\n",
    "\n",
    "# Classify infections for individuals with Alzheimer's\n",
    "alz_zero, alz_one, alz_two_or_more = classify_infections_v2(with_alzheimers, total_alz_patients)\n",
    "\n",
    "# Total unique patients without Alzheimer's\n",
    "total_non_alz_patients = set(combined_age_data_filtered['person_id']) - total_alz_patients\n",
    "\n",
    "# Classify infections for individuals without Alzheimer's\n",
    "non_alz_zero, non_alz_one, non_alz_two_or_more = classify_infections_v2(without_alzheimers, total_non_alz_patients)\n",
    "\n",
    "# Step 7: Results\n",
    "print(\"Bacterial Infections Only:\")\n",
    "print(\"\\nWith Alzheimer's:\")\n",
    "print(f\"  Individuals with 0 infections: {alz_zero}\")\n",
    "print(f\"  Individuals with 1 infection: {alz_one}\")\n",
    "print(f\"  Individuals with 2+ infections: {alz_two_or_more}\")\n",
    "\n",
    "print(\"\\nWithout Alzheimer's:\")\n",
    "print(f\"  Individuals with 0 infections: {non_alz_zero}\")\n",
    "print(f\"  Individuals with 1 infection: {non_alz_one}\")\n",
    "print(f\"  Individuals with 2+ infections: {non_alz_two_or_more}\")\n",
    "\n",
    "# Step 8: Detailed disease classification\n",
    "def classify_by_disease(df):\n",
    "    results = defaultdict(lambda: {'one_infection': 0, 'two_or_more': 0})\n",
    "    infection_counts = df.groupby(['person_id', 'disease_name']).size()\n",
    "\n",
    "    for (person_id, disease), count in infection_counts.items():\n",
    "        if count == 1:\n",
    "            results[disease]['one_infection'] += 1\n",
    "        else:\n",
    "            results[disease]['two_or_more'] += 1\n",
    "    return results\n",
    "\n",
    "# With Alzheimer's: Classify individuals by disease\n",
    "with_alz_disease_results = classify_by_disease(with_alzheimers)\n",
    "\n",
    "# Without Alzheimer's: Classify individuals by disease\n",
    "without_alz_disease_results = classify_by_disease(without_alzheimers)\n",
    "\n",
    "# Convert the results to DataFrame for readability\n",
    "def format_disease_results(results):\n",
    "    formatted = []\n",
    "    for disease, counts in results.items():\n",
    "        formatted.append({\n",
    "            'Disease': disease,\n",
    "            'One Infection': counts['one_infection'],\n",
    "            'Two or More Infections': counts['two_or_more'],\n",
    "        })\n",
    "    return pd.DataFrame(formatted)\n",
    "\n",
    "with_alz_disease_df = format_disease_results(with_alz_disease_results)\n",
    "without_alz_disease_df = format_disease_results(without_alz_disease_results)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nWith Alzheimer's - Infections by Disease:\")\n",
    "display(with_alz_disease_df)\n",
    "\n",
    "print(\"\\nWithout Alzheimer's - Infections by Disease:\")\n",
    "display(without_alz_disease_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Alzheimer's individuals based on person_id_list\n",
    "ad_individuals = set(alzheimers_patients) & set(person_id_list)\n",
    "\n",
    "# Classify infections into 0, 1, or 2+ for individuals with Alzheimer's\n",
    "def classify_ad_infections(df, ad_list):\n",
    "    ad_df = df[df['person_id'].isin(ad_list)]\n",
    "    infection_counts_per_person = ad_df.groupby('person_id')['disease_name'].nunique()\n",
    "    \n",
    "    zero_infection = len(ad_list) - len(infection_counts_per_person)  # Individuals not in the filtered dataframe\n",
    "    one_infection = infection_counts_per_person[infection_counts_per_person == 1].count()\n",
    "    two_or_more_infections = infection_counts_per_person[infection_counts_per_person >= 2].count()\n",
    "    \n",
    "    return zero_infection, one_infection, two_or_more_infections\n",
    "\n",
    "# Classify infections for Alzheimer's individuals in the given list\n",
    "ad_zero, ad_one, ad_two_or_more = classify_ad_infections(bacterial_data, ad_individuals)\n",
    "\n",
    "# Count the occurrences of each bacteria for Alzheimer's individuals in the list\n",
    "def count_bacteria_by_person(df, ad_list, bacterial_list):\n",
    "    ad_df = df[df['person_id'].isin(ad_list)]\n",
    "    bacteria_counts = ad_df['disease_name'].value_counts()\n",
    "    return bacteria_counts[bacteria_counts.index.str.contains('|'.join(bacterial_list), case=False)]\n",
    "\n",
    "# Get bacterial counts for Alzheimer's individuals in the list\n",
    "ad_bacteria_counts = count_bacteria_by_person(bacterial_data, ad_individuals, bacterial_infections)\n",
    "\n",
    "# Display Results\n",
    "print(\"Infection Categories for Individuals with Alzheimer's:\")\n",
    "print(f\"  0 Infections: {ad_zero}\")\n",
    "print(f\"  1 Infection: {ad_one}\")\n",
    "print(f\"  2+ Infections: {ad_two_or_more}\")\n",
    "\n",
    "print(\"\\nBacterial Counts for Individuals with Alzheimer's:\")\n",
    "print(ad_bacteria_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "\n",
    "# Classify infections into 0, 1, or 2+ and count bacteria occurrences\n",
    "def detailed_infection_bacteria_counts(df, ad_list, bacterial_list):\n",
    "    ad_df = df[df['person_id'].isin(ad_list)]\n",
    "    infection_counts_per_person = ad_df.groupby('person_id')['disease_name'].nunique()\n",
    "    \n",
    "    # Initialize counters\n",
    "    bacteria_summary = defaultdict(lambda: {'0': 0, '1': 0, '2+': 0})\n",
    "    \n",
    "    # Loop through individuals and classify\n",
    "    for person_id in ad_list:\n",
    "        if person_id not in infection_counts_per_person:\n",
    "            # 0 infections\n",
    "            for bacteria in bacterial_list:\n",
    "                bacteria_summary[bacteria]['0'] += 1\n",
    "        else:\n",
    "            # Get individual's infections\n",
    "            person_bacteria = ad_df[ad_df['person_id'] == person_id]['disease_name'].unique()\n",
    "            infection_count = len(person_bacteria)\n",
    "            \n",
    "            # Classify infection count\n",
    "            category = '1' if infection_count == 1 else '2+'\n",
    "            for bacteria in bacterial_list:\n",
    "                if bacteria in person_bacteria:\n",
    "                    bacteria_summary[bacteria][category] += 1\n",
    "\n",
    "    # Summarize counts for each bacteria\n",
    "    detailed_counts = pd.DataFrame.from_dict(bacteria_summary, orient='index')\n",
    "    detailed_counts.reset_index(inplace=True)\n",
    "    detailed_counts.rename(columns={'index': 'Bacteria', '0': 'No Infection', '1': '1 Infection', '2+': '2+ Infections'}, inplace=True)\n",
    "    \n",
    "    return detailed_counts\n",
    "\n",
    "# Get the detailed counts\n",
    "detailed_bacteria_counts = detailed_infection_bacteria_counts(bacterial_data, ad_individuals, bacterial_infections)\n",
    "\n",
    "# Display results\n",
    "print(\"Detailed Breakdown of Infections by Bacteria for Individuals with Alzheimer's:\")\n",
    "print(detailed_bacteria_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct Pies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Total number of patients in the dataset\n",
    "total_patients = len(person_id_list)\n",
    "\n",
    "# Step 2: Identify the list of Alzheimers patients\n",
    "alzheimers_patients = alzheimer_data_filtered['person_id'].unique()\n",
    "\n",
    "# Step 3: Find non-Alzheimers patients\n",
    "non_alz_patients = set(person_id_list) - set(alzheimers_patients)\n",
    "total_number_no_ad = len(non_alz_patients)\n",
    "\n",
    "# Step 4: Filter bacterial data for non-Alzheimers patients older than 65\n",
    "\n",
    "non_alz_bacterial_data = bacterial_data[\n",
    "    (bacterial_data['person_id'].isin(non_alz_patients)) & \n",
    "    (bacterial_data['age'] > bacterial_data_age)\n",
    "]\n",
    "# Classify non-Alzheimers patients by infection count\n",
    "def classify_non_ad_patients(non_ad_bacterial_data, non_ad_patient_list):\n",
    "    infection_counts = non_ad_bacterial_data.groupby(['person_id'])['disease_name'].nunique()\n",
    "    \n",
    "    no_infections = len(set(non_ad_patient_list) - set(non_ad_bacterial_data['person_id']))\n",
    "    one_infection = (infection_counts[infection_counts == 1].count())\n",
    "    two_or_more_infections = (infection_counts[infection_counts >= 2].count())\n",
    "    \n",
    "    return no_infections, one_infection, two_or_more_infections\n",
    "\n",
    "# Step 5: Calculate infection categories for non-Alzheimers patients\n",
    "non_ad_no_infections, non_ad_one_infection, non_ad_two_or_more = classify_non_ad_patients(\n",
    "    non_alz_bacterial_data, non_alz_patients\n",
    ")\n",
    "\n",
    "# Step 6: Combine results\n",
    "alz_total = len(alzheimers_patients)\n",
    "non_ad_total = total_number_no_ad\n",
    "\n",
    "print(f\"Total patients: {total_patients}\")\n",
    "print(f\"{di.lower()} patients: {alz_total}\")\n",
    "print(f\"Non-{di.lower()}s patients: {non_ad_total}\")\n",
    "print(f\"\\nNon-{di.lower()}s Infection Summary:\")\n",
    "print(f\"  No infections: {non_ad_no_infections}\")\n",
    "print(f\"  1 infection: {non_ad_one_infection}\")\n",
    "print(f\"  2+ infections: {non_ad_two_or_more}\")\n",
    "print(f\"\\n  No infections with {di}: {alz_zero}\")\n",
    "print(f\"  1 infection with {di}: {alz_one}\")\n",
    "print(f\"  2+ infections with {di}: {alz_two_or_more}\")\n",
    "# Step 7: Prepare data for two pies\n",
    "alz_pie_data = {\n",
    "    \"No infection\": alz_zero,\n",
    "    \"1 infection\": alz_one,\n",
    "    \"2+ infections\": alz_two_or_more\n",
    "}\n",
    "\n",
    "non_ad_pie_data = {\n",
    "    \"No infection\": non_ad_no_infections,\n",
    "    \"1 infection\": non_ad_one_infection,\n",
    "    \"2+ infections\": non_ad_two_or_more\n",
    "}\n",
    "\n",
    "# Step 8: Define colors\n",
    "colors = {\n",
    "    \"No infection\": \"#ff9999\",  # Red\n",
    "    \"1 infection\": \"#99ff99\",  # Green\n",
    "    \"2+ infections\": \"#66b3ff\",  # Blue\n",
    "}\n",
    "\n",
    "# Step 9: Plot pie charts\n",
    "def plot_pie_chart(data, title, output_path):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    wedges, texts, autotexts = plt.pie(\n",
    "        data.values(),\n",
    "        labels=data.keys(),\n",
    "        autopct='%1.1f%%',\n",
    "        colors=[colors[group] for group in data.keys()],\n",
    "        startangle=90,\n",
    "        textprops={'fontsize': 12}\n",
    "    )\n",
    "    plt.title(title, fontsize=14)\n",
    "    legend_labels = [f\"{group}, n={count}\" for group, count in data.items()]\n",
    "    plt.legend(\n",
    "        wedges,\n",
    "        legend_labels,\n",
    "        loc='upper right',\n",
    "        bbox_to_anchor=(1, 0, 0.5, 1),\n",
    "        frameon=False,\n",
    "        fontsize=12\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Alzheimers pie chart\n",
    "plot_pie_chart(\n",
    "    alz_pie_data,\n",
    "    f\"Distribution of infections in {di.lower()} patients\",\n",
    "    f\"./download/{di.lower()}_infections_pie_{bacterial_data_age}.pdf\"\n",
    ")\n",
    "\n",
    "# # Non-Alzheimers pie chart\n",
    "# plot_pie_chart(\n",
    "#     non_ad_pie_data,\n",
    "#     \"Distribution of Infections in Non-Alzheimers Patients\",\n",
    "#     \"./non_ad_infections_pie.pdf\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_pie_chart(data, title, output_path):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    \n",
    "    # Plot the pie chart with adjusted label distance\n",
    "    wedges, texts = plt.pie(\n",
    "        data.values(),\n",
    "        labels=data.keys(),\n",
    "        autopct=None,  # Disable default percentage placement\n",
    "        colors=[colors[group] for group in data.keys()],\n",
    "        startangle=90,\n",
    "        textprops={'fontsize': 12},\n",
    "        labeldistance=1.2  # Move labels further from the center\n",
    "    )\n",
    "    \n",
    "    # Add percentage labels with adjusted positions\n",
    "    total = sum(data.values())\n",
    "    for i, (wedge, count, label) in enumerate(zip(wedges, data.values(), data.keys())):\n",
    "        angle = (wedge.theta2 + wedge.theta1) / 2  # Find the center angle of the wedge\n",
    "        x = np.cos(np.radians(angle))  # X-coordinate adjustment\n",
    "        y = np.sin(np.radians(angle))  # Y-coordinate adjustment\n",
    "        \n",
    "        # Adjust the distance from the center\n",
    "        if label == \"2+ infections\":\n",
    "            x_adjusted = x * 0.8   # Move left\n",
    "            y_adjusted = y * 0.9 - 0.2  # Move lower\n",
    "        elif label == \"1 infection\":\n",
    "            x_adjusted = x * 0.8 + 0.01  # Move right\n",
    "            y_adjusted = y * 0.5 + 0.2  # Move higher\n",
    "        else:\n",
    "            x_adjusted = x * 1+0.3\n",
    "            y_adjusted = y * 1+0.3\n",
    "        \n",
    "        # Add the percentage label\n",
    "        plt.text(\n",
    "            x_adjusted, y_adjusted,\n",
    "            f\"{(count / total) * 100:.1f}%\",\n",
    "            ha=\"center\", va=\"center\", fontsize=12, color='black'\n",
    "        )\n",
    "    \n",
    "    # Title and legend\n",
    "    plt.title(title, fontsize=14)\n",
    "    legend_labels = [f\"{group}, n={count}\" for group, count in data.items()]\n",
    "    plt.legend(\n",
    "        wedges,\n",
    "        legend_labels,\n",
    "        loc='upper right',\n",
    "        bbox_to_anchor=(1, 0, 0.5, 1),\n",
    "        frameon=False,\n",
    "        fontsize=12\n",
    "    )\n",
    "    \n",
    "    # Save and show the pie chart\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Non-Alzheimers pie chart\n",
    "plot_pie_chart(\n",
    "    non_ad_pie_data,\n",
    "    f\"Distribution of infections in non-{di.lower()} patients\",\n",
    "    f\"./download/non_{di.lower()}_infections_pie_{bacterial_data_age}.pdf\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lifelines\n",
    "# print(lifelines.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Count total bacterial infections for each person\n",
    "bacteria_list = ['staphylococcus', 'ecoli', 'pseudomonas', 'gram_negative', 'gram_positive', 'streptococcus']\n",
    "bacteria_counts = (\n",
    "    combined_age_data_cleaned[\n",
    "        combined_age_data_cleaned['disease_name'].isin(bacteria_list)\n",
    "    ]\n",
    "    .groupby('person_id')['disease_name']\n",
    "    .count()  # Count total infections (including duplicates)\n",
    "    .reset_index()\n",
    "    .rename(columns={'disease_name': 'bacteria_infections'})\n",
    ")\n",
    "\n",
    "# Step 2: Identify the first AD diagnosis for each person\n",
    "ad_data = combined_age_data_cleaned[combined_age_data_cleaned['disease_name'] == 'alzheimer']\n",
    "ad_first_diagnosis = (\n",
    "    ad_data.groupby('person_id')['age_at_diagnosis']\n",
    "    .min()\n",
    "    .reset_index()\n",
    "    .rename(columns={'age_at_diagnosis': 'first_ad_age'})\n",
    ")\n",
    "\n",
    "# Step 3: Merge bacterial infection counts with first AD diagnosis age\n",
    "ad_first_diagnosis = ad_first_diagnosis.merge(bacteria_counts, on='person_id', how='left').fillna(0)\n",
    "\n",
    "# Step 4: Filter by minimum age at first AD diagnosis\n",
    "min_first_ad_age = 0\n",
    "ad_first_diagnosis = ad_first_diagnosis[ad_first_diagnosis['first_ad_age'] > min_first_ad_age]\n",
    "\n",
    "# Step 5: Categorize into infection groups\n",
    "ad_first_diagnosis['infection_group'] = ad_first_diagnosis['bacteria_infections'].apply(\n",
    "    lambda x: '0' if x == 0 else ('1' if x == 1 else ('2' if x == 2 else \"3+\"))\n",
    ")\n",
    "\n",
    "\n",
    "# Step 6: Perform Kaplan-Meier Analysis\n",
    "kmf = KaplanMeierFitter()\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = {'0': 'blue', '1': 'purple', '2': 'green', '3+': 'red'}\n",
    "# Add general dementia line\n",
    "kmf.fit(\n",
    "    durations=ad_first_diagnosis['first_ad_age'],\n",
    "    event_observed=[1] * len(ad_first_diagnosis),\n",
    "    label=\"Dementia (All Patients)\"\n",
    ")\n",
    "kmf.plot_survival_function(color='black', linestyle='--', linewidth=2,ci_show=False)\n",
    "# Log-Rank Test\n",
    "log_rank_results = []\n",
    "groups = ['0', '1', '2', '3+']\n",
    "for i in range(len(groups)):\n",
    "    for j in range(i + 1, len(groups)):\n",
    "        group_1, group_2 = groups[i], groups[j]\n",
    "        if group_1 in group_survival_data and group_2 in group_survival_data:\n",
    "            result = logrank_test(\n",
    "                group_survival_data[group_1],\n",
    "                group_survival_data[group_2]\n",
    "            )\n",
    "            log_rank_results.append((group_1, group_2, result.p_value))\n",
    "\n",
    "log_rank_comparisons = pd.DataFrame(\n",
    "    log_rank_results,\n",
    "    columns=[\"Group_1\", \"Group_2\", \"P_Value\"]\n",
    ")\n",
    "\n",
    "# Create custom legend labels with p-values\n",
    "group_labels = {}\n",
    "for group in groups:\n",
    "    if group == '0':\n",
    "        group_labels[group] = f\"{group} Infections (n={len(ad_first_diagnosis[ad_first_diagnosis['infection_group'] == group])})\"\n",
    "    else:\n",
    "        p_val = min([res[2] for res in log_rank_results if res[0] == '0' and res[1] == group])\n",
    "        group_labels[group] = f\"{group} Infections (n={len(ad_first_diagnosis[ad_first_diagnosis['infection_group'] == group])}, p={p_val:.6f})\"\n",
    "\n",
    "# Prepare Kaplan-Meier plot and survival data\n",
    "group_survival_data = {}\n",
    "for group in ['0', '1', '2', '3+']:\n",
    "    group_data = ad_first_diagnosis[ad_first_diagnosis['infection_group'] == group]\n",
    "    group_survival_data[group] = group_data['first_ad_age']\n",
    "    kmf.fit(\n",
    "        durations=group_data['first_ad_age'], \n",
    "        event_observed=[1] * len(group_data),  # Assume all events observed\n",
    "        label=group_labels[group]\n",
    "    )\n",
    "    kmf.plot_survival_function(color=colors[group], ci_show=False)\n",
    "\n",
    "\n",
    "\n",
    "# Enhance the plot\n",
    "plt.title(f'Kaplan-Meier Plot for First {di} Diagnosis Age by Infection Group', fontsize=16)\n",
    "plt.xlabel(f'Age at First {di} Diagnosis', fontsize=14)\n",
    "plt.ylabel('Survival Probability', fontsize=14)\n",
    "plt.legend(title='Infection Group', fontsize=12, frameon=False)\n",
    "plt.grid(False)\n",
    "# Set x-axis limit to start at 40\n",
    "plt.xlim(40, None)  # Start x-axis at 40, let it auto-adjust for the upper limit\n",
    "\n",
    "# Customize plot aesthetics\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_color('black')\n",
    "ax.spines['bottom'].set_color('black')\n",
    "ax.spines['left'].set_linewidth(2)\n",
    "ax.spines['bottom'].set_linewidth(2)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "reversed_survival_plot_path = f\"./download/first_ad_diagnosis_by_infection_group_with_logrank_{di}.pdf\"\n",
    "plt.savefig(reversed_survival_plot_path)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_rank_comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Count total bacterial infections for each person\n",
    "bacteria_list = ['staphylococcus', 'ecoli', 'pseudomonas', 'gram_negative', 'gram_positive', 'streptococcus']\n",
    "bacteria_counts = (\n",
    "    combined_age_data_cleaned[\n",
    "        combined_age_data_cleaned['disease_name'].isin(bacteria_list)\n",
    "    ]\n",
    "    .groupby('person_id')['disease_name']\n",
    "    .count()  # Count total infections (including duplicates)\n",
    "    .reset_index()\n",
    "    .rename(columns={'disease_name': 'bacteria_infections'})\n",
    ")\n",
    "\n",
    "# Step 2: Identify the first AD diagnosis for each person\n",
    "ad_data = combined_age_data_cleaned[combined_age_data_cleaned['disease_name'] == 'alzheimer']\n",
    "ad_first_diagnosis = (\n",
    "    ad_data.groupby('person_id')['age_at_diagnosis']\n",
    "    .min()\n",
    "    .reset_index()\n",
    "    .rename(columns={'age_at_diagnosis': 'first_ad_age'})\n",
    ")\n",
    "\n",
    "# Step 3: Merge bacterial infection counts with first AD diagnosis age\n",
    "ad_first_diagnosis = ad_first_diagnosis.merge(bacteria_counts, on='person_id', how='left').fillna(0)\n",
    "\n",
    "# Step 4: Filter by minimum age at first AD diagnosis\n",
    "min_first_ad_age = 0\n",
    "ad_first_diagnosis = ad_first_diagnosis[ad_first_diagnosis['first_ad_age'] > min_first_ad_age]\n",
    "\n",
    "# Step 5: Categorize into infection groups\n",
    "ad_first_diagnosis['infection_group'] = ad_first_diagnosis['bacteria_infections'].apply(\n",
    "    lambda x: '0' if x == 0 else ('1' if x == 1 else ('2' if x == 2 else \"3+\"))\n",
    ")\n",
    "\n",
    "# Step 6: Perform Kaplan-Meier Analysis\n",
    "kmf = KaplanMeierFitter()\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = {'0': 'blue', '1': 'purple', '2': 'green', '3+': 'red'}\n",
    "# Add general dementia line\n",
    "kmf.fit(\n",
    "    durations=ad_first_diagnosis['first_ad_age'],\n",
    "    event_observed=[1] * len(ad_first_diagnosis),\n",
    "    label=\"Dementia (All Patients)\"\n",
    ")\n",
    "kmf.plot_survival_function(color='black', linestyle='--', linewidth=2,ci_show=False)\n",
    "# Log-Rank Test\n",
    "log_rank_results = []\n",
    "groups = ['0', '1', '2', '3+']\n",
    "for i in range(len(groups)):\n",
    "    for j in range(i + 1, len(groups)):\n",
    "        group_1, group_2 = groups[i], groups[j]\n",
    "        if group_1 in group_survival_data and group_2 in group_survival_data:\n",
    "            result = logrank_test(\n",
    "                group_survival_data[group_1],\n",
    "                group_survival_data[group_2]\n",
    "            )\n",
    "            log_rank_results.append((group_1, group_2, result.p_value))\n",
    "\n",
    "log_rank_comparisons = pd.DataFrame(\n",
    "    log_rank_results,\n",
    "    columns=[\"Group_1\", \"Group_2\", \"P_Value\"]\n",
    ")\n",
    "# Set x-axis limit to start at 40\n",
    "plt.xlim(0, None)  # Start x-axis at 40, let it auto-adjust for the upper limit\n",
    "\n",
    "# Create custom legend labels with p-values\n",
    "group_labels = {}\n",
    "for group in groups:\n",
    "    if group == '0':\n",
    "        group_labels[group] = f\"{group} Infections (n={len(ad_first_diagnosis[ad_first_diagnosis['infection_group'] == group])})\"\n",
    "    else:\n",
    "        p_val = min([res[2] for res in log_rank_results if res[0] == '0' and res[1] == group])\n",
    "        group_labels[group] = f\"{group} Infections (n={len(ad_first_diagnosis[ad_first_diagnosis['infection_group'] == group])}, p={p_val:.3e})\"\n",
    "\n",
    "# Prepare Kaplan-Meier plot and survival data\n",
    "group_survival_data = {}\n",
    "for group in ['0', '1', '2', '3+']:\n",
    "    group_data = ad_first_diagnosis[ad_first_diagnosis['infection_group'] == group]\n",
    "    group_survival_data[group] = group_data['first_ad_age']\n",
    "    kmf.fit(\n",
    "        durations=group_data['first_ad_age'], \n",
    "        event_observed=[1] * len(group_data),  # Assume all events observed\n",
    "        label=group_labels[group]\n",
    "    )\n",
    "    kmf.plot_survival_function(color=colors[group], ci_show=False)\n",
    "\n",
    "\n",
    "\n",
    "# Enhance the plot\n",
    "plt.title(f'Kaplan-Meier plot for first {di} diagnosis age by infection group', fontsize=16)\n",
    "plt.xlabel(f'Age at first {di} diagnosis', fontsize=14)\n",
    "plt.ylabel('Survival probability', fontsize=14)\n",
    "plt.legend(title='Infection group', fontsize=12, frameon=False)\n",
    "plt.grid(False)\n",
    "\n",
    "# Customize plot aesthetics\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_color('black')\n",
    "ax.spines['bottom'].set_color('black')\n",
    "ax.spines['left'].set_linewidth(2)\n",
    "ax.spines['bottom'].set_linewidth(2)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "reversed_survival_plot_path = f\"./download/first_ad_diagnosis_by_infection_group_with_logrank_e_{di}.pdf\"\n",
    "plt.savefig(reversed_survival_plot_path)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Define the list of bacterial infections\n",
    "bacteria_list = ['staphylococcus', 'ecoli', 'pseudomonas', 'gram_negative', 'gram_positive', 'streptococcus']\n",
    "\n",
    "# Step 2: Filter patients with Alzheimer's\n",
    "alzheimers_patients = combined_age_data_filtered.loc[\n",
    "    combined_age_data_filtered['disease_name'].str.contains('alzheimer', case=False), 'person_id'\n",
    "].unique()\n",
    "\n",
    "# Step 3: Filter bacterial data for patients with Alzheimer's\n",
    "bacterial_data_alz = combined_age_data_filtered[\n",
    "    (combined_age_data_filtered['person_id'].isin(alzheimers_patients)) &\n",
    "    (combined_age_data_filtered['disease_name'].isin(bacteria_list))\n",
    "]\n",
    "\n",
    "# Step 4: Count infections for each person\n",
    "infection_counts_alz = bacterial_data_alz.groupby(['person_id', 'disease_name']).size().reset_index(name='infection_count')\n",
    "\n",
    "# Step 5: Categorize individuals by the number of infections for each bacteria\n",
    "infection_summary_alz = (\n",
    "    bacterial_data_alz.groupby('disease_name')['person_id']\n",
    "    .apply(lambda x: pd.Series({\n",
    "        '0 Infections': len(set(alzheimers_patients) - set(x)),\n",
    "        '1 Infection': (x.value_counts() == 1).sum(),\n",
    "        '2+ Infections': (x.value_counts() > 1).sum()\n",
    "    }))\n",
    "    .unstack()  # Convert the Series into DataFrame columns\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Step 6: Rename columns for clarity\n",
    "infection_summary_alz.rename(columns={'disease_name': 'Bacteria'}, inplace=True)\n",
    "\n",
    "# Display the corrected summary\n",
    "print(\"\\nCorrected Summary of Infections by Bacteria for Patients with Alzheimer's:\")\n",
    "print(infection_summary_alz)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create the box plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(\n",
    "    data=ad_first_diagnosis,\n",
    "    x='infection_group',\n",
    "    y='first_ad_age',\n",
    "    palette='tab10',\n",
    "    order=['0', '1', '2', '3+'],\n",
    "    showfliers=False\n",
    ")\n",
    "\n",
    "# Step 3: Enhance the plot\n",
    "plt.title(f'Distribution of Age at First {di} Diagnosis by Infection Group', fontsize=16)\n",
    "plt.xlabel('Infection Group', fontsize=14)\n",
    "plt.ylabel(f'Age at First {di} Diagnosis', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "# Customize plot aesthetics\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_color('black')\n",
    "ax.spines['bottom'].set_color('black')\n",
    "ax.spines['left'].set_linewidth(2)\n",
    "ax.spines['bottom'].set_linewidth(2)\n",
    "# Step 4: Save the plot\n",
    "box_plot_path = f\"./download/{di}_first_diagnosis_box_plot.pdf\"\n",
    "plt.savefig(box_plot_path, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Box plot saved to {box_plot_path}\")\n",
    "# Step 2: Create the box plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(\n",
    "    data=ad_first_diagnosis,\n",
    "    x='infection_group',\n",
    "    y='first_ad_age',\n",
    "    palette='tab10',\n",
    "    order=['0', '1', '2', '3+'],\n",
    "    showfliers=False\n",
    ")\n",
    "\n",
    "# Step 3: Enhance the plot\n",
    "plt.title(f'Distribution of Age at First {di} Diagnosis by Infection Group', fontsize=16)\n",
    "plt.xlabel('Infection Group', fontsize=14)\n",
    "plt.ylabel(f'Age at First {di} Diagnosis', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "# Customize plot aesthetics\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_color('black')\n",
    "ax.spines['bottom'].set_color('black')\n",
    "ax.spines['left'].set_linewidth(2)\n",
    "ax.spines['bottom'].set_linewidth(2)\n",
    "# Step 4: Save the plot\n",
    "box_plot_path = f\"./download/{di}_first_diagnosis_violin_plot.pdf\"\n",
    "plt.savefig(box_plot_path, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Box plot saved to {box_plot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate cumulative probability for age of first encounter for all diseases\n",
    "first_encounter_diseases = (\n",
    "    combined_age_data_cleaned\n",
    "    .groupby(['disease_name', 'person_id'])['age_at_diagnosis']\n",
    "    .min()\n",
    "    .reset_index()\n",
    ")\n",
    "# Ensure `age_at_diagnosis` is retained correctly in disease_probabilities\n",
    "disease_probabilities = (\n",
    "    first_encounter_diseases\n",
    "    .sort_values('age_at_diagnosis')\n",
    "    .groupby('disease_name', group_keys=False)\n",
    "    .apply(lambda x: x.assign(cumulative_probability=x['age_at_diagnosis'].rank(pct=True)))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Calculate patient counts for each disease\n",
    "disease_patient_counts = first_encounter_diseases['disease_name'].value_counts().to_dict()\n",
    "\n",
    "# Create a mapping of disease names to labels with counts\n",
    "disease_label_mapping = {\n",
    "    \"alzheimer\": f\"{di} (n={disease_patient_counts.get('alzheimer', 0)})\",\n",
    "    \"pseudomonas\": f\"Pseudomonas (n={disease_patient_counts.get('pseudomonas', 0)})\",\n",
    "    \"staphylococcus\": f\"Staphylococcus (n={disease_patient_counts.get('staphylococcus', 0)})\",\n",
    "    \"streptococcus\": f\"Streptococcus (n={disease_patient_counts.get('streptococcus', 0)})\",\n",
    "    \"ecoli\": f\"E. coli (n={disease_patient_counts.get('ecoli', 0)})\",\n",
    "    \"gram_positive\": f\"Gram-positive (n={disease_patient_counts.get('gram_positive', 0)})\",\n",
    "    \"gram_negative\": f\"Gram-negative (n={disease_patient_counts.get('gram_negative', 0)})\",\n",
    "    \"retrovirus\": f\"Retrovirus (n={disease_patient_counts.get('retrovirus', 0)})\",\n",
    "}\n",
    "# import matplotlib.cm as cm\n",
    "# from lifelines import KaplanMeierFitter\n",
    "# from collections import defaultdict\n",
    "# import statsmodels.formula.api as smf\n",
    "# from scipy.stats import mannwhitneyu\n",
    "# import itertools\n",
    "# from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "# from scipy.stats import f_oneway\n",
    "# from scipy.stats import skew, kurtosis\n",
    "# from lifelines import KaplanMeierFitter\n",
    "# import matplotlib.lines as mlines\n",
    "# from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "colors = cm.get_cmap('tab10')\n",
    "# Plot cumulative probability vs. age for each disease\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for idx, (disease, group) in enumerate(disease_probabilities.groupby('disease_name')):\n",
    "    plt.plot(\n",
    "        group['age_at_diagnosis'],\n",
    "        group['cumulative_probability'],\n",
    "        label=disease_label_mapping.get(disease, disease),  # Use label mapping\n",
    "        linewidth=2.5,  # Make lines thicker\n",
    "        color=colors(idx % 10)  # Use a bright, distinguishable color\n",
    "    )\n",
    "plt.title('Cumulative probability of first encounter by disease', fontsize=16)\n",
    "plt.xlabel('Age at first encounter', fontsize=14)\n",
    "plt.ylabel('Cumulative probability', fontsize=14)\n",
    "plt.legend(title='Disease name', fontsize=10, frameon=False)\n",
    "plt.grid(False)\n",
    "\n",
    "# Customize plot aesthetics\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_color('black')\n",
    "ax.spines['bottom'].set_color('black')\n",
    "ax.spines['left'].set_linewidth(2)\n",
    "ax.spines['bottom'].set_linewidth(2)\n",
    "\n",
    "plt.tight_layout()\n",
    "# Save the plot\n",
    "plt.savefig(f'./download/cumulative_probability_first_encounter_{di}.pdf', format='pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dementia_ages based on the dataset\n",
    "dementia_ages = (\n",
    "    combined_age_data_cleaned[combined_age_data_cleaned['disease_name'] == 'alzheimer']\n",
    "    .groupby('person_id')['age_at_diagnosis']\n",
    "    .min()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Recompute cumulative probabilities for dementia vs other diseases\n",
    "disease_vs_dementia_age = pd.merge(\n",
    "    first_encounter_diseases,\n",
    "    dementia_ages.rename(columns={'age_at_diagnosis': 'age_at_first_dementia'}),\n",
    "    on='person_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "dementia_probabilities = (\n",
    "    disease_vs_dementia_age\n",
    "    .sort_values('age_at_first_dementia')\n",
    "    .groupby('disease_name', group_keys=False)\n",
    "    .apply(lambda x: x.assign(cumulative_probability=x['age_at_first_dementia'].rank(pct=True)))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Calculate patient counts for each disease in the dementia-related dataset\n",
    "disease_patient_counts_dementia = disease_vs_dementia_age['disease_name'].value_counts().to_dict()\n",
    "\n",
    "# Update disease_label_mapping with counts specific to the dementia dataset\n",
    "disease_label_mapping_dementia = {\n",
    "    \"alzheimer\": f\"{di} (n={disease_patient_counts_dementia.get('alzheimer', 0)})\",\n",
    "    \"pseudomonas\": f\"Pseudomonas (n={disease_patient_counts_dementia.get('pseudomonas', 0)})\",\n",
    "    \"staphylococcus\": f\"Staphylococcus (n={disease_patient_counts_dementia.get('staphylococcus', 0)})\",\n",
    "    \"streptococcus\": f\"Streptococcus (n={disease_patient_counts_dementia.get('streptococcus', 0)})\",\n",
    "    \"ecoli\": f\"E. coli (n={disease_patient_counts_dementia.get('ecoli', 0)})\",\n",
    "    \"gram_positive\": f\"Gram-positive (n={disease_patient_counts_dementia.get('gram_positive', 0)})\",\n",
    "    \"gram_negative\": f\"Gram-negative (n={disease_patient_counts_dementia.get('gram_negative', 0)})\",\n",
    "    \"retrovirus\": f\"Retrovirus (n={disease_patient_counts_dementia.get('retrovirus', 0)})\",\n",
    "}\n",
    "\n",
    "# Plot cumulative probability vs. age of first dementia encounter\n",
    "plt.figure(figsize=(12, 8))\n",
    "for disease, group in dementia_probabilities.groupby('disease_name'):\n",
    "    plt.plot(\n",
    "        group['age_at_first_dementia'],\n",
    "        group['cumulative_probability'],\n",
    "        linewidth=2.5,\n",
    "        label=disease_label_mapping_dementia.get(disease, f\"{disease} (n={disease_patient_counts_dementia.get(disease, 0)})\")\n",
    "    )\n",
    "plt.title(f'Cumulative probability of diseases by age at first {di} encounter', fontsize=16)\n",
    "plt.xlabel(f'Age at first {di} encounter', fontsize=14)\n",
    "plt.ylabel('Cumulative probability', fontsize=14)\n",
    "plt.legend(title='Disease name', fontsize=10, frameon=False)\n",
    "plt.grid(False)\n",
    "\n",
    "# Customize plot aesthetics\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_color('black')\n",
    "ax.spines['bottom'].set_color('black')\n",
    "ax.spines['left'].set_linewidth(2)\n",
    "ax.spines['bottom'].set_linewidth(2)\n",
    "\n",
    "plt.tight_layout()\n",
    "# Save the plot\n",
    "plt.savefig(f'./download/cumulative_probability_first_{di}_encounter.pdf', format='pdf')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the list of bacterial infections\n",
    "bacteria_list = ['staphylococcus', 'ecoli', 'pseudomonas', 'gram_negative', 'gram_positive', 'streptococcus']\n",
    "\n",
    "# Step 2: Filter patients with Alzheimer's\n",
    "alzheimers_patients = combined_age_data_filtered.loc[\n",
    "    combined_age_data_filtered['disease_name'].str.contains('alzheimer', case=False), 'person_id'\n",
    "].unique()\n",
    "\n",
    "# Step 3: Filter bacterial data for patients with Alzheimer's\n",
    "bacterial_data_alz = combined_age_data_filtered[\n",
    "    (combined_age_data_filtered['person_id'].isin(alzheimers_patients)) &\n",
    "    (combined_age_data_filtered['disease_name'].isin(bacteria_list))\n",
    "]\n",
    "\n",
    "# Step 4: Identify patients with no bacterial infections\n",
    "alz_no_infections = len(set(alzheimers_patients) - set(bacterial_data_alz['person_id']))\n",
    "\n",
    "# Step 5: Count infections for each person and classify them\n",
    "infection_summary_alz = (\n",
    "    bacterial_data_alz.groupby('disease_name')['person_id']\n",
    "    .apply(lambda x: pd.Series({\n",
    "        '1 Infection': (x.value_counts() == 1).sum(),\n",
    "        '2+ Infections': (x.value_counts() > 1).sum()\n",
    "    }))\n",
    "    .unstack()  # Convert the Series into DataFrame columns\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Add the \"0 Infections\" row for clarity\n",
    "infection_summary_alz.loc[len(infection_summary_alz)] = {\n",
    "    'Bacteria': 'No bacterial infections',\n",
    "    '1 Infection': 0,\n",
    "    '2+ Infections': 0\n",
    "}\n",
    "\n",
    "# Correct totals for \"No bacterial infections\"\n",
    "infection_summary_alz.at[len(infection_summary_alz) - 1, '1 Infection'] = alz_no_infections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_first_ad_age = 0\n",
    "# Step 1: Count total bacterial infections for each person\n",
    "bacteria_list = ['staphylococcus', 'ecoli', 'pseudomonas', 'gram_negative', 'gram_positive', 'streptococcus']\n",
    "bacteria_counts = (\n",
    "    combined_age_data_cleaned[\n",
    "        combined_age_data_cleaned['disease_name'].isin(bacteria_list)\n",
    "    ]\n",
    "    .groupby('person_id')['disease_name']\n",
    "    .count()  # Count total infections (including duplicates)\n",
    "    .reset_index()\n",
    "    .rename(columns={'disease_name': 'bacteria_infections'})\n",
    ")\n",
    "\n",
    "# Step 2: Identify the first AD diagnosis for each person\n",
    "ad_data = combined_age_data_cleaned[combined_age_data_cleaned['disease_name'] == 'alzheimer']\n",
    "ad_first_diagnosis = (\n",
    "    ad_data.groupby('person_id')['age_at_diagnosis']\n",
    "    .min()\n",
    "    .reset_index()\n",
    "    .rename(columns={'age_at_diagnosis': 'first_ad_age'})\n",
    ")\n",
    "\n",
    "# Step 3: Merge bacterial infection counts with first AD diagnosis age\n",
    "ad_first_diagnosis = ad_first_diagnosis.merge(bacteria_counts, on='person_id', how='left').fillna(0)\n",
    "\n",
    "# Step 4: Filter by minimum age at first AD diagnosis\n",
    "\n",
    "ad_first_diagnosis = ad_first_diagnosis[ad_first_diagnosis['first_ad_age'] > min_first_ad_age]\n",
    "\n",
    "# Step 5: Categorize into infection groups\n",
    "ad_first_diagnosis['infection_group'] = ad_first_diagnosis['bacteria_infections'].apply(\n",
    "    lambda x: '0' if x == 0 else ('1' if x == 1 else ('2' if x == 2 else \"3+\"))\n",
    ")\n",
    "\n",
    "\n",
    "# Step 6: Perform Kaplan-Meier Analysis\n",
    "kmf = KaplanMeierFitter()\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = {'0': 'blue', '1': 'purple', '2': 'green', '3+': 'red'}\n",
    "# Add general dementia line\n",
    "kmf.fit(\n",
    "    durations=ad_first_diagnosis['first_ad_age'],\n",
    "    event_observed=[1] * len(ad_first_diagnosis),\n",
    "    label=f\"{di}\"\n",
    ")\n",
    "kmf.plot_survival_function(color='black', linestyle='--', linewidth=2,ci_show=False)\n",
    "# Log-Rank Test\n",
    "log_rank_results = []\n",
    "groups = ['0', '1', '2', '3+']\n",
    "for i in range(len(groups)):\n",
    "    for j in range(i + 1, len(groups)):\n",
    "        group_1, group_2 = groups[i], groups[j]\n",
    "        if group_1 in group_survival_data and group_2 in group_survival_data:\n",
    "            result = logrank_test(\n",
    "                group_survival_data[group_1],\n",
    "                group_survival_data[group_2]\n",
    "            )\n",
    "            log_rank_results.append((group_1, group_2, result.p_value))\n",
    "\n",
    "log_rank_comparisons = pd.DataFrame(\n",
    "    log_rank_results,\n",
    "    columns=[\"Group_1\", \"Group_2\", \"P_Value\"]\n",
    ")\n",
    "\n",
    "# Create custom legend labels with p-values\n",
    "group_labels = {}\n",
    "for group in groups:\n",
    "    if group == '0':\n",
    "        group_labels[group] = f\"{group} Infections (n={len(ad_first_diagnosis[ad_first_diagnosis['infection_group'] == group])})\"\n",
    "    else:\n",
    "        p_val = min([res[2] for res in log_rank_results if res[0] == '0' and res[1] == group])\n",
    "        group_labels[group] = f\"{group} Infections (n={len(ad_first_diagnosis[ad_first_diagnosis['infection_group'] == group])}, p={p_val:.4e})\"\n",
    "\n",
    "# Prepare Kaplan-Meier plot and survival data\n",
    "group_survival_data = {}\n",
    "for group in ['0', '1', '2', '3+']:\n",
    "    group_data = ad_first_diagnosis[ad_first_diagnosis['infection_group'] == group]\n",
    "    group_survival_data[group] = group_data['first_ad_age']\n",
    "    kmf.fit(\n",
    "        durations=group_data['first_ad_age'], \n",
    "        event_observed=[1] * len(group_data),  # Assume all events observed\n",
    "        label=group_labels[group]\n",
    "    )\n",
    "    kmf.plot_survival_function(color=colors[group], ci_show=False)\n",
    "\n",
    "\n",
    "\n",
    "# Enhance the plot\n",
    "plt.title(f'Kaplan-Meier plot for first {di} diagnosis age by infection group', fontsize=16)\n",
    "plt.xlabel(f'Age at first {di} diagnosis', fontsize=14)\n",
    "plt.ylabel('Survival probability', fontsize=14)\n",
    "plt.legend(title='Infection group', fontsize=12, frameon=False)\n",
    "plt.grid(False)\n",
    "\n",
    "# Customize plot aesthetics\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_color('black')\n",
    "ax.spines['bottom'].set_color('black')\n",
    "ax.spines['left'].set_linewidth(2)\n",
    "ax.spines['bottom'].set_linewidth(2)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "reversed_survival_plot_path = f\"./download/first_ad_diagnosis_by_infection_group_with_logrank_{di}.pdf\"\n",
    "plt.savefig(reversed_survival_plot_path, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Step 6: Perform Kaplan-Meier Analysis\n",
    "kmf = KaplanMeierFitter()\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = {'0': 'blue', '1': 'purple', '2': 'green', '3+': 'red'}\n",
    "# Add general dementia line\n",
    "kmf.fit(\n",
    "    durations=ad_first_diagnosis['first_ad_age'],\n",
    "    event_observed=[1] * len(ad_first_diagnosis),\n",
    "    label=f\"{di}\"\n",
    ")\n",
    "kmf.plot_survival_function(color='black', linestyle='--', linewidth=2,ci_show=False)\n",
    "# Log-Rank Test\n",
    "log_rank_results = []\n",
    "groups = ['0', '1', '2', '3+']\n",
    "for i in range(len(groups)):\n",
    "    for j in range(i + 1, len(groups)):\n",
    "        group_1, group_2 = groups[i], groups[j]\n",
    "        if group_1 in group_survival_data and group_2 in group_survival_data:\n",
    "            result = logrank_test(\n",
    "                group_survival_data[group_1],\n",
    "                group_survival_data[group_2]\n",
    "            )\n",
    "            log_rank_results.append((group_1, group_2, result.p_value))\n",
    "\n",
    "log_rank_comparisons = pd.DataFrame(\n",
    "    log_rank_results,\n",
    "    columns=[\"Group_1\", \"Group_2\", \"P_Value\"]\n",
    ")\n",
    "\n",
    "# Create custom legend labels with p-values\n",
    "group_labels = {}\n",
    "for group in groups:\n",
    "    if group == '0':\n",
    "        group_labels[group] = f\"{group} Infections (n={len(ad_first_diagnosis[ad_first_diagnosis['infection_group'] == group])})\"\n",
    "    else:\n",
    "        p_val = min([res[2] for res in log_rank_results if res[0] == '0' and res[1] == group])\n",
    "        group_labels[group] = f\"{group} Infections (n={len(ad_first_diagnosis[ad_first_diagnosis['infection_group'] == group])}, p={p_val:.4e})\"\n",
    "\n",
    "# Prepare Kaplan-Meier plot and survival data\n",
    "group_survival_data = {}\n",
    "for group in ['0', '1', '2', '3+']:\n",
    "    group_data = ad_first_diagnosis[ad_first_diagnosis['infection_group'] == group]\n",
    "    group_survival_data[group] = group_data['first_ad_age']\n",
    "    kmf.fit(\n",
    "        durations=group_data['first_ad_age'], \n",
    "        event_observed=[1] * len(group_data),  # Assume all events observed\n",
    "        label=group_labels[group]\n",
    "    )\n",
    "    kmf.plot_survival_function(color=colors[group], ci_show=False)\n",
    "\n",
    "\n",
    "\n",
    "# Enhance the plot\n",
    "plt.title(f'Kaplan-Meier plot for first {di} diagnosis age by infection group', fontsize=16)\n",
    "plt.xlabel(f'Age at first {di} diagnosis', fontsize=14)\n",
    "plt.ylabel('Survival probability', fontsize=14)\n",
    "plt.legend(title='Infection group', fontsize=12, frameon=False)\n",
    "plt.grid(False)\n",
    "\n",
    "# Customize plot aesthetics\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_color('black')\n",
    "ax.spines['bottom'].set_color('black')\n",
    "ax.spines['left'].set_linewidth(2)\n",
    "ax.spines['bottom'].set_linewidth(2)\n",
    "plt.gca().invert_yaxis()\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "reversed_survival_plot_path = f\"./download/first_ad_diagnosis_by_infection_group_with_logrank_{di}_reverse.pdf\"\n",
    "plt.savefig(reversed_survival_plot_path, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Filter for first occurrence of AD per patient\n",
    "ad_data = combined_age_data_cleaned[combined_age_data_cleaned['disease_name'] == 'alzheimer']\n",
    "ad_data_first = ad_data.sort_values(by='age_at_diagnosis').drop_duplicates(subset='person_id')\n",
    "\n",
    "# Step 2: Count unique AD patients and create sequential IDs\n",
    "num_ad_patients = len(ad_data_first)\n",
    "ad_data_first['sequential_id'] = range(1, num_ad_patients + 1)\n",
    "id_mapping = ad_data_first.set_index('person_id')['sequential_id'].to_dict()\n",
    "\n",
    "# Step 3: Add sequential IDs to the full dataset\n",
    "filtered_data = combined_age_data_cleaned[combined_age_data_cleaned['person_id'].isin(id_mapping.keys())].copy()\n",
    "filtered_data['sequential_id'] = filtered_data['person_id'].map(id_mapping)\n",
    "\n",
    "# Step 4: Separate data into before and after AD onset\n",
    "# Before AD onset: All diseases except AD below the AD onset age\n",
    "before_ad_data = []\n",
    "after_ad_data = []\n",
    "\n",
    "for person_id in ad_data_first['person_id']:\n",
    "    person_data = filtered_data[filtered_data['person_id'] == person_id]\n",
    "    ad_age = person_data[person_data['disease_name'] == 'alzheimer']['age_at_diagnosis'].iloc[0]\n",
    "    \n",
    "    # Data before AD onset (only bacterial infections, exclude Alzheimer's)\n",
    "    before_ad_data.append(person_data[\n",
    "        (person_data['age_at_diagnosis'] < ad_age) &\n",
    "        (person_data['disease_name'].str.contains('|'.join(bacterial_infections), case=False))\n",
    "    ])\n",
    "    \n",
    "    # Data after AD onset (Alzheimer only)\n",
    "    after_ad_data.append(person_data[\n",
    "        (person_data['age_at_diagnosis'] >= ad_age) & \n",
    "        (person_data['disease_name'] == 'alzheimer')\n",
    "    ])\n",
    "\n",
    "before_ad_data = pd.concat(before_ad_data)\n",
    "after_ad_data = pd.concat(after_ad_data)\n",
    "\n",
    "# # Display Results\n",
    "# print(f\"Before AD Data: {before_ad_data.shape[0]} rows\")\n",
    "# print(f\"After AD Data: {after_ad_data.shape[0]} rows\")\n",
    "\n",
    "# # Preview the dataframes\n",
    "# print(\"\\nBefore AD Data:\")\n",
    "# print(before_ad_data.head())\n",
    "\n",
    "# print(\"\\nAfter AD Data:\")\n",
    "# print(after_ad_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the diseases to include and their order for consistent coloring\n",
    "disease_list = [\n",
    "    'staphylococcus', 'ecoli', 'pseudomonas', \n",
    "    'gram_negative', 'gram_positive', 'streptococcus'\n",
    "]\n",
    "\n",
    "# Define the color order for the diseases\n",
    "color_order = {\n",
    "    'staphylococcus': 'blue', 'ecoli': 'green', \n",
    "    'pseudomonas': 'black',  # Pseudomonas in black as per request\n",
    "    'gram_negative': 'orange', 'gram_positive': 'red', \n",
    "    'streptococcus': 'brown'\n",
    "}\n",
    "\n",
    "# Define the labels for the legend\n",
    "legend_labels = {\n",
    "    'staphylococcus': 'Staphylococcus',\n",
    "    'ecoli': 'E. coli',\n",
    "    'pseudomonas': 'Pseudomonas',\n",
    "    'gram_negative': 'Gram-negative Bacteria',\n",
    "    'gram_positive': 'Gram-positive Bacteria',\n",
    "    'streptococcus': 'Streptococcus'\n",
    "}\n",
    "\n",
    "# Step 5: Plot data\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Plot bacterial infections before AD onset\n",
    "sns.scatterplot(\n",
    "    data=before_ad_data,\n",
    "    x='sequential_id',\n",
    "    y='age_at_diagnosis',\n",
    "    hue='disease_name',\n",
    "    palette=color_order,\n",
    "    hue_order=disease_list,\n",
    "    s=100,\n",
    "    alpha=0.7,\n",
    "    zorder=2,\n",
    "    legend='full'\n",
    ")\n",
    "\n",
    "# Highlight Alzheimer's after AD onset\n",
    "sns.scatterplot(\n",
    "    data=after_ad_data[after_ad_data['disease_name'] == 'alzheimer'],\n",
    "    x='sequential_id',\n",
    "    y='age_at_diagnosis',\n",
    "    color='lightblue',\n",
    "    s=100,\n",
    "    alpha=0.7,\n",
    "    label=f\"{di} after anset age\",\n",
    "    zorder=1\n",
    ")\n",
    "\n",
    "# Plot bacterial infections after AD onset\n",
    "sns.scatterplot(\n",
    "    data=after_ad_data[after_ad_data['disease_name'] != 'alzheimer'],\n",
    "    x='sequential_id',\n",
    "    y='age_at_diagnosis',\n",
    "    hue='disease_name',\n",
    "    palette=color_order,\n",
    "    hue_order=disease_list,\n",
    "    s=100,\n",
    "    alpha=0.7,\n",
    "    zorder=4,\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "# Add a line for AD onset ages\n",
    "plt.plot(\n",
    "    ad_data_first['sequential_id'],\n",
    "    ad_data_first['age_at_diagnosis'],\n",
    "    color='blue',\n",
    "    label=f'{di} onset age',\n",
    "    linewidth=3,\n",
    "    zorder=5\n",
    ")\n",
    "\n",
    "# Enhance the plot\n",
    "plt.title(f'Diseases before and after onset age of {di}', fontsize=16)\n",
    "plt.xlabel(f'Patient ID', fontsize=16)\n",
    "plt.ylabel('Age at diagnosis', fontsize=16)\n",
    "\n",
    "# Adjust legend\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "unique_legend = dict(zip(labels, handles))  # Remove duplicates\n",
    "plt.legend(\n",
    "    unique_legend.values(),\n",
    "    unique_legend.keys(),\n",
    "    title='Disease',\n",
    "    fontsize=12,\n",
    "    frameon=False,\n",
    "    loc='upper right',\n",
    "    bbox_to_anchor=(1.2, 1)\n",
    ")\n",
    "\n",
    "# Customize plot aesthetics\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_color('black')\n",
    "ax.spines['bottom'].set_color('black')\n",
    "ax.spines['left'].set_linewidth(2)\n",
    "ax.spines['bottom'].set_linewidth(2)\n",
    "\n",
    "# Improve tick readability\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# Dynamically set X-axis limits\n",
    "plt.xlim(-5, num_ad_patients + 5)\n",
    "plt.grid(False)\n",
    "# Save the plot\n",
    "output_path = f\"./download/diseases_before_after_onset_Best_only_for_those_with_bacteria_infection_before_{di}.pdf\"\n",
    "plt.savefig(output_path, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Plot saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define diseases to include and their order\n",
    "disease_list = [\n",
    "    'staphylococcus', 'ecoli', 'pseudomonas', \n",
    "    'gram_negative', 'gram_positive', 'streptococcus', 'alzheimer'\n",
    "]\n",
    "\n",
    "# Define color order for the diseases\n",
    "color_order = {\n",
    "    'staphylococcus': 'blue', 'ecoli': 'green', \n",
    "    'pseudomonas': 'black',\n",
    "    'gram_negative': 'orange', 'gram_positive': 'red', \n",
    "    'streptococcus': 'brown', 'alzheimer': 'lightblue'\n",
    "}\n",
    "\n",
    "# Step 1: Filter for Alzheimer's data\n",
    "ad_data = combined_age_data_cleaned[combined_age_data_cleaned['disease_name'] == 'alzheimer']\n",
    "ad_data_first = ad_data.sort_values(by='age_at_diagnosis').drop_duplicates(subset='person_id')\n",
    "\n",
    "# Step 2: Create sequential IDs for Alzheimer's patients\n",
    "num_ad_patients = len(ad_data_first)\n",
    "ad_data_first['sequential_id'] = range(1, num_ad_patients + 1)\n",
    "id_mapping = ad_data_first.set_index('person_id')['sequential_id'].to_dict()\n",
    "\n",
    "# Step 3: Add sequential IDs to the full dataset\n",
    "combined_age_data_cleaned['sequential_id'] = combined_age_data_cleaned['person_id'].map(id_mapping)\n",
    "\n",
    "# Step 4: Separate data into before and after AD onset\n",
    "before_ad_data = []\n",
    "after_ad_data = []\n",
    "\n",
    "for person_id in ad_data_first['person_id']:\n",
    "    person_data = combined_age_data_cleaned[combined_age_data_cleaned['person_id'] == person_id]\n",
    "    ad_age = person_data[person_data['disease_name'] == 'alzheimer']['age_at_diagnosis'].iloc[0]\n",
    "    \n",
    "    # Data before AD onset (bacterial infections only)\n",
    "    before_ad_data.append(person_data[\n",
    "        (person_data['age_at_diagnosis'] < ad_age) & \n",
    "        (person_data['disease_name'].isin(disease_list[:-1]))  # Exclude 'alzheimer'\n",
    "    ])\n",
    "    \n",
    "    # Data after AD onset (bacterial infections + Alzheimer)\n",
    "    after_ad_data.append(person_data[\n",
    "        (person_data['age_at_diagnosis'] >= ad_age) & \n",
    "        (person_data['disease_name'].isin(disease_list))  # Include all diseases\n",
    "    ])\n",
    "\n",
    "before_ad_data = pd.concat(before_ad_data, ignore_index=True)\n",
    "after_ad_data = pd.concat(after_ad_data, ignore_index=True)\n",
    "\n",
    "# Step 5: Plot data\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Plot Alzheimer's data as a background layer\n",
    "sns.scatterplot(\n",
    "    data=after_ad_data[after_ad_data['disease_name'] == 'alzheimer'],\n",
    "    x='sequential_id',\n",
    "    y='age_at_diagnosis',\n",
    "    color='lightblue',\n",
    "#         color='#A3C1DA',\n",
    "    s=100,  # Larger size to emphasize the background\n",
    "    alpha=1,  # More transparency for background effect\n",
    "    zorder=1,\n",
    "    label=f'{di}',\n",
    "     edgecolor='none'\n",
    ")\n",
    "\n",
    "# Plot bacterial infections before AD onset\n",
    "sns.scatterplot(\n",
    "    data=before_ad_data,\n",
    "    x='sequential_id',\n",
    "    y='age_at_diagnosis',\n",
    "    hue='disease_name',\n",
    "    palette=color_order,\n",
    "    hue_order=disease_list[:-1],\n",
    "    s=100,\n",
    "    alpha=0.7,\n",
    "    zorder=2,\n",
    "    legend='full',\n",
    "     edgecolor='none'\n",
    ")\n",
    "\n",
    "# Plot bacterial infections after AD onset\n",
    "sns.scatterplot(\n",
    "    data=after_ad_data[after_ad_data['disease_name'] != 'alzheimer'],\n",
    "    x='sequential_id',\n",
    "    y='age_at_diagnosis',\n",
    "    hue='disease_name',\n",
    "    palette=color_order,\n",
    "    hue_order=disease_list[:-1],\n",
    "    s=100,\n",
    "    alpha=0.7,\n",
    "    zorder=3,\n",
    "    legend='full',\n",
    "     edgecolor='none'\n",
    ")\n",
    "\n",
    "# Add a line for AD onset ages\n",
    "plt.plot(\n",
    "    ad_data_first['sequential_id'],\n",
    "    ad_data_first['age_at_diagnosis'],\n",
    "    color='blue',\n",
    "    label=f'{di} onset age',\n",
    "    linewidth=1,\n",
    "    zorder=5\n",
    ")\n",
    "\n",
    "# Enhance the plot\n",
    "plt.title(f'Diseases before and after onset age of {di}', fontsize=16)\n",
    "plt.xlabel('Patient ID', fontsize=16)\n",
    "plt.ylabel('Age at diagnosis', fontsize=16)\n",
    "\n",
    "# Adjust legend\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "unique_legend = dict(zip(labels, handles))  # Remove duplicates\n",
    "plt.legend(\n",
    "    unique_legend.values(),\n",
    "    unique_legend.keys(),\n",
    "    title='Disease',\n",
    "    fontsize=12,\n",
    "    frameon=False,\n",
    "    loc='upper right',\n",
    "    bbox_to_anchor=(1.2, 1)\n",
    ")\n",
    "\n",
    "# Customize plot aesthetics\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_color('black')\n",
    "ax.spines['bottom'].set_color('black')\n",
    "ax.spines['left'].set_linewidth(2)\n",
    "ax.spines['bottom'].set_linewidth(2)\n",
    "\n",
    "# Improve tick readability\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# Dynamically set X-axis limits\n",
    "plt.xlim(-5, num_ad_patients + 5)\n",
    "plt.grid(False)\n",
    "\n",
    "# Save the plot\n",
    "output_path =f\"./download/diseases_before_after_onset_with_background_{di}.pdf\"\n",
    "plt.savefig(output_path, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Plot saved to {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_age_data_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of patients per disease in combined_age_data_cleaned\n",
    "patient_counts_per_disease = combined_age_data_cleaned.groupby('disease_name')['person_id'].nunique()\n",
    "patient_counts_per_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, find unique IDs for each disease\n",
    "unique_ids_per_disease = {\n",
    "    disease: set(combined_age_data_cleaned[combined_age_data_cleaned['disease_name'] == disease]['person_id'].unique())\n",
    "    for disease in combined_age_data_cleaned['disease_name'].unique()\n",
    "}\n",
    "\n",
    "# Separate unique IDs for Alzheimer and other disorders\n",
    "alzheimer_ids = unique_ids_per_disease.pop('alzheimer', set())\n",
    "\n",
    "# Find unique IDs for each other disorder\n",
    "other_disorder_ids = {disease: ids for disease, ids in unique_ids_per_disease.items()}\n",
    "\n",
    "# Calculate the intersection of IDs (common IDs) between Alzheimer and each other disorder\n",
    "common_ids_counts = {\n",
    "    disease: len(alzheimer_ids.intersection(ids))\n",
    "    for disease, ids in other_disorder_ids.items()\n",
    "}\n",
    "\n",
    "# Prepare the results\n",
    "results = {\n",
    "    'Alzheimer': len(alzheimer_ids),\n",
    "    **{disease: len(ids) for disease, ids in other_disorder_ids.items()},\n",
    "    'Common': common_ids_counts\n",
    "}\n",
    "\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame.from_dict(results, orient='index', columns=['Count'])\n",
    "results_df \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total unique IDs for each disease\n",
    "disease_counts = {disease: len(ids) for disease, ids in unique_ids_per_disease.items()}\n",
    "\n",
    "# Common IDs between Alzheimer and each disorder\n",
    "common_ids_with_ad = {\n",
    "    disease: len(alzheimer_ids.intersection(ids))\n",
    "    for disease, ids in unique_ids_per_disease.items()\n",
    "}\n",
    "\n",
    "# Combine the data into a DataFrame\n",
    "disease_overlap_df = pd.DataFrame({\n",
    "    \"Disease\": list(disease_counts.keys()),\n",
    "    \"disease_count\": list(disease_counts.values()),\n",
    "    \"common_id_with_AD_disease\": list(common_ids_with_ad.values())\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_overlap_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for patients with Alzheimer's disease in `combined_age_data_cleaned`\n",
    "alzheimer_data_test = combined_age_data_cleaned[combined_age_data_cleaned['disease_name'] == 'alzheimer']\n",
    "\n",
    "# Find the earliest age of Alzheimer diagnosis for each person\n",
    "earliest_ad_diagnosis = alzheimer_data_test.groupby('person_id').apply(\n",
    "    lambda group: group.loc[group['age_at_diagnosis'].idxmin()]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Calculate the age of onset for dementia (earliest age of Alzheimer diagnosis)\n",
    "earliest_ad_diagnosis['age_onset_of_alzheimer'] = earliest_ad_diagnosis['age_at_diagnosis']\n",
    "\n",
    "# Select relevant columns for the final DataFrame\n",
    "ad_earliest_diagnosis_df = earliest_ad_diagnosis[[\n",
    "    'person_id', 'age_at_diagnosis', 'disease_name', 'age', 'diagnosis_year_month', 'date_of_birth', 'age_onset_of_alzheimer'\n",
    "]]\n",
    "# ad_earliest_diagnosis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_age_data_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column to `ad_earliest_diagnosis_df` for the start of the 5-year window\n",
    "ad_earliest_diagnosis_df['start_window'] = ad_earliest_diagnosis_df['age_onset_of_alzheimer'] - 5\n",
    "\n",
    "# Merge `combined_age_data_cleaned` with `ad_earliest_diagnosis_df` to get all diseases for AD patients\n",
    "merged_data = combined_age_data_cleaned.merge(\n",
    "    ad_earliest_diagnosis_df[['person_id', 'start_window', 'age_onset_of_alzheimer']],\n",
    "    on='person_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Filter the data for diseases within the 5-year window before AD onset\n",
    "merged_data['within_window'] = (\n",
    "    (merged_data['age_at_diagnosis'] >= merged_data['start_window']) &\n",
    "    (merged_data['age_at_diagnosis'] <= merged_data['age_onset_of_alzheimer'])\n",
    ")\n",
    "\n",
    "# Filter only rows within the window\n",
    "diseases_within_window = merged_data[merged_data['within_window']]\n",
    "\n",
    "# Count how many patients had each disease within the 5-year window\n",
    "disease_counts_within_window = diseases_within_window['disease_name'].value_counts()\n",
    "\n",
    "# Convert to a DataFrame for better presentation\n",
    "disease_counts_within_window_df = disease_counts_within_window.reset_index()\n",
    "disease_counts_within_window_df.columns = ['Disease', 'Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_counts_within_window_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Add categories based on age relative to AD onset\n",
    "merged_data['time_category'] = 'Other'\n",
    "\n",
    "# 5 years before AD onset (exclusive of earlier categories)\n",
    "merged_data.loc[\n",
    "    (merged_data['age_at_diagnosis'] >= merged_data['start_window']) &\n",
    "    (merged_data['age_at_diagnosis'] <= merged_data['age_onset_of_alzheimer']),\n",
    "    'time_category'\n",
    "] = '5 years before AD'\n",
    "\n",
    "# Before 5 years window\n",
    "merged_data.loc[\n",
    "    (merged_data['age_at_diagnosis'] < merged_data['start_window']),\n",
    "    'time_category'\n",
    "] = 'Before 5 years'\n",
    "\n",
    "# After AD onset\n",
    "merged_data.loc[\n",
    "    (merged_data['age_at_diagnosis'] > merged_data['age_onset_of_alzheimer']),\n",
    "    'time_category'\n",
    "] = 'After AD onset'\n",
    "\n",
    "# Step 2: Assign categories uniquely, prioritizing '5 years before AD'\n",
    "merged_data = merged_data.sort_values(by='time_category', key=lambda col: col.map({\n",
    "    '5 years before AD': 1,\n",
    "    'Before 5 years': 2,\n",
    "    'After AD onset': 3,\n",
    "    'Other': 4\n",
    "})).drop_duplicates(subset=['person_id', 'disease_name'])\n",
    "\n",
    "# Step 3: Count diseases in each category\n",
    "category_counts = (\n",
    "    merged_data.groupby(['time_category', 'disease_name'])['person_id']\n",
    "    .nunique()\n",
    "    .reset_index()\n",
    "    .rename(columns={'person_id': 'Patient_Count'})\n",
    ")\n",
    "# category_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the plot style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(14, 8))\n",
    "bar_plot = sns.barplot(\n",
    "    data=category_counts[category_counts['disease_name']!='alzheimer'],\n",
    "    x='disease_name',\n",
    "    y='Patient_Count',\n",
    "    hue='time_category',\n",
    "    palette='tab10'\n",
    ")\n",
    "\n",
    "# Enhance the plot\n",
    "plt.title(\"Patient Count by Disease and Time Category\", fontsize=16)\n",
    "plt.xlabel(\"Disease Name\", fontsize=14)\n",
    "plt.ylabel(\"Patient Count\", fontsize=14)\n",
    "plt.xticks(rotation=45, fontsize=12, ha=\"right\")\n",
    "plt.legend(title=\"Time Category\", fontsize=12,frameon=False)\n",
    "# Customize the plot aesthetics\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_color('black')\n",
    "ax.spines['bottom'].set_color('black')\n",
    "ax.spines['left'].set_linewidth(2)\n",
    "ax.spines['bottom'].set_linewidth(2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.grid(False)\n",
    "\n",
    "# Save the plot\n",
    "output_plot_path = \"./download/patient_count_by_disease_time_category.pdf\"\n",
    "plt.savefig(output_plot_path, dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "print(f\"Plot saved to: {output_plot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values in 'Patient_Count' column if less than 20\n",
    "category_counts['Patient_Count'] = category_counts['Patient_Count'].apply(\n",
    "    lambda x: '<20' if x < 20 else x\n",
    ")\n",
    "\n",
    "# Save the modified DataFrame to a new file\n",
    "category_counts_path = \"./download/modified_category_counts.tsv\"\n",
    "category_counts.to_csv(category_counts_path, sep='\\t', index=False)\n",
    "\n",
    "# Print the file path\n",
    "print(f\"Modified category_counts saved to: {category_counts_path}\")\n",
    "\n",
    "# Display the modified DataFrame\n",
    "category_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_counts.to_csv(f'./download/Disease_infection_5_year_pior_of_{di}.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results to a file in the specified directory\n",
    "output_path = \"./download/disease_count_by_time_category.tsv\"\n",
    "category_counts.to_csv(output_path, sep='\\t', index=False)\n",
    "\n",
    "print(f\"Disease count by time category saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def test_age_difference_direction(df, disease_dfs):\n",
    "    \"\"\"\n",
    "    Perform one-sample t-test to determine if a disease occurs before or after AD.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for disease in disease_dfs.keys():\n",
    "        age_difference_col = f\"Age_difference_AD_{disease}\"\n",
    "        if age_difference_col in df.columns:\n",
    "            data = df[age_difference_col].dropna()\n",
    "            if len(data) > 1:\n",
    "                # Perform one-sample t-test\n",
    "                t_stat, t_pval = ttest_1samp(data, 0)\n",
    "\n",
    "                # Determine direction\n",
    "                mean_difference = data.median()\n",
    "                if mean_difference < 0:\n",
    "                    direction = \"First AD\"\n",
    "                elif mean_difference > 0:\n",
    "                    direction = \"First Disease\"\n",
    "                else:\n",
    "                    direction = \"No Difference\"\n",
    "\n",
    "                # Append results\n",
    "                results.append({\n",
    "                    \"Disease\": disease,\n",
    "                    \"Mean Age Difference\": mean_difference,\n",
    "                    \"T-Test Statistic\": t_stat,\n",
    "                    \"T-Test P-Value\": t_pval,\n",
    "                    \"Direction\": direction\n",
    "                })\n",
    "    return pd.DataFrame(results)\n",
    "# Function to annotate with direction\n",
    "def annotate_with_direction(ax, test_results):\n",
    "    for i, result in enumerate(test_results.to_dict(orient=\"records\")):\n",
    "        disease = result[\"Disease\"]\n",
    "        direction = result[\"Direction\"]\n",
    "        t_pval = result[\"T-Test P-Value\"]\n",
    "        ax.text(\n",
    "            i,\n",
    "            ax.get_ylim()[1] - 1,  # Adjust based on data range\n",
    "            f\"{direction}\\nP(T): {mean_differencel:.3f}\",\n",
    "            ha=\"center\",\n",
    "            fontsize=10,\n",
    "            color=\"black\"\n",
    "        )\n",
    "direction_test_results = test_age_difference_direction(final_combined_df, disease_dfs)\n",
    "direction_test_results\n",
    "from scipy.stats import ttest_1samp, wilcoxon\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "# Function to prepare combined_plot_data\n",
    "def prepare_plot_data(df, disease_dfs):\n",
    "    \"\"\"\n",
    "    Prepare data for plotting Age Difference by Disease.\n",
    "    \"\"\"\n",
    "    plot_data = []\n",
    "    for disease in disease_dfs.keys():\n",
    "        age_difference_col = f\"Age_difference_AD_{disease}\"\n",
    "        if age_difference_col in df.columns:\n",
    "            temp_df = df[[age_difference_col]].dropna()\n",
    "            temp_df[\"Disease\"] = disease\n",
    "            temp_df[\"Age Difference\"] = temp_df[age_difference_col]\n",
    "            plot_data.append(temp_df[[\"Disease\", \"Age Difference\"]])\n",
    "    return pd.concat(plot_data, ignore_index=True)\n",
    "\n",
    "# Statistical tests function\n",
    "def test_age_difference(df, disease_dfs):\n",
    "    \"\"\"\n",
    "    Perform one-sample t-test, Wilcoxon test, and proportion test for Age Difference.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for disease in disease_dfs.keys():\n",
    "        age_difference_col = f\"Age_difference_AD_{disease}\"\n",
    "        if age_difference_col in df.columns:\n",
    "            data = df[age_difference_col].dropna()\n",
    "            if len(data) > 1:\n",
    "                # T-test\n",
    "                t_stat, t_pval = ttest_1samp(data, 0)\n",
    "\n",
    "                # Wilcoxon signed-rank test\n",
    "                try:\n",
    "                    w_stat, w_pval = wilcoxon(data - 0)\n",
    "                except ValueError:\n",
    "                    w_stat, w_pval = None, None\n",
    "\n",
    "                # Proportion test for 0.5 year difference\n",
    "                within_half_year = ((data >= -0.5) & (data <= 0.5)).sum()\n",
    "                n_total = len(data)\n",
    "                proportion = within_half_year / n_total\n",
    "                expected_proportion = 0.5  # Null hypothesis: 50% of cases fall within 0.5 years\n",
    "                z_stat, prop_pval = proportions_ztest(within_half_year, n_total, value=expected_proportion)\n",
    "\n",
    "                results.append({\n",
    "                    \"Disease\": disease,\n",
    "                    \"T-Test P-Value\": t_pval,\n",
    "                    \"Wilcoxon P-Value\": w_pval,\n",
    "                    \"Proportion P-Value\": prop_pval,\n",
    "                    \"Mean Age Difference\": data.mean(),\n",
    "                    \"Median Age Difference\": data.median(),\n",
    "                    \"Proportion 0.5 Year\": proportion\n",
    "                })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Function to annotate plot with p-values\n",
    "def annotate_plot_with_pvalues(ax, test_results):\n",
    "    for i, result in enumerate(test_results.to_dict(orient=\"records\")):\n",
    "        disease = result[\"Disease\"]\n",
    "        t_pval = result[\"T-Test P-Value\"]\n",
    "        prop_pval = result[\"Proportion P-Value\"]\n",
    "        ax.text(\n",
    "            i,\n",
    "            ax.get_ylim()[1] - 3,  # Adjust based on data range\n",
    "            f\"T-Test P: {t_pval:.3f}\\n\",\n",
    "            ha=\"center\",\n",
    "            fontsize=10,\n",
    "            color=\"black\"\n",
    "        )\n",
    "\n",
    "# Simulated data\n",
    "diseases = ['ecoli', 'gram_negative', 'gram_positive', 'pseudomonas', 'staphylococcus', 'streptococcus', 'retrovirus']\n",
    "disease_dfs = {disease: None for disease in diseases}\n",
    "\n",
    "# Prepare data\n",
    "combined_plot_data = prepare_plot_data(final_combined_df, disease_dfs)\n",
    "\n",
    "# Perform statistical tests\n",
    "one_sample_test_results = test_age_difference(final_combined_df, disease_dfs)\n",
    "\n",
    "# Annotate with direction and t-test results for direction\n",
    "def annotate_with_direction(ax, test_results):\n",
    "    for i, result in enumerate(test_results.to_dict(orient=\"records\")):\n",
    "        disease = result[\"Disease\"]\n",
    "        direction = result[\"Direction\"]\n",
    "        t_pval = result[\"T-Test P-Value\"]\n",
    "        mean_difference= result[\"Mean Age Difference\"]\n",
    "        ax.text(\n",
    "            i,\n",
    "            ax.get_ylim()[1] - 4.4,  # Adjust based on data range\n",
    "            f\"{direction}\\nMedian: {mean_difference:.3f}\",\n",
    "            ha=\"center\",\n",
    "            fontsize=10,\n",
    "            color=\"black\"\n",
    "        )\n",
    "\n",
    "# Run direction test\n",
    "direction_test_results = test_age_difference_direction(final_combined_df, disease_dfs)\n",
    "\n",
    "# Plot the existing graph\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.violinplot(\n",
    "    x=\"Disease\",\n",
    "    y=\"Age Difference\",\n",
    "    data=combined_plot_data,\n",
    "    palette=\"Set2\",\n",
    "    showfliers=False\n",
    ")\n",
    "sns.stripplot(\n",
    "    x=\"Disease\",\n",
    "    y=\"Age Difference\",\n",
    "    data=combined_plot_data,\n",
    "    color=\"black\",\n",
    "    alpha=0.5,\n",
    "    jitter=True\n",
    ")\n",
    "plt.axhline(-0.5, color=\"Grey\", linestyle=\"--\", linewidth=1.5, label=\"-1 Year Difference\")\n",
    "plt.axhline(+0.5, color=\"Grey\", linestyle=\"--\", linewidth=1.5, label=\"+1 Year Difference\")\n",
    "plt.axhline(0, color=\"red\", linestyle=\"--\", linewidth=1.5, label=\"Same Time Reference\")\n",
    "plt.title(\"Distribution of Age Difference (AD Onset - Disease Onset) by Disease\", fontsize=16)\n",
    "plt.xlabel(\"Disease\", fontsize=14)\n",
    "plt.ylabel(\"Age Difference (Years)\", fontsize=14)\n",
    "plt.xticks(rotation=45, fontsize=12)\n",
    "plt.legend(loc=\"upper right\", bbox_to_anchor=(1.2, 0.9), frameon=False)\n",
    "plt.grid(axis='y', linestyle='--', linewidth=0.1)\n",
    "plt.ylim(-45, 45)\n",
    "# Annotate counts below each x-axis label\n",
    "disease_counts = combined_plot_data.groupby(\"Disease\")[\"Age Difference\"].count()\n",
    "\n",
    "for i, disease in enumerate(disease_counts.index):\n",
    "    count = disease_counts[disease]\n",
    "    if count <20:\n",
    "        plt.text(\n",
    "            i, ax.get_ylim()[1] - 6,  # Position the text below the x-axis\n",
    "            f\"n is <20\",\n",
    "            ha=\"center\",\n",
    "            fontsize=10,\n",
    "            color=\"black\"\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        plt.text(\n",
    "            i, ax.get_ylim()[1] - 6,  # Position the text below the x-axis\n",
    "            f\"n is {count}\",\n",
    "            ha=\"center\",\n",
    "            fontsize=10,\n",
    "            color=\"black\"\n",
    "        )\n",
    "# Customize plot spines\n",
    "ax = plt.gca()\n",
    "ax.spines['left'].set_color('black')\n",
    "ax.spines['bottom'].set_color('black')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['left'].set_linewidth(2)\n",
    "ax.spines['bottom'].set_linewidth(2)\n",
    "\n",
    "# Annotate with statistical test p-values\n",
    "annotate_plot_with_pvalues(ax, one_sample_test_results)\n",
    "annotate_with_direction(ax, direction_test_results)  # Add this annotation\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "forest_plot_path = f'./download/Violin_plot_stripplot_{di}.pdf'\n",
    "plt.savefig(forest_plot_path, format='pdf')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare combined_plot_data\n",
    "def prepare_plot_data(df, disease_dfs):\n",
    "    \"\"\"\n",
    "    Prepare data for plotting Age Difference by Disease.\n",
    "    \"\"\"\n",
    "    plot_data = []\n",
    "    for disease in disease_dfs.keys():\n",
    "        age_difference_col = f\"Age_difference_AD_{disease}\"\n",
    "        if age_difference_col in df.columns:\n",
    "            temp_df = df[[age_difference_col]].dropna()\n",
    "            temp_df[\"Disease\"] = disease\n",
    "            temp_df[\"Age Difference\"] = temp_df[age_difference_col]\n",
    "            plot_data.append(temp_df[[\"Disease\", \"Age Difference\"]])\n",
    "    return pd.concat(plot_data, ignore_index=True)\n",
    "\n",
    "# Statistical tests function\n",
    "def test_age_difference(df, disease_dfs):\n",
    "    \"\"\"\n",
    "    Perform one-sample t-test, Wilcoxon test, and proportion test for Age Difference.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for disease in disease_dfs.keys():\n",
    "        age_difference_col = f\"Age_difference_AD_{disease}\"\n",
    "        if age_difference_col in df.columns:\n",
    "            data = df[age_difference_col].dropna()\n",
    "            if len(data) > 1:\n",
    "                # T-test\n",
    "                t_stat, t_pval = ttest_1samp(data, 0)\n",
    "\n",
    "                # Wilcoxon signed-rank test\n",
    "                try:\n",
    "                    w_stat, w_pval = wilcoxon(data - 0)\n",
    "                except ValueError:\n",
    "                    w_stat, w_pval = None, None\n",
    "\n",
    "                # Proportion test for 0.5 year difference\n",
    "                within_half_year = ((data >= -0.5) & (data <= 0.5)).sum()\n",
    "                n_total = len(data)\n",
    "                proportion = within_half_year / n_total\n",
    "                expected_proportion = 0.5  # Null hypothesis: 50% of cases fall within 0.5 years\n",
    "                z_stat, prop_pval = proportions_ztest(within_half_year, n_total, value=expected_proportion)\n",
    "\n",
    "                results.append({\n",
    "                    \"Disease\": disease,\n",
    "                    \"T-Test P-Value\": t_pval,\n",
    "                    \"Wilcoxon P-Value\": w_pval,\n",
    "                    \"Proportion P-Value\": prop_pval,\n",
    "                    \"Mean Age Difference\": data.mean(),\n",
    "                    \"Median Age Difference\": data.median(),\n",
    "                    \"Proportion 0.5 Year\": proportion\n",
    "                })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Function to annotate plot with p-values\n",
    "def annotate_plot_with_pvalues(ax, test_results):\n",
    "    for i, result in enumerate(test_results.to_dict(orient=\"records\")):\n",
    "        disease = result[\"Disease\"]\n",
    "        t_pval = result[\"T-Test P-Value\"]\n",
    "        prop_pval = result[\"Proportion P-Value\"]\n",
    "        ax.text(\n",
    "            i,\n",
    "            ax.get_ylim()[1] - 3,  # Adjust based on data range\n",
    "            f\"T-Test P: {t_pval:.3f}\\n\",\n",
    "            ha=\"center\",\n",
    "            fontsize=10,\n",
    "            color=\"black\"\n",
    "        )\n",
    "\n",
    "# Simulated data\n",
    "diseases = ['ecoli', 'gram_negative', 'gram_positive', 'pseudomonas', 'staphylococcus', 'streptococcus', 'retrovirus']\n",
    "disease_dfs = {disease: None for disease in diseases}\n",
    "# Define a mapping for better disease labels\n",
    "disease_labels = {\n",
    "    'ecoli': 'E. coli',\n",
    "    'pseudomonas': 'Pseudomonas',\n",
    "    'gram_negative': 'Gram-Negative',\n",
    "    'gram_positive': 'Gram-Positive',\n",
    "    'staphylococcus': 'Staphylococcus',\n",
    "    'streptococcus': 'Streptococcus',\n",
    "    'retrovirus': 'Retrovirus'\n",
    "}\n",
    "\n",
    "# Map the disease labels in the combined_plot_data dataframe\n",
    "combined_plot_data['Disease'] = combined_plot_data['Disease'].map(disease_labels)\n",
    "\n",
    "# Perform statistical tests and map disease labels in test results\n",
    "one_sample_test_results['Disease'] = one_sample_test_results['Disease'].map(disease_labels)\n",
    "\n",
    "# Run direction test and map disease labels\n",
    "direction_test_results['Disease'] = direction_test_results['Disease'].map(disease_labels)\n",
    "\n",
    "# Plot the updated graph\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.violinplot(\n",
    "    x=\"Disease\",\n",
    "    y=\"Age Difference\",\n",
    "    data=combined_plot_data,\n",
    "    palette=\"Set2\",\n",
    "    showfliers=False\n",
    ")\n",
    "plt.axhline(-0.5, color=\"Grey\", linestyle=\"--\", linewidth=1.5, label=\"-1 Year Difference\")\n",
    "plt.axhline(+0.5, color=\"Grey\", linestyle=\"--\", linewidth=1.5, label=\"+1 Year Difference\")\n",
    "plt.axhline(0, color=\"red\", linestyle=\"--\", linewidth=1.5, label=\"Same Time Reference\")\n",
    "plt.title(f\"Distribution of Age Difference ({di} Onset - Disease Onset) by Disease\", fontsize=16)\n",
    "plt.xlabel(\"Disease\", fontsize=14)\n",
    "plt.ylabel(\"Age Difference (Years)\", fontsize=14)\n",
    "plt.xticks(rotation=90, fontsize=12)\n",
    "plt.legend(loc=\"upper right\", bbox_to_anchor=(1.2, 0.9), frameon=False)\n",
    "plt.grid(axis='y', linestyle='--', linewidth=0.1)\n",
    "plt.ylim(-45, 45)\n",
    "\n",
    "# Annotate counts below each x-axis label\n",
    "disease_counts = combined_plot_data.groupby(\"Disease\")[\"Age Difference\"].count()\n",
    "\n",
    "for i, disease in enumerate(disease_counts.index):\n",
    "    count = disease_counts[disease]\n",
    "    if count < 20:\n",
    "        plt.text(\n",
    "            i, ax.get_ylim()[1] - 6,  # Position the text below the x-axis\n",
    "            f\"n < 20\",\n",
    "            ha=\"center\",\n",
    "            fontsize=10,\n",
    "            color=\"black\"\n",
    "        )\n",
    "    else:\n",
    "        plt.text(\n",
    "            i, ax.get_ylim()[1] - 6,  # Position the text below the x-axis\n",
    "            f\"n = {count}\",\n",
    "            ha=\"center\",\n",
    "            fontsize=10,\n",
    "            color=\"black\"\n",
    "        )\n",
    "\n",
    "# Customize plot spines\n",
    "ax = plt.gca()\n",
    "ax.spines['left'].set_color('black')\n",
    "ax.spines['bottom'].set_color('black')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['left'].set_linewidth(2)\n",
    "ax.spines['bottom'].set_linewidth(2)\n",
    "\n",
    "# Annotate with statistical test p-values\n",
    "annotate_plot_with_pvalues(ax, one_sample_test_results)\n",
    "annotate_with_direction(ax, direction_test_results)  # Add this annotation\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "forest_plot_path = f'./download/Violin_plot_{di}.pdf'\n",
    "plt.savefig(forest_plot_path, format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_age_at_diagnosis(data, disease_name, person_info):\n",
    "    \"\"\"\n",
    "    Calculate the age at disease diagnosis for each person, ensuring no duplicate diagnoses in the same month.\n",
    "    \"\"\"\n",
    "    # Ensure `condition_start_datetime` and `date_of_birth` are in datetime format\n",
    "    data['condition_start_datetime'] = pd.to_datetime(data['condition_start_datetime'], errors='coerce')\n",
    "    person_info['date_of_birth'] = pd.to_datetime(person_info['date_of_birth'], errors='coerce')\n",
    "\n",
    "    # Drop rows where `condition_start_datetime` could not be parsed\n",
    "    data = data.dropna(subset=['condition_start_datetime'])\n",
    "\n",
    "    # Convert both to timezone-naive\n",
    "    data['condition_start_datetime'] = data['condition_start_datetime'].dt.tz_localize(None)\n",
    "    person_info['date_of_birth'] = person_info['date_of_birth'].dt.tz_localize(None)\n",
    "\n",
    "    # Extract the year and month of diagnosis\n",
    "    data['diagnosis_year_month'] = data['condition_start_datetime'].dt.to_period('M')\n",
    "\n",
    "    # Drop duplicate diagnoses for the same person and disease in the same month\n",
    "    data = data.drop_duplicates(subset=['person_id', 'diagnosis_year_month'])\n",
    "\n",
    "    # Merge with `person_info` to get date_of_birth and age\n",
    "    merged_data = data.merge(person_info, on='person_id', how='left')\n",
    "\n",
    "    # Calculate the age at diagnosis\n",
    "    merged_data['age_at_diagnosis'] = (\n",
    "        (merged_data['condition_start_datetime'] - merged_data['date_of_birth']).dt.days / 365.25\n",
    "    )\n",
    "\n",
    "    # Add disease name for clarity\n",
    "    merged_data['disease_name'] = disease_name\n",
    "\n",
    "    # Select relevant columns\n",
    "    age_data = merged_data[['person_id', 'age_at_diagnosis', 'disease_name', 'age', 'diagnosis_year_month','date_of_birth']]\n",
    "\n",
    "    return age_data\n",
    "\n",
    "\n",
    "\n",
    "# Assume `person_info` contains `person_id`, `date_of_birth`, and `age`\n",
    "person_info = final_combined_df[['person_id', 'date_of_birth', 'age']].copy()\n",
    "\n",
    "# Calculate age at diagnosis for each disease and combine results\n",
    "all_diagnoses = []\n",
    "for disease, df in disease_dataframes.items():\n",
    "    age_data = calculate_age_at_diagnosis(df, disease, person_info)\n",
    "    all_diagnoses.append(age_data)\n",
    "\n",
    "# Combine all diseases into a single DataFrame\n",
    "combined_age_data = pd.concat(all_diagnoses, ignore_index=True)\n",
    "\n",
    "\n",
    "# Remove rows with NaN values in the 'age' or 'age_at_diagnosis' columns\n",
    "combined_age_data_cleaned = combined_age_data.dropna(subset=['age', 'age_at_diagnosis'])\n",
    "# combined_age_data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# alzheimer_data_filtered=alzheimer_data.copy()\n",
    "# Ensure `final_combined_df` contains the necessary columns\n",
    "# final_combined_df = final_combined_df[['person_id', 'age', 'sex_at_birth']]\n",
    "\n",
    "# Convert `age` to numeric\n",
    "final_combined_df['age'] = pd.to_numeric(final_combined_df['age'], errors='coerce')\n",
    "\n",
    "# Diseases and their respective dataframes\n",
    "disease_dataframes = {\n",
    "    \"alzheimer\": alzheimer_data_filtered,\n",
    "    \"gram_negative\": gram_negative_data_filtered,\n",
    "    \"staphylococcus\": staphylococcus_data,\n",
    "    \"pseudomonas\": pseudomonas_data,\n",
    "    \"streptococcus\": streptococcus_data,\n",
    "    \"ecoli\": ecoli_data_filtered,\n",
    "    \"gram_positive\": gram_positive_data\n",
    "}\n",
    "\n",
    "def calculate_age_at_diagnosis(data, disease_name, person_info):\n",
    "    \"\"\"\n",
    "    Calculate the age at disease diagnosis for each person, ensuring no duplicate diagnoses in the same month.\n",
    "    \"\"\"\n",
    "    # Ensure `condition_start_datetime` is in datetime format\n",
    "    data['condition_start_datetime'] = pd.to_datetime(data['condition_start_datetime'], errors='coerce')\n",
    "\n",
    "    # Drop rows where `condition_start_datetime` could not be parsed\n",
    "    data = data.dropna(subset=['condition_start_datetime'])\n",
    "\n",
    "    # Extract the year and month of diagnosis\n",
    "    data['diagnosis_year_month'] = data['condition_start_datetime'].dt.to_period('M')\n",
    "\n",
    "    # Drop duplicate diagnoses for the same person and disease in the same month\n",
    "    data = data.drop_duplicates(subset=['person_id', 'diagnosis_year_month'])\n",
    "\n",
    "    # Merge with `person_info` to get the base age\n",
    "    merged_data = data.merge(person_info, on='person_id', how='left')\n",
    "\n",
    "    # Calculate the age at diagnosis\n",
    "    merged_data['age_at_diagnosis'] = merged_data['age'] + \\\n",
    "        (merged_data['condition_start_datetime'].dt.year - 2022)\n",
    "\n",
    "    # Add disease name for clarity\n",
    "    merged_data['disease_name'] = disease_name\n",
    "\n",
    "    # Select relevant columns\n",
    "    age_data = merged_data[['person_id', 'age_at_diagnosis', 'disease_name', 'age', 'diagnosis_year_month']]\n",
    "\n",
    "    return age_data\n",
    "\n",
    "# Process each disease to calculate ages at diagnosis\n",
    "age_at_diagnosis_list = []\n",
    "for disease, df in disease_dataframes.items():\n",
    "    if 'condition_start_datetime' not in df.columns:\n",
    "        print(f\"Skipping {disease} due to missing 'condition_start_datetime'\")\n",
    "        continue\n",
    "    disease_ages = calculate_age_at_diagnosis(df, disease, final_combined_df)\n",
    "    age_at_diagnosis_list.append(disease_ages)\n",
    "\n",
    "# Combine all ages into one dataframe\n",
    "final_age_data = pd.concat(age_at_diagnosis_list, ignore_index=True)\n",
    "\n",
    "# Display the table with ages at diagnosis\n",
    "# print(final_age_data)\n",
    "\n",
    "# keep patients that are in the creteria \n",
    "final_age_data = final_age_data[final_age_data['person_id'].isin(person_id_list)]\n",
    "final_age_data\n",
    "final_age_data = final_age_data[final_age_data['person_id'].isin(person_ids_more_than_10)].copy()\n",
    "final_age_data\n",
    "final_age_data[final_age_data['disease_name']=='alzheimer']['person_id'].nunique()\n",
    "# Step 1: Find the total number of unique individuals for each disease\n",
    "disease_counts = final_age_data.groupby('disease_name')['person_id'].nunique().reset_index()\n",
    "disease_counts.columns = ['disease_name', 'total_individuals']\n",
    "\n",
    "# Step 2: Identify individuals with Alzheimer's disease\n",
    "alzheimer_individuals = set(final_age_data[final_age_data['disease_name'] == 'alzheimer']['person_id'])\n",
    "\n",
    "# Step 3: For each disease, calculate overlap with Alzheimer's and age statistics\n",
    "summary_data = []\n",
    "for disease in disease_counts['disease_name']:\n",
    "    if disease == 'alzheimer':\n",
    "        continue  # Skip Alzheimer's as we are calculating overlap with it\n",
    "    \n",
    "    # Get individuals with the current disease\n",
    "    disease_individuals = set(final_age_data[final_age_data['disease_name'] == disease]['person_id'])\n",
    "    \n",
    "    # Calculate overlap and exclusivity\n",
    "    both_alzheimer_and_disease = alzheimer_individuals & disease_individuals\n",
    "    only_disease = disease_individuals - alzheimer_individuals\n",
    "    only_alzheimer = alzheimer_individuals - disease_individuals\n",
    "    neither = len(set(final_age_data['person_id'])) - len(both_alzheimer_and_disease) - len(only_disease) - len(only_alzheimer)\n",
    "    \n",
    "    # Calculate age statistics\n",
    "    both_ages = final_age_data[final_age_data['person_id'].isin(both_alzheimer_and_disease) & (final_age_data['disease_name'] == disease)]\n",
    "    only_disease_ages = final_age_data[final_age_data['person_id'].isin(only_disease) & (final_age_data['disease_name'] == disease)]\n",
    "    \n",
    "    # Append results\n",
    "    summary_data.append({\n",
    "        \"Disease\": disease,\n",
    "        \"Total_With_Disease\": len(disease_individuals),\n",
    "        f\"With_{di}_And_Disease\": len(both_alzheimer_and_disease),\n",
    "        f\"Mean_Age_{di}_And_Disease\": both_ages['age_at_diagnosis'].mean(),\n",
    "        f\"Median_Age_{di}_And_Disease\": both_ages['age_at_diagnosis'].median(),\n",
    "        \"With_Only_Disease\": len(only_disease),\n",
    "        \"Mean_Age_Only_Disease\": only_disease_ages['age_at_diagnosis'].mean(),\n",
    "        \"Median_Age_Only_Disease\": only_disease_ages['age_at_diagnosis'].median(),\n",
    "        f\"With_Only_v\": len(only_alzheimer),\n",
    "        \"With_Neither\": neither\n",
    "    })\n",
    "\n",
    "# Step 4: Convert summary data to a DataFrame\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Save the summary DataFrame to a TSV file\n",
    "summary_df_path = f\"./download/{di}_disease_overlap_summary_with_ages.tsv\"\n",
    "summary_df.to_csv(summary_df_path, sep='\\t', index=False)\n",
    "\n",
    "# Display the file path\n",
    "print(f\"Disease overlap summary with ages saved to: {summary_df_path}\")\n",
    "summary_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the data is sorted by person_id and disease_name\n",
    "final_age_data = final_age_data.sort_values(by=['person_id', 'disease_name'])\n",
    "\n",
    "# Filter the data for Alzheimer's disease\n",
    "alzheimer_data_test = final_age_data[final_age_data['disease_name'] == 'alzheimer']\n",
    "\n",
    "# Group by person_id and get the minimum age_at_diagnosis for Alzheimer's\n",
    "min_ad_age = alzheimer_data_test.groupby('person_id', as_index=False)['age_at_diagnosis'].min()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "min_ad_age.columns = ['person_id', 'min_ad_age_at_diagnosis']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for the first occurrence of AD per patient\n",
    "ad_data = final_age_data[final_age_data['disease_name'] == 'alzheimer']\n",
    "ad_data_first = ad_data.sort_values(by='age_at_diagnosis').drop_duplicates(subset='person_id')\n",
    "\n",
    "# Count unique AD patients\n",
    "num_ad_patients = len(ad_data_first)\n",
    "print(f\"Number of unique Alzheimer's disease (AD) patients: {num_ad_patients}\")\n",
    "\n",
    "# Create a mapping for sequential IDs\n",
    "ad_data_first['sequential_id'] = range(1, num_ad_patients + 1)\n",
    "id_mapping = ad_data_first.set_index('person_id')['sequential_id'].to_dict()\n",
    "\n",
    "# Add sequential IDs to the full dataset\n",
    "filtered_data = final_age_data[final_age_data['person_id'].isin(id_mapping.keys())].copy()\n",
    "filtered_data['sequential_id'] = filtered_data['person_id'].map(id_mapping)\n",
    "\n",
    "# Sort by sequential ID and age at diagnosis\n",
    "filtered_data = filtered_data.sort_values(by=['sequential_id', 'age_at_diagnosis'])\n",
    "\n",
    "# Create separate DataFrames for infections before and after AD onset\n",
    "pre_ad_data = []\n",
    "post_ad_data = []\n",
    "for person_id in ad_data_first['person_id']:\n",
    "    person_data = filtered_data[filtered_data['person_id'] == person_id]\n",
    "    ad_age = person_data[person_data['disease_name'] == 'alzheimer']['age_at_diagnosis'].iloc[0]\n",
    "    \n",
    "    # Separate diagnoses before and after AD onset\n",
    "    pre_ad = person_data[person_data['age_at_diagnosis'] <= ad_age]\n",
    "    post_ad = person_data[person_data['age_at_diagnosis'] > ad_age]\n",
    "    \n",
    "    pre_ad_data.append(pre_ad)\n",
    "    post_ad_data.append(post_ad)\n",
    "\n",
    "# Combine all data\n",
    "pre_ad_data = pd.concat(pre_ad_data)\n",
    "post_ad_data = pd.concat(post_ad_data)\n",
    "\n",
    "# Add a flag to indicate before or after AD\n",
    "pre_ad_data['relative_to_ad'] = 'Before AD'\n",
    "post_ad_data['relative_to_ad'] = 'After AD'\n",
    "\n",
    "# Combine the two datasets for plotting\n",
    "combined_data = pd.concat([pre_ad_data, post_ad_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply min-max scaling to the age_at_diagnosis column\n",
    "min_age = combined_data['age_at_diagnosis'].min()\n",
    "max_age = combined_data['age_at_diagnosis'].max()\n",
    "\n",
    "combined_data['scaled_age'] = (combined_data['age_at_diagnosis'] - min_age) / (max_age - min_age)\n",
    "ad_data_first['scaled_age'] = (ad_data_first['age_at_diagnosis'] - min_age) / (max_age - min_age)\n",
    "\n",
    "# Smooth AD onset age line\n",
    "x = ad_data_first['sequential_id']\n",
    "y = ad_data_first['scaled_age']\n",
    "valid_indices = ~np.isnan(y)\n",
    "x_clean = x[valid_indices]\n",
    "y_clean = y[valid_indices]\n",
    "x_smooth = np.linspace(x_clean.min(), x_clean.max(), 50)\n",
    "y_smooth = make_interp_spline(x_clean, y_clean + 0.005)(x_smooth)\n",
    "color_order = ['staphylococcus', 'ecoli', 'pseudomonas', 'gram_negative', 'gram_positive', 'streptococcus']\n",
    "\n",
    "# Separate data for \"Before AD\" and \"After AD\"\n",
    "before_ad = combined_data[(combined_data['relative_to_ad'] == 'Before AD') & (combined_data['disease_name'] != 'alzheimer')]\n",
    "after_ad = combined_data[(combined_data['relative_to_ad'] == 'After AD') & (combined_data['disease_name'] != 'alzheimer')]\n",
    "\n",
    "# Combined plot for both before and after AD infections\n",
    "def combined_line_plot(before_data, after_data, ad_data_first, title, output_path):\n",
    "    plt.figure(figsize=(18, 9))\n",
    "\n",
    "    # Plot lines for before AD infections\n",
    "    for sequential_id in before_data['sequential_id'].unique():\n",
    "        person_data = before_data[before_data['sequential_id'] == sequential_id]\n",
    "        ad_scaled_age = ad_data_first.loc[ad_data_first['sequential_id'] == sequential_id, 'scaled_age'].values[0]\n",
    "        for _, row in person_data.iterrows():\n",
    "            # Line from infection to AD onset\n",
    "            plt.plot(\n",
    "                [sequential_id, sequential_id],\n",
    "                [row['scaled_age'], ad_scaled_age],\n",
    "                color='gray',\n",
    "                linestyle='--',\n",
    "                alpha=0.5\n",
    "            )\n",
    "\n",
    "    # Plot lines for after AD infections\n",
    "    for sequential_id in after_data['sequential_id'].unique():\n",
    "        person_data = after_data[after_data['sequential_id'] == sequential_id]\n",
    "        ad_scaled_age = ad_data_first.loc[ad_data_first['sequential_id'] == sequential_id, 'scaled_age'].values[0]\n",
    "        for _, row in person_data.iterrows():\n",
    "            # Line from AD onset to infection\n",
    "            plt.plot(\n",
    "                [sequential_id, sequential_id],\n",
    "                [ad_scaled_age, row['scaled_age']],\n",
    "                color='gray',\n",
    "                linestyle='--',\n",
    "                alpha=0.5\n",
    "            )\n",
    "\n",
    "    # Scatter plot for before AD infections\n",
    "    sns.scatterplot(\n",
    "        data=before_data,\n",
    "        x='sequential_id',\n",
    "        y='scaled_age',\n",
    "        hue='disease_name',\n",
    "        palette='tab10',\n",
    "        hue_order=color_order,\n",
    "        s=40,\n",
    "        alpha=0.5\n",
    "        # label='Before AD'\n",
    "    )\n",
    "\n",
    "    # Scatter plot for after AD infections\n",
    "    sns.scatterplot(\n",
    "        data=after_data,\n",
    "        x='sequential_id',\n",
    "        y='scaled_age',\n",
    "        hue='disease_name',\n",
    "        palette='tab10',\n",
    "        hue_order=color_order,\n",
    "        s=40,\n",
    "        alpha=0.5,\n",
    "        legend=False\n",
    "        # label='After AD'\n",
    "    )\n",
    "\n",
    "    # Add the smooth line for AD onset ages\n",
    "    plt.plot(\n",
    "        x_smooth,\n",
    "        y_smooth,\n",
    "        color='blue',\n",
    "        label='Dementia Onset Age (Smooth)',\n",
    "        linewidth=2.5,\n",
    "        alpha=0.8\n",
    "    )\n",
    "\n",
    "    # Enhance the plot\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel(f'Sequential Patient ID (Sorted by {di} Onset Age)', fontsize=14)\n",
    "    plt.ylabel('Scaled Age at Diagnosis (0-1)', fontsize=14)\n",
    "    plt.xticks(rotation=45, fontsize=10)\n",
    "    plt.legend(title='Legend', fontsize=12, frameon=False, loc='upper right', bbox_to_anchor=(1.2, 0.6))\n",
    "    plt.grid(False)\n",
    "    ax = plt.gca()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_color('black')\n",
    "    ax.spines['bottom'].set_color('black')\n",
    "    ax.spines['left'].set_linewidth(2)\n",
    "    ax.spines['bottom'].set_linewidth(2)\n",
    "    plt.xlim(-5, num_ad_patients + 5)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Plot saved to {output_path}\")\n",
    "\n",
    "# Generate combined plot\n",
    "combined_line_plot(\n",
    "    before_ad,\n",
    "    after_ad,\n",
    "    ad_data_first,\n",
    "    f\"Lines Connecting Before and After {di} Infections to {di} Onset Age\",\n",
    "    \"./download/Combined_Lines_Before_After_AD.pdf\"\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.interpolate import make_interp_spline\n",
    "import numpy as np\n",
    "\n",
    "# Smooth AD onset age line using the original `age_at_diagnosis`\n",
    "x = ad_data_first['sequential_id']\n",
    "y = ad_data_first['age_at_diagnosis']\n",
    "valid_indices = ~np.isnan(y)\n",
    "x_clean = x[valid_indices]\n",
    "y_clean = y[valid_indices]\n",
    "x_smooth = np.linspace(x_clean.min(), x_clean.max(), 50)\n",
    "y_smooth = make_interp_spline(x_clean, y_clean + 0.5)(x_smooth)  # Add slight offset for visibility\n",
    "color_order = ['staphylococcus', 'ecoli', 'pseudomonas', 'gram_negative', 'gram_positive', 'streptococcus']\n",
    "\n",
    "# Combined plot for both before and after AD infections\n",
    "def combined_line_plot(before_data, after_data, ad_data_first, title, output_path):\n",
    "    plt.figure(figsize=(18, 9))\n",
    "\n",
    "    # Plot lines for before AD infections\n",
    "    for sequential_id in before_data['sequential_id'].unique():\n",
    "        person_data = before_data[before_data['sequential_id'] == sequential_id]\n",
    "        ad_age = ad_data_first.loc[ad_data_first['sequential_id'] == sequential_id, 'age_at_diagnosis'].values[0]\n",
    "        for _, row in person_data.iterrows():\n",
    "            # Line from infection to AD onset\n",
    "            plt.plot(\n",
    "                [sequential_id, sequential_id],\n",
    "                [row['age_at_diagnosis'], ad_age],\n",
    "                color='gray',\n",
    "                linestyle='--',\n",
    "                alpha=0.5\n",
    "            )\n",
    "\n",
    "    # Plot lines for after AD infections\n",
    "    for sequential_id in after_data['sequential_id'].unique():\n",
    "        person_data = after_data[after_data['sequential_id'] == sequential_id]\n",
    "        ad_age = ad_data_first.loc[ad_data_first['sequential_id'] == sequential_id, 'age_at_diagnosis'].values[0]\n",
    "        for _, row in person_data.iterrows():\n",
    "            # Line from AD onset to infection\n",
    "            plt.plot(\n",
    "                [sequential_id, sequential_id],\n",
    "                [ad_age, row['age_at_diagnosis']],\n",
    "                color='gray',\n",
    "                linestyle='--',\n",
    "                alpha=0.5\n",
    "            )\n",
    "\n",
    "    # Scatter plot for before AD infections\n",
    "    sns.scatterplot(\n",
    "        data=before_data,\n",
    "        x='sequential_id',\n",
    "        y='age_at_diagnosis',\n",
    "        hue='disease_name',\n",
    "        palette='tab10',\n",
    "        hue_order=color_order,\n",
    "        s=40,\n",
    "        alpha=0.5\n",
    "    )\n",
    "\n",
    "    # Scatter plot for after AD infections\n",
    "    sns.scatterplot(\n",
    "        data=after_data,\n",
    "        x='sequential_id',\n",
    "        y='age_at_diagnosis',\n",
    "        hue='disease_name',\n",
    "        palette='tab10',\n",
    "        hue_order=color_order,\n",
    "        s=40,\n",
    "        alpha=0.5,\n",
    "        legend=False\n",
    "    )\n",
    "\n",
    "    # Add the smooth line for AD onset ages\n",
    "    plt.plot(\n",
    "        x_smooth,\n",
    "        y_smooth,\n",
    "        color='blue',\n",
    "        label='Dementia Onset Age (Smooth)',\n",
    "        linewidth=2.5,\n",
    "        alpha=0.8\n",
    "    )\n",
    "\n",
    "    # Enhance the plot\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel('Sequential Patient ID (Sorted by Dementia Onset Age)', fontsize=14)\n",
    "    plt.ylabel('Age at Diagnosis (Years)', fontsize=14)\n",
    "    plt.xticks(rotation=45, fontsize=10)\n",
    "    plt.legend(title='Legend', fontsize=12, frameon=False, loc='upper right', bbox_to_anchor=(1.2, 0.6))\n",
    "    plt.grid(False)\n",
    "    ax = plt.gca()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_color('black')\n",
    "    ax.spines['bottom'].set_color('black')\n",
    "    ax.spines['left'].set_linewidth(2)\n",
    "    ax.spines['bottom'].set_linewidth(2)\n",
    "    plt.xlim(-5, num_ad_patients + 5)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Plot saved to {output_path}\")\n",
    "\n",
    "# Generate combined plot\n",
    "combined_line_plot(\n",
    "    before_ad,\n",
    "    after_ad,\n",
    "    ad_data_first,\n",
    "    f\"Lines Connecting Before and After {di} Infections to {di} Onset Age\",\n",
    "    f\"./download/Combined_Lines_Before_After_A_no_scaling.pdf\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define age bins for grouping\n",
    "age_bins = [20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "age_labels = [f\"{age_bins[i]}-{age_bins[i+1]-1}\" for i in range(len(age_bins)-1)]\n",
    "\n",
    "# Group data into decades for age of first bacterial disease and Alzheimer's diagnosis\n",
    "combined_age_data_cleaned['age_bin'] = pd.cut(\n",
    "    combined_age_data_cleaned['age_at_diagnosis'], bins=age_bins, labels=age_labels, right=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Adjusting the plots with the preferred styles and applying them to all diseases\n",
    "diseases = list(disease_dataframes.keys())\n",
    "output_path = \"./download\"  # Update to your preferred output directory\n",
    "\n",
    "# KDE plot function with preferred styles\n",
    "def kde_plot(data, x_col, title, xlabel, output_filename):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.kdeplot(data[x_col], fill=True, common_norm=False)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.xlabel(xlabel, fontsize=12)\n",
    "    plt.ylabel('Density', fontsize=12)\n",
    "    plt.legend(title='Legend', fontsize=12, frameon=False, loc='upper right', bbox_to_anchor=(1.2, 0.6))\n",
    "    plt.grid(False)\n",
    "    ax = plt.gca()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_color('black')\n",
    "    ax.spines['bottom'].set_color('black')\n",
    "    ax.spines['left'].set_linewidth(2)\n",
    "    ax.spines['bottom'].set_linewidth(2)\n",
    "    plt.tight_layout()\n",
    "    output_file = f\"{output_path}/{output_filename}.png\"\n",
    "    plt.savefig(output_file, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Plot saved to {output_file}\")\n",
    "\n",
    "# # Plot KDEs for each disease for Alzheimer's patients\n",
    "# for disease in diseases:\n",
    "#     if disease == \"alzheimer\":\n",
    "#         continue  # Skip Alzheimer's as it will be handled separately\n",
    "\n",
    "#     disease_data = combined_age_data_cleaned[\n",
    "#         (combined_age_data_cleaned['disease_name'] == disease) &\n",
    "#         (combined_age_data_cleaned['person_id'].isin(ad_with_infections['person_id']))\n",
    "#     ]\n",
    "\n",
    "#     title = f'KDE Plot: Age of First {disease.capitalize()} Disease (Alzheimer Patients)'\n",
    "#     xlabel = 'Age of First Disease'\n",
    "#     kde_plot(disease_data, 'age_at_diagnosis', title, xlabel, f\"alzheimer_first_{disease}\")\n",
    "\n",
    "# # Plot KDEs for age at Alzheimer's diagnosis for each disease's patients\n",
    "# for disease in diseases:\n",
    "#     disease_data = combined_age_data_cleaned[\n",
    "#         (combined_age_data_cleaned['disease_name'] == 'alzheimer') &\n",
    "#         (combined_age_data_cleaned['person_id'].isin(\n",
    "#             combined_age_data_cleaned[combined_age_data_cleaned['disease_name'] == disease]['person_id']\n",
    "#         ))\n",
    "#     ]\n",
    "\n",
    "#     title = f'KDE Plot: Age at Alzheimer Diagnosis ({disease.capitalize()} Patients)'\n",
    "#     xlabel = 'Age at Alzheimer Diagnosis'\n",
    "#     kde_plot(disease_data, 'age_at_diagnosis', title, xlabel, f\"{disease}_first_alzheimer\")\n",
    "\n",
    "# Combined KDE plot for all diseases (Alzheimer patients and first bacterial disease)\n",
    "plt.figure(figsize=(12, 8))\n",
    "for disease in diseases:\n",
    "    if disease == \"alzheimer\":\n",
    "        continue  # Skip Alzheimer's as it's not a bacterial disease\n",
    "    disease_data = combined_age_data_cleaned[\n",
    "        (combined_age_data_cleaned['disease_name'] == disease) &\n",
    "        (combined_age_data_cleaned['person_id'].isin(ad_with_infections['person_id']))\n",
    "    ]\n",
    "    sns.kdeplot(disease_data['age_at_diagnosis'], fill=True, label=f\"{disease.capitalize()}\")\n",
    "\n",
    "plt.title('Combined KDE Plot: Age of First Bacterial Disease for Alzheimer Patients', fontsize=14)\n",
    "plt.xlabel('Age of First Disease', fontsize=12)\n",
    "plt.ylabel('Density', fontsize=12)\n",
    "plt.legend(title='Legend', fontsize=12, frameon=False, loc='upper right', bbox_to_anchor=(1.2, 0.6))\n",
    "plt.grid(False)\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_color('black')\n",
    "ax.spines['bottom'].set_color('black')\n",
    "ax.spines['left'].set_linewidth(2)\n",
    "ax.spines['bottom'].set_linewidth(2)\n",
    "plt.tight_layout()\n",
    "combined_plot_path = f\"{output_path}/combined_bacterial_first_disease.png\"\n",
    "plt.savefig(combined_plot_path, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"Combined bacterial disease plot saved to {combined_plot_path}\")\n",
    "\n",
    "# Combined KDE plot for all diseases and age at Alzheimer's diagnosis\n",
    "plt.figure(figsize=(12, 8))\n",
    "for disease in diseases:\n",
    "    if disease == \"alzheimer\":\n",
    "        continue\n",
    "    disease_data = combined_age_data_cleaned[\n",
    "        (combined_age_data_cleaned['disease_name'] == 'alzheimer') &\n",
    "        (combined_age_data_cleaned['person_id'].isin(\n",
    "            combined_age_data_cleaned[combined_age_data_cleaned['disease_name'] == disease]['person_id']\n",
    "        ))\n",
    "    ]\n",
    "    sns.kdeplot(disease_data['age_at_diagnosis'], fill=True, label=f\"{disease.capitalize()}\")\n",
    "\n",
    "plt.title('Combined KDE Plot: Age at Alzheimer Diagnosis for Bacterial Disease Patients', fontsize=14)\n",
    "plt.xlabel('Age at Alzheimer Diagnosis', fontsize=12)\n",
    "plt.ylabel('Density', fontsize=12)\n",
    "plt.legend(title='Legend', fontsize=12, frameon=False, loc='upper right', bbox_to_anchor=(1.2, 0.6))\n",
    "plt.grid(False)\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_color('black')\n",
    "ax.spines['bottom'].set_color('black')\n",
    "ax.spines['left'].set_linewidth(2)\n",
    "ax.spines['bottom'].set_linewidth(2)\n",
    "plt.tight_layout()\n",
    "# combined_plot_path_ad = f\"{output_path}/combined_alzheimer_diagnosis.png\"\n",
    "# plt.savefig(combined_plot_path_ad, bbox_inches='tight')\n",
    "plt.show()\n",
    "# print(f\"Combined Alzheimer's diagnosis plot saved to {combined_plot_path_ad}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Ensure minimum age for the first disease is calculated for each person\n",
    "min_age_data = combined_age_data_cleaned.groupby(['person_id', 'disease_name'])['age_at_diagnosis'].min().reset_index()\n",
    "min_age_data.rename(columns={'age_at_diagnosis': 'min_age_at_diagnosis'}, inplace=True)\n",
    "\n",
    "# Process the age of first disease and first dementia\n",
    "first_disease_dementia_data = min_age_data.pivot(index='person_id', columns='disease_name', values='min_age_at_diagnosis')\n",
    "\n",
    "# Iterate over diseases to plot the graphs\n",
    "for disease in diseases:\n",
    "    if disease == 'alzheimer': \n",
    "        continue  # Skip Alzheimer for the first disease plot\n",
    "    \n",
    "    if disease not in first_disease_dementia_data.columns or 'alzheimer' not in first_disease_dementia_data.columns:\n",
    "        print(f\"Skipping {disease} as it doesn't have sufficient data.\")\n",
    "        continue\n",
    "\n",
    "    # Extract data for the disease and Alzheimer\n",
    "    disease_data = first_disease_dementia_data[[disease, 'alzheimer']].dropna()\n",
    "    disease_data.columns = ['age_first_disease', 'age_first_dementia']\n",
    "\n",
    "    # Plotting the KDEs\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.kdeplot(disease_data['age_first_disease'], fill=True, color='blue', label='Age of First Disease')\n",
    "    sns.kdeplot(disease_data['age_first_dementia'], fill=True, color='red', label='Age of First Dementia')\n",
    "    plt.title(f'KDE Plot: Age of First {disease.capitalize()} Disease and Dementia', fontsize=14)\n",
    "    plt.xlabel('Age', fontsize=12)\n",
    "    plt.ylabel('Density', fontsize=12)\n",
    "    plt.legend(title='Legend', fontsize=12, frameon=False, loc='upper right', bbox_to_anchor=(1.2, 0.6))\n",
    "    plt.grid(False)\n",
    "    ax = plt.gca()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_color('black')\n",
    "    ax.spines['bottom'].set_color('black')\n",
    "    ax.spines['left'].set_linewidth(2)\n",
    "    ax.spines['bottom'].set_linewidth(2)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count as categories if they have the infection in general. For example if a patient have in his life ecoli then count 1, if he had 4 times ecoli and one Pseudomonas then we count it as 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Add a column for total infection count\n",
    "# Specify infection-related diseases\n",
    "infection_columns = [\"gram_negative_count\", \"staphylococcus_count\", \"pseudomonas_count\", \n",
    "                     \"streptococcus_count\", \"ecoli_count\", \"gram_positive_count\"]\n",
    "\n",
    "# Calculate the total infections for each person\n",
    "combined_phecode_counts[\"total_infections\"] = combined_phecode_counts[infection_columns].sum(axis=1)\n",
    "\n",
    "# Correct the apply call to use the total_infections column directly\n",
    "def classify_infection_level(total_infections):\n",
    "    if total_infections == 0:\n",
    "        return \"No infection\"\n",
    "    elif total_infections == 1:\n",
    "        return \"1 infection\"\n",
    "    else:\n",
    "        return \"2+ infections\"\n",
    "\n",
    "# Apply the classification function to the total_infections column\n",
    "combined_phecode_counts[\"infection_level\"] = combined_phecode_counts[\"total_infections\"].apply(classify_infection_level)\n",
    "\n",
    "\n",
    "# Step 3: Filter for individuals with Alzheimer's Disease\n",
    "ad_with_infections = combined_phecode_counts[combined_phecode_counts[\"alzheimer_count\"] > 0]\n",
    "\n",
    "# Step 4: Count individuals by infection level\n",
    "infection_summary = ad_with_infections[\"infection_level\"].value_counts()\n",
    "infection_summary.columns = [\"Infection Level\", \"Count\"]\n",
    "\n",
    "# Step 5: Display the results\n",
    "print(infection_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify infection levels\n",
    "ad_combined_counts[\"infection_level\"] = ad_combined_counts[\"total_infections\"].apply(classify_infection_level)\n",
    "\n",
    "# Count infection levels\n",
    "infection_summary_ad = ad_combined_counts[\"infection_level\"].value_counts()\n",
    "print(\"Infection level summary for Alzheimer's patients:\")\n",
    "print(infection_summary_ad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Count total occurrences for each infection\n",
    "infection_counts = combined_age_data_filtered['disease_name'].value_counts()\n",
    "\n",
    "# Step 2: Filter individuals with and without Alzheimer's diagnosis\n",
    "# Identify individuals with Alzheimer's\n",
    "alzheimers_patients = combined_age_data_filtered.loc[\n",
    "    combined_age_data_filtered['disease_name'].str.contains('alzheimer', case=False), 'person_id'\n",
    "].unique()\n",
    "def classify_infections(df):\n",
    "    infection_counts_per_person = df.groupby('person_id')['disease_name'].nunique()\n",
    "    ad_infection = infection_counts_per_person[infection_counts_per_person == 1].count()\n",
    "    one_infections = infection_counts_per_person[infection_counts_per_person == 2].count()\n",
    "    two_or_more_infections = infection_counts_per_person[infection_counts_per_person >= 3].count()\n",
    "    return ad_infection, one_infections,two_or_more_infections\n",
    "\n",
    "# Split data into with and without Alzheimer's\n",
    "with_alzheimers = combined_age_data_filtered[combined_age_data_filtered['person_id'].isin(alzheimers_patients)]\n",
    "without_alzheimers = combined_age_data_filtered[~combined_age_data_filtered['person_id'].isin(alzheimers_patients)]\n",
    "\n",
    "\n",
    "# Classify infections for individuals with Alzheimer's\n",
    "with_alz_ad_infection, with_alz_one_infections,with_alz_two_or_more_infections = classify_infections(with_alzheimers)\n",
    "\n",
    "# Results\n",
    "print(\"Total infections:\")\n",
    "print(infection_counts)\n",
    "\n",
    "print(f\"\\nWith {di}:\")\n",
    "print(f\"  Individuals with {di}: {with_alz_ad_infection}\")\n",
    "print(f\"  Individuals with one infections in category and {di}: {with_alz_one_infections}\")\n",
    "print(f\"  Individuals with two or more infections and {di}: {with_alz_two_or_more_infections}\")\n",
    "\n",
    "# Step 3: Count infections for each person and classify by infection count\n",
    "def classify_infections(df):\n",
    "    infection_counts_per_person = df.groupby('person_id')['disease_name'].nunique()\n",
    "    one_infection = infection_counts_per_person[infection_counts_per_person == 1].count()\n",
    "    two_or_more_infections = infection_counts_per_person[infection_counts_per_person >= 2].count()\n",
    "    \n",
    "    return one_infection, two_or_more_infections\n",
    "# Classify infections for individuals without Alzheimer's\n",
    "without_alz_one_infection, without_alz_two_or_more = classify_infections(without_alzheimers)\n",
    "\n",
    "print(f\"\\nWithout {di}:\")\n",
    "print(f\"  Individuals with one infection: {without_alz_one_infection}\")\n",
    "print(f\"  Individuals with two or more infections: {without_alz_two_or_more}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the infection levels into the dataset\n",
    "infection_levels = combined_phecode_counts[[\"person_id\", \"infection_level\"]]\n",
    "ad_first_diagnosis = ad_first_diagnosis.merge(infection_levels, on=\"person_id\", how=\"left\")\n",
    "\n",
    "# Categorize infection groups for consistency\n",
    "ad_first_diagnosis[\"infection_group\"] = ad_first_diagnosis[\"infection_level\"]\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Count bacterial infections for each person\n",
    "bacteria_list = ['staphylococcus', 'ecoli', 'pseudomonas', 'gram_negative', 'gram_positive', 'streptococcus']\n",
    "bacteria_counts = (\n",
    "    combined_age_data_cleaned[\n",
    "        combined_age_data_cleaned['disease_name'].isin(bacteria_list)\n",
    "    ]\n",
    "    .groupby('person_id')['disease_name']\n",
    "    .nunique()\n",
    "    .reset_index()\n",
    "    .rename(columns={'disease_name': 'bacteria_infections'})\n",
    ")\n",
    "\n",
    "# Step 2: Identify the first AD diagnosis for each person\n",
    "ad_data = combined_age_data_cleaned[combined_age_data_cleaned['disease_name'] == 'alzheimer']\n",
    "ad_first_diagnosis = (\n",
    "    ad_data.groupby('person_id')['age_at_diagnosis']\n",
    "    .min()\n",
    "    .reset_index()\n",
    "    .rename(columns={'age_at_diagnosis': 'first_ad_age'})\n",
    ")\n",
    "\n",
    "# Step 3: Merge bacterial infection counts with first AD diagnosis age\n",
    "ad_first_diagnosis = ad_first_diagnosis.merge(bacteria_counts, on='person_id', how='left').fillna(0)\n",
    "\n",
    "# Step 4: Filter by minimum age at first AD diagnosis\n",
    "min_first_ad_age = 0\n",
    "ad_first_diagnosis = ad_first_diagnosis[ad_first_diagnosis['first_ad_age'] > min_first_ad_age]\n",
    "\n",
    "# Step 5: Categorize into infection groups\n",
    "ad_first_diagnosis['infection_group'] = ad_first_diagnosis['bacteria_infections'].apply(\n",
    "    lambda x: '0' if x == 0 else ('1' if x == 1 else ('2' if x == 2 else \"3+\"))\n",
    ")\n",
    "\n",
    "# Step 6: Perform Kaplan-Meier Analysis\n",
    "kmf = KaplanMeierFitter()\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = {'0': 'blue', '1': 'purple', '2': 'green', '3+': 'red'}\n",
    "\n",
    "# Add general dementia line\n",
    "kmf.fit(\n",
    "    durations=ad_first_diagnosis['first_ad_age'],\n",
    "    event_observed=[1] * len(ad_first_diagnosis),\n",
    "    label=\"Dementia (All Patients)\"\n",
    ")\n",
    "kmf.plot_survival_function(color='black', linestyle='--', linewidth=2, ci_show=False)\n",
    "\n",
    "# Prepare Kaplan-Meier plot and survival data\n",
    "group_survival_data = {}\n",
    "group_labels = {\n",
    "    \"0\": \"0 Infections\",\n",
    "    \"1\": \"1 Infection\",\n",
    "    \"2\": \"2 Infections\",\n",
    "    \"3+\": \"3+ Infections\"\n",
    "}\n",
    "for group in ['0', '1', '2', '3+']:\n",
    "    group_data = ad_first_diagnosis[ad_first_diagnosis['infection_group'] == group]\n",
    "    group_survival_data[group] = group_data['first_ad_age']\n",
    "    kmf.fit(\n",
    "        durations=group_data['first_ad_age'], \n",
    "        event_observed=[1] * len(group_data),  # Assume all events observed\n",
    "        label=f\"{group_labels[group]}, n={len(group_data)}\"\n",
    "    )\n",
    "    kmf.plot_survival_function(color=colors[group], ci_show=False)\n",
    "\n",
    "# Log-Rank Test\n",
    "log_rank_results = []\n",
    "groups = ['0', '1', '2', '3+']\n",
    "for i in range(len(groups)):\n",
    "    for j in range(i + 1, len(groups)):\n",
    "        group_1, group_2 = groups[i], groups[j]\n",
    "        if group_1 in group_survival_data and group_2 in group_survival_data:\n",
    "            result = logrank_test(\n",
    "                group_survival_data[group_1],\n",
    "                group_survival_data[group_2]\n",
    "            )\n",
    "            log_rank_results.append((group_1, group_2, result.p_value))\n",
    "\n",
    "log_rank_comparisons = pd.DataFrame(\n",
    "    log_rank_results,\n",
    "    columns=[\"Group_1\", \"Group_2\", \"P_Value\"]\n",
    ")\n",
    "\n",
    "# Enhance the plot\n",
    "plt.title('Kaplan-Meier Plot for First AD Diagnosis Age by Infection Group', fontsize=16)\n",
    "plt.xlabel('Age at First AD Diagnosis', fontsize=14)\n",
    "plt.ylabel('Survival Probability', fontsize=14)\n",
    "plt.legend(title='Infection Group', fontsize=12, frameon=False)\n",
    "plt.grid(False)\n",
    "\n",
    "# Customize plot aesthetics\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_color('black')\n",
    "ax.spines['bottom'].set_color('black')\n",
    "ax.spines['left'].set_linewidth(2)\n",
    "ax.spines['bottom'].set_linewidth(2)\n",
    "\n",
    "# Save the plot\n",
    "output_path = \"./download/first_ad_diagnosis_by_infection_group_with_logrank.pdf\"\n",
    "plt.savefig(output_path, bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"Kaplan-Meier plot saved at:\", output_path)\n",
    "\n",
    "# Display log-rank test results\n",
    "print(\"\\nLog-Rank Test Results:\")\n",
    "print(log_rank_comparisons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines.statistics import logrank_test\n",
    "from lifelines import KaplanMeierFitter\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Count bacterial infections for each person\n",
    "bacteria_counts = (\n",
    "    combined_age_data_cleaned[\n",
    "        combined_age_data_cleaned['disease_name'].isin(['staphylococcus', 'ecoli', 'pseudomonas', \n",
    "                                                        'gram_negative', 'gram_positive', 'streptococcus'])\n",
    "    ]\n",
    "    .groupby('person_id')['disease_name']\n",
    "    .nunique()\n",
    "    .reset_index()\n",
    "    .rename(columns={'disease_name': 'bacteria_infections'})\n",
    ")\n",
    "\n",
    "# Step 2: Identify the first AD diagnosis for each person\n",
    "ad_data = combined_age_data_cleaned[combined_age_data_cleaned['disease_name'] == 'alzheimer']\n",
    "ad_first_diagnosis = (\n",
    "    ad_data.groupby('person_id')['age_at_diagnosis']\n",
    "    .min()\n",
    "    .reset_index()\n",
    "    .rename(columns={'age_at_diagnosis': 'first_ad_age'})\n",
    ")\n",
    "\n",
    "# Step 3: Merge bacterial infection counts with first AD diagnosis age\n",
    "ad_first_diagnosis = ad_first_diagnosis.merge(bacteria_counts, on='person_id', how='left').fillna(0)\n",
    "\n",
    "# Step 4: Categorize into infection groups\n",
    "ad_first_diagnosis['infection_group'] = ad_first_diagnosis['bacteria_infections'].apply(\n",
    "    lambda x: '0' if x == 0 else ('1' if x == 1 else ('2' if x == 2 else '3+'))\n",
    ")\n",
    "\n",
    "# Prepare Kaplan-Meier Analysis\n",
    "kmf = KaplanMeierFitter()\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = {'0': 'blue', '1': 'purple', '2': 'green', '3+': 'red'}\n",
    "\n",
    "# Prepare log-rank test statistics\n",
    "groups = ['0', '1', '2', '3+']\n",
    "group_survival_data = {group: ad_first_diagnosis[ad_first_diagnosis['infection_group'] == group]['first_ad_age'] for group in groups}\n",
    "log_rank_results = []\n",
    "\n",
    "for i in range(len(groups)):\n",
    "    for j in range(i + 1, len(groups)):\n",
    "        group_1, group_2 = groups[i], groups[j]\n",
    "        result = logrank_test(\n",
    "            group_survival_data[group_1],\n",
    "            group_survival_data[group_2]\n",
    "        )\n",
    "        log_rank_results.append((group_1, group_2, result.p_value))\n",
    "\n",
    "# Save log-rank comparisons as a TSV\n",
    "log_rank_comparisons = pd.DataFrame(\n",
    "    log_rank_results,\n",
    "    columns=[\"Group_1\", \"Group_2\", \"P_Value\"]\n",
    ")\n",
    "output_tsv_path = \"./download/log_rank_comparisons.tsv\"\n",
    "log_rank_comparisons.to_csv(output_tsv_path, sep='\\t', index=False)\n",
    "print(f\"Log-rank comparison TSV file saved to: {output_tsv_path}\")\n",
    "\n",
    "# Create custom legend labels with p-values\n",
    "group_labels = {}\n",
    "for group in groups:\n",
    "    if group == '0':\n",
    "        group_labels[group] = f\"{group} Infections (n={len(ad_first_diagnosis[ad_first_diagnosis['infection_group'] == group])})\"\n",
    "    else:\n",
    "        p_val = min([res[2] for res in log_rank_results if res[0] == '0' and res[1] == group])\n",
    "        group_labels[group] = f\"{group} Infections (n={len(ad_first_diagnosis[ad_first_diagnosis['infection_group'] == group])}, p={p_val:.3e})\"\n",
    "\n",
    "# Plot Kaplan-Meier curves with updated legend\n",
    "for group in groups:\n",
    "    group_data = ad_first_diagnosis[ad_first_diagnosis['infection_group'] == group]\n",
    "    kmf.fit(\n",
    "        durations=group_data['first_ad_age'],\n",
    "        event_observed=[1] * len(group_data),\n",
    "        label=group_labels[group]\n",
    "    )\n",
    "    kmf.plot_survival_function(color=colors[group], ci_show=False)\n",
    "\n",
    "# Enhance the plot\n",
    "plt.title(f'Kaplan-Meier plot for first {di} diagnosis age by the number of bacterial infections', fontsize=16)\n",
    "plt.xlabel(f'Age at first {di} diagnosis', fontsize=14)\n",
    "plt.ylabel(f'Survival probability', fontsize=14)\n",
    "plt.legend(title='Number of bacteria infections', fontsize=12, frameon=False)\n",
    "plt.grid(False)\n",
    "\n",
    "# Customize plot aesthetics\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_color('black')\n",
    "ax.spines['bottom'].set_color('black')\n",
    "ax.spines['left'].set_linewidth(2)\n",
    "ax.spines['bottom'].set_linewidth(2)\n",
    "\n",
    "# Save the plot\n",
    "survival_plot_path = f\"./download/first_ad_diagnosis_by_infection_group_with_logrank_{di}.pdf\"\n",
    "plt.savefig(survival_plot_path, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Survival plot saved to {survival_plot_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Code from the old file for age difference"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dementia_and_no_disease = {}\n",
    "no_alzheimer_and_no_disease = {}\n",
    "alzheimer_and_disease = {}\n",
    "no_alzheimer_and_disease = {}\n",
    "\n",
    "# Iterate over each disease to populate the dictionaries\n",
    "for disease in disease_person_ids.keys():\n",
    "    if disease != 'alzheimer':\n",
    "        # Patients with Dementia and no other disease\n",
    "        dementia_and_no_disease[disease] = older_people[(older_people['alzheimer'] == 1) & (older_people[disease] == 0)].shape[0]\n",
    "\n",
    "        # Patients with no Alzheimer's and no other disease\n",
    "        no_alzheimer_and_no_disease[disease] = older_people[(older_people['alzheimer'] == 0) & (older_people[disease] == 0)].shape[0]\n",
    "\n",
    "        # Patients with Alzheimer's and the disease\n",
    "        alzheimer_and_disease[disease] = older_people[(older_people['alzheimer'] == 1) & (older_people[disease] == 1)].shape[0]\n",
    "\n",
    "        # Patients with no Alzheimer's and the disease\n",
    "        no_alzheimer_and_disease[disease] = older_people[(older_people['alzheimer'] == 0) & (older_people[disease] == 1)].shape[0]\n",
    "\n",
    "# Print the comparison counts\n",
    "print(\"\\nNumber of patients with Dementia and no other disease:\")\n",
    "for disease, count in dementia_and_no_disease.items():\n",
    "    print(f\"Dementia and {disease}: {count}\")\n",
    "\n",
    "print(\"\\nNumber of patients with no Dementia and no other disease:\")\n",
    "for disease, count in no_alzheimer_and_no_disease.items():\n",
    "    print(f\"No Alzheimer's and {disease}: {count}\")\n",
    "\n",
    "print(\"\\nNumber of patients with Dementia and each other disease:\")\n",
    "for disease, count in alzheimer_and_disease.items():\n",
    "    print(f\"Alzheimer's and {disease}: {count}\")\n",
    "\n",
    "print(\"\\nNumber of patients with no Dementia and each other disease:\")\n",
    "for disease, count in no_alzheimer_and_disease.items():\n",
    "    print(f\"No Alzheimer's and {disease}: {count}\")\n",
    "\n",
    "# Total number of patients with Alzheimer's\n",
    "total_alzheimer = older_people['alzheimer'].sum()\n",
    "print(f\"\\nTotal number of patients with Alzheimer's: {total_alzheimer}\")\n",
    "\n",
    "# Total number of patients overall\n",
    "sum_total = len(older_people['person_id'])\n",
    "print(f\"Total number of patients: {sum_total}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Ensure condition_start_datetime is in date format\n",
    "for df in [ecoli_aggregated_df, gram_negative_aggregated_df, retrovirus_aggregated_df, epilepsy_aggregated_df,\n",
    "           streptococcus_aggregated_df, pseudomonas_aggregated_df, alzheimer_aggregated_df, postconcussion_aggregated_df,\n",
    "           staphylococcus_aggregated_df, guillain_barre_aggregated_df, gram_positive_aggregated_df]:\n",
    "    df['condition_start_datetime'] = pd.to_datetime(df['condition_start_datetime']).dt.date\n",
    "\n",
    "# Function to calculate age_onset while handling NaN values\n",
    "def calculate_age_onset(aggregated_df, older_people):\n",
    "    # Merge with df_common to get the date_of_birth\n",
    "    merged_df = aggregated_df.merge(older_people[['person_id', 'date_of_birth']], on='person_id', how='left')\n",
    "\n",
    "    # Ensure date_of_birth is in date format and extract date only\n",
    "    merged_df['date_of_birth'] = pd.to_datetime(merged_df['date_of_birth']).dt.date\n",
    "\n",
    "    # Calculate age_onset and handle NaN values\n",
    "    merged_df['age_onset'] = merged_df.apply(\n",
    "        lambda row: (row['condition_start_datetime'] - row['date_of_birth']).days / 365.25 if pd.notnull(row['condition_start_datetime']) and pd.notnull(row['date_of_birth']) else np.nan,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Round the age_onset to 2 decimal places\n",
    "    merged_df['age_onset'] = merged_df['age_onset'].round(1)\n",
    "\n",
    "    return merged_df[['person_id', 'condition_start_datetime', 'source_concept_name', 'source_concept_code', 'source_vocabulary', 'age_onset']]\n",
    "\n",
    "# Dictionary to hold the aggregated DataFrames with age_onset calculated\n",
    "aggregated_dfs = {\n",
    "    'ecoli': calculate_age_onset(ecoli_aggregated_df, older_people),\n",
    "    'gram_negative': calculate_age_onset(gram_negative_aggregated_df, older_people),\n",
    "    'retrovirus': calculate_age_onset(retrovirus_aggregated_df, older_people),\n",
    "    'epilepsy': calculate_age_onset(epilepsy_aggregated_df, older_people),\n",
    "    'streptococcus': calculate_age_onset(streptococcus_aggregated_df, older_people),\n",
    "    'pseudomonas': calculate_age_onset(pseudomonas_aggregated_df, older_people),\n",
    "    'alzheimer': calculate_age_onset(alzheimer_aggregated_df, older_people),\n",
    "    'postconcussion': calculate_age_onset(postconcussion_aggregated_df, older_people),\n",
    "    'staphylococcus': calculate_age_onset(staphylococcus_aggregated_df, older_people),\n",
    "    'gram_positive': calculate_age_onset(gram_positive_aggregated_df, older_people)\n",
    "}\n",
    "\n",
    "# Display a sample of the aggregated DataFrame for Alzheimer's\n",
    "aggregated_dfs['alzheimer']\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Function to calculate age_onset and return rows with NaN values for debugging\n",
    "def calculate_age_onset_with_debugging(aggregated_df, older_people):\n",
    "    # Merge with df_common to get the date_of_birth\n",
    "    merged_df = aggregated_df.merge(older_people[['person_id', 'date_of_birth']], on='person_id', how='left')\n",
    "\n",
    "    # Ensure date_of_birth is in date format and extract date only\n",
    "    merged_df['date_of_birth'] = pd.to_datetime(merged_df['date_of_birth']).dt.date\n",
    "\n",
    "    # Calculate age_onset and handle NaN values\n",
    "    merged_df['age_onset'] = merged_df.apply(\n",
    "        lambda row: (row['condition_start_datetime'] - row['date_of_birth']).days / 365.25 if pd.notnull(row['condition_start_datetime']) and pd.notnull(row['date_of_birth']) else np.nan,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Identify rows where age_onset is NaN\n",
    "    nan_rows = merged_df[merged_df['age_onset'].isna()]\n",
    "\n",
    "    # Print the problematic rows for debugging\n",
    "    print(\"Rows with NaN in age_onset:\")\n",
    "    print(nan_rows[['person_id', 'condition_start_datetime', 'date_of_birth', 'source_concept_name', 'source_concept_code', 'source_vocabulary']])\n",
    "\n",
    "    # Return the dataframe including age_onset\n",
    "    return merged_df[['person_id', 'condition_start_datetime', 'source_concept_name', 'source_concept_code', 'source_vocabulary', 'age_onset']]\n",
    "\n",
    "# Example: Check for NaN issues in Alzheimer's data\n",
    "alzheimer_debug_df = calculate_age_onset_with_debugging(alzheimer_aggregated_df, older_people)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Function to remove rows where age_onset is NaN\n",
    "def remove_nan_age_onset(aggregated_df):\n",
    "    return aggregated_df.dropna(subset=['age_onset'])\n",
    "\n",
    "# Apply the removal function to each dataframe in the dictionary\n",
    "aggregated_dfs_cleaned = {disease: remove_nan_age_onset(df) for disease, df in aggregated_dfs.items()}\n",
    "\n",
    "# Display a sample of the cleaned aggregated DataFrame for Alzheimer's\n",
    "aggregated_dfs_cleaned['alzheimer']\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to calculate age differences between two diseases\n",
    "def calculate_age_difference(disease1, disease2, aggregated_dfs_cleaned):\n",
    "    df1 = aggregated_dfs_cleaned[disease1]\n",
    "    df2 = aggregated_dfs_cleaned[disease2]\n",
    "\n",
    "    # Merge on person_id to find patients with both diseases\n",
    "    merged_df = df1.merge(df2, on='person_id', suffixes=(f'_{disease1}', f'_{disease2}'))\n",
    "\n",
    "    # Calculate the age difference\n",
    "    merged_df['age_difference'] = merged_df[f'age_onset_{disease1}'] - merged_df[f'age_onset_{disease2}']\n",
    "\n",
    "    return merged_df['age_difference']\n",
    "\n",
    "# Example: Compare Alzheimer's with Retrovirus\n",
    "age_diff_alzheimers_pseudomonas = calculate_age_difference('alzheimer', 'pseudomonas', aggregated_dfs_cleaned)\n",
    "\n",
    "# Display the first few differences for inspection\n",
    "print(age_diff_alzheimers_pseudomonas.head())\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to calculate age differences between two diseases\n",
    "def calculate_age_difference(disease1, disease2, aggregated_dfs_cleaned):\n",
    "    df1 = aggregated_dfs_cleaned[disease1]\n",
    "    df2 = aggregated_dfs_cleaned[disease2]\n",
    "\n",
    "    # Merge on person_id to find patients with both diseases\n",
    "    merged_df = df1.merge(df2, on='person_id', suffixes=(f'_{disease1}', f'_{disease2}'))\n",
    "\n",
    "    # Calculate the age difference\n",
    "    merged_df['age_difference'] = merged_df[f'age_onset_{disease1}'] - merged_df[f'age_onset_{disease2}']\n",
    "\n",
    "    return merged_df['age_difference'], merged_df[f'age_onset_{disease1}']\n",
    "\n",
    "# Function to plot histogram of age differences with colors based on Alzheimer's age onset groups\n",
    "def plot_age_difference_histogram(age_differences, age_onset_alzheimer, disease1, disease2):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Define 20 age groups and corresponding colors\n",
    "    bins = np.linspace(0, 100, 21)  # 20 bins (0-5, 6-10, ..., 96-100)\n",
    "    colors = plt.get_cmap('tab20')(np.linspace(0, 1, len(bins)-1))\n",
    "\n",
    "    # Assign each patient to an age group based on Alzheimer's onset age\n",
    "    age_groups = pd.cut(age_onset_alzheimer, bins=bins, labels=False, include_lowest=True)\n",
    "\n",
    "    # Define the histogram bins to use\n",
    "    hist_bins = np.linspace(min(age_differences), max(age_differences), 20)  # 40 bins for age differences\n",
    "\n",
    "    # Create an array to store the cumulative values for stacking\n",
    "    cumulative_values = np.zeros(len(hist_bins) - 1)\n",
    "\n",
    "    # Initialize lists to store legend handles and labels\n",
    "    legend_handles = []\n",
    "    legend_labels = []\n",
    "\n",
    "    # Calculate total count\n",
    "    total_count = len(age_differences)\n",
    "    count_display = \"<20\" if total_count < 20 else str(total_count)\n",
    "\n",
    "    # Plot the histogram in layers, stacking each group\n",
    "    for i in reversed(range(len(bins) - 1)):\n",
    "        hist_values, _ = np.histogram(\n",
    "            age_differences[age_groups == i],\n",
    "            bins=hist_bins\n",
    "        )\n",
    "        if np.any(hist_values):  # Only plot and add to legend if the group has data\n",
    "            # Convert counts to percentages\n",
    "            hist_values_percentage = (hist_values / total_count) * 100\n",
    "            bar = plt.bar(\n",
    "                hist_bins[:-1],\n",
    "                hist_values_percentage,\n",
    "                width=np.diff(hist_bins),\n",
    "                color=colors[i],\n",
    "                edgecolor='black',\n",
    "                bottom=cumulative_values\n",
    "            )\n",
    "            # Update the cumulative values to stack the next group on top\n",
    "            cumulative_values += hist_values_percentage\n",
    "            # Add to legend\n",
    "            legend_handles.append(bar[0])\n",
    "            legend_labels.append(f'{bins[i]:.0f}-{bins[i+1]:.0f} years')\n",
    "\n",
    "    # Add a vertical line at x=0\n",
    "    plt.axvline(0, color='grey', linestyle='--', linewidth=2)\n",
    "\n",
    "    # Add labels and title with sample count\n",
    "    plt.xlabel('Age difference (years)')\n",
    "    plt.ylabel('Percentage of patients (%)')\n",
    "    plt.title(f'Age difference between onsets of {ad} and {disease2.capitalize()} ({count_display} patients)')\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.gca().spines['left'].set_linewidth(2)\n",
    "    plt.gca().spines['bottom'].set_linewidth(2)\n",
    "    plt.gca().spines['left'].set_color('black')\n",
    "    plt.gca().spines['bottom'].set_color('black')\n",
    "    plt.grid(False)\n",
    "    plt.tick_params(axis='x', colors='grey')\n",
    "    plt.tick_params(axis='y', colors='grey')\n",
    "\n",
    "    # Add legend with bbox to the right, flipping the order of labels in the legend\n",
    "    plt.legend(legend_handles[::-1], legend_labels[::-1], title=f\"{ad} onset age groups\", frameon=False, bbox_to_anchor=(1, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot as a PDF in the ./download/ folder\n",
    "    os.makedirs('./download/', exist_ok=True)\n",
    "    file_name = f'./download/age_difference_{ad}_vs_{disease2}_percentage.pdf'\n",
    "    plt.savefig(file_name, format='pdf', dpi=300)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# List of diseases to compare with Alzheimer's\n",
    "diseases = ['retrovirus','gram_negative', 'staphylococcus', 'postconcussion', 'pseudomonas', 'streptococcus', 'epilepsy', 'ecoli', 'gram_positive']\n",
    "\n",
    "# Loop over the diseases and generate histograms\n",
    "for disease in diseases:\n",
    "    age_diff, age_onset_alzheimer = calculate_age_difference('alzheimer', disease, aggregated_dfs_cleaned)\n",
    "    plot_age_difference_histogram(age_diff, age_onset_alzheimer, 'Alzheimer', disease)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_age_difference_bell_curve_fixed(age_differences, age_onset_alzheimer, disease1, disease2):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Define Alzheimer's onset age bins starting from 20 to 90, with 90+ as the last group\n",
    "    age_onset_bins = [20, 30, 40, 50, 60, 70, 80, 90, float('inf')]\n",
    "    colors = plt.get_cmap('tab20')(np.linspace(0, 1, len(age_onset_bins) - 1))\n",
    "\n",
    "    # Assign Alzheimer's onset age groups\n",
    "    age_groups = pd.cut(age_onset_alzheimer, bins=age_onset_bins, labels=False, include_lowest=True)\n",
    "\n",
    "    # Define a consistent range for all KDEs\n",
    "    global_min = age_differences.min() - 5  # Extend range slightly for aesthetics\n",
    "    global_max = age_differences.max() + 5\n",
    "    x_range = np.linspace(global_min, global_max, 500)\n",
    "\n",
    "    # Plot a KDE curve for each age group\n",
    "    legend_handles = []\n",
    "    legend_labels = []\n",
    "\n",
    "    for i in range(len(age_onset_bins) - 1):\n",
    "        # Select age differences for the current Alzheimer's onset age group\n",
    "        group_data = age_differences[age_groups == i]\n",
    "        if len(group_data) > 1:  # KDE requires at least two points\n",
    "            kde = gaussian_kde(group_data)\n",
    "            y_values = kde(x_range)\n",
    "            plt.plot(x_range, y_values, color=colors[i], linewidth=2)\n",
    "\n",
    "            # Add to legend\n",
    "            if age_onset_bins[i+1] == float('inf'):\n",
    "                legend_labels.append('90+ years')\n",
    "            else:\n",
    "                legend_labels.append(f'{age_onset_bins[i]:.0f}-{age_onset_bins[i+1]:.0f} years')\n",
    "            legend_handles.append(plt.Line2D([0], [0], color=colors[i], linewidth=2))\n",
    "\n",
    "    # Add vertical line at x=0\n",
    "    plt.axvline(0, color='grey', linestyle='--', linewidth=2)\n",
    "\n",
    "    # Add labels, title, and formatting\n",
    "    plt.xlabel('Age difference (years)')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title(f'Age difference KDE between onsets of {disease1} and {disease2}')\n",
    "    plt.legend(legend_handles, legend_labels, title=f\"{disease1} onset age groups\", frameon=False)\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.gca().spines['left'].set_linewidth(2)\n",
    "    plt.gca().spines['bottom'].set_linewidth(2)\n",
    "    plt.gca().spines['left'].set_color('black')\n",
    "    plt.gca().spines['bottom'].set_color('black')\n",
    "    plt.grid(False)\n",
    "    plt.tick_params(axis='x', colors='grey')\n",
    "    plt.tick_params(axis='y', colors='grey')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot as PDF\n",
    "    os.makedirs('./download/', exist_ok=True)\n",
    "    file_name = f'./download/age_difference_{disease1}_vs_{disease2}_bell_curve_fixed.pdf'\n",
    "    plt.savefig(file_name, format='pdf', dpi=300)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with the updated range\n",
    "plot_age_difference_bell_curve_fixed(\n",
    "    age_differences,\n",
    "    age_onset_alzheimer,\n",
    "    'Alzheimer',\n",
    "    'Bacterial Groups'\n",
    ")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_age_difference_bell_curve_by_group(age_differences, age_onset_alzheimer, disease1, group_name):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Define Alzheimer's onset age bins starting from 20 to 90, with 90+ as the last group\n",
    "    age_onset_bins = [20, 30, 40, 50, 60, 70, 80, 90, float('inf')]\n",
    "    colors = plt.get_cmap('tab10')(np.linspace(0, 1, len(age_onset_bins) - 1))\n",
    "\n",
    "    # Assign Alzheimer's onset age groups\n",
    "    age_groups = pd.cut(age_onset_alzheimer, bins=age_onset_bins, labels=False, include_lowest=True)\n",
    "\n",
    "    # Define a consistent range for all KDEs\n",
    "    global_min = age_differences.min() - 5  # Extend range slightly for aesthetics\n",
    "    global_max = age_differences.max() + 5\n",
    "    x_range = np.linspace(global_min, global_max, 500)\n",
    "\n",
    "    # Plot a KDE curve for each age group\n",
    "    legend_handles = []\n",
    "    legend_labels = []\n",
    "\n",
    "    for i in range(len(age_onset_bins) - 1):\n",
    "        # Select age differences for the current Alzheimer's onset age group\n",
    "        group_data = age_differences[age_groups == i]\n",
    "        if len(group_data) > 1:  # KDE requires at least two points\n",
    "            kde = gaussian_kde(group_data)\n",
    "            y_values = kde(x_range)\n",
    "            plt.plot(x_range, y_values, color=colors[i], linewidth=2)\n",
    "\n",
    "            # Add to legend\n",
    "            if age_onset_bins[i+1] == float('inf'):\n",
    "                legend_labels.append('90+ years')\n",
    "            else:\n",
    "                legend_labels.append(f'{age_onset_bins[i]:.0f}-{age_onset_bins[i+1]:.0f} years')\n",
    "            legend_handles.append(plt.Line2D([0], [0], color=colors[i], linewidth=2))\n",
    "\n",
    "    # Add vertical line at x=0\n",
    "    plt.axvline(0, color='grey', linestyle='--', linewidth=2)\n",
    "\n",
    "    # Add labels, title, and formatting\n",
    "    plt.xlabel('Age difference (years)')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title(f'Age difference KDE for {group_name} and {disease1}')\n",
    "    plt.legend(legend_handles, legend_labels, title=f\"{disease1} onset age groups\", frameon=False)\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.gca().spines['left'].set_linewidth(2)\n",
    "    plt.gca().spines['bottom'].set_linewidth(2)\n",
    "    plt.gca().spines['left'].set_color('black')\n",
    "    plt.gca().spines['bottom'].set_color('black')\n",
    "    plt.grid(False)\n",
    "    plt.tick_params(axis='x', colors='grey')\n",
    "    plt.tick_params(axis='y', colors='grey')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot as PDF\n",
    "    os.makedirs('./download/', exist_ok=True)\n",
    "    file_name = f'./download/age_difference_{group_name}_vs_{disease1}_bell_curve.pdf'\n",
    "    plt.savefig(file_name, format='pdf', dpi=300)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Gram-negative bacteria (gram_negative, ecoli, pseudomonas)\n",
    "gram_negative_combined = pd.concat(\n",
    "    [aggregated_dfs_cleaned['gram_negative'], aggregated_dfs_cleaned['ecoli'], aggregated_dfs_cleaned['pseudomonas']],\n",
    "    ignore_index=True\n",
    ")\n",
    "merged_gram_negative = aggregated_dfs_cleaned['alzheimer'].merge(\n",
    "    gram_negative_combined,\n",
    "    on='person_id',\n",
    "    suffixes=('_alzheimer', '_bacteria')\n",
    ")\n",
    "age_diff_gram_negative = merged_gram_negative['age_onset_alzheimer'] - merged_gram_negative['age_onset_bacteria']\n",
    "plot_age_difference_bell_curve_by_group(\n",
    "    age_diff_gram_negative,\n",
    "    merged_gram_negative['age_onset_alzheimer'],\n",
    "    'Alzheimer',\n",
    "    'Gram-negative Bacteria'\n",
    ")\n",
    "\n",
    "# Gram-positive bacteria (gram_positive, staphylococcus, streptococcus)\n",
    "gram_positive_combined = pd.concat(\n",
    "    [aggregated_dfs_cleaned['gram_positive'], aggregated_dfs_cleaned['staphylococcus'], aggregated_dfs_cleaned['streptococcus']],\n",
    "    ignore_index=True\n",
    ")\n",
    "merged_gram_positive = aggregated_dfs_cleaned['alzheimer'].merge(\n",
    "    gram_positive_combined,\n",
    "    on='person_id',\n",
    "    suffixes=('_alzheimer', '_bacteria')\n",
    ")\n",
    "age_diff_gram_positive = merged_gram_positive['age_onset_alzheimer'] - merged_gram_positive['age_onset_bacteria']\n",
    "plot_age_difference_bell_curve_by_group(\n",
    "    age_diff_gram_positive,\n",
    "    merged_gram_positive['age_onset_alzheimer'],\n",
    "    'Alzheimer',\n",
    "    'Gram-positive Bacteria'\n",
    ")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# Create directories for saving output files\n",
    "os.makedirs('./download/', exist_ok=True)\n",
    "\n",
    "# Function to plot histograms of age differences\n",
    "def plot_age_difference_histogram_exact_bins(age_differences, age_onset_alzheimer, group_name, file_prefix):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Define one-year bins for the histogram\n",
    "    min_age_diff = int(age_differences.min()) - 1\n",
    "    max_age_diff = int(age_differences.max()) + 1\n",
    "    #     bins = np.arange(min_age_diff, max_age_diff + 1, 1)\n",
    "    # Define one-year bins for the histogram within the range -20 to 20\n",
    "    bins = np.arange(-20, 21, 1)  # Bins with 1-year increments\n",
    "\n",
    "    # Define simplified age groups: <60, 60-70, >70\n",
    "    age_onset_bins = [0, 60, 70, float('inf')]\n",
    "    age_onset_labels = ['<60', '60-70', '>70']\n",
    "    colors = ['#ff9999', '#66b3ff', '#99ff99']\n",
    "\n",
    "    # Assign Alzheimer's onset age groups\n",
    "    age_groups = pd.cut(age_onset_alzheimer, bins=age_onset_bins, labels=age_onset_labels, include_lowest=True)\n",
    "\n",
    "    # Initialize cumulative values for stacking\n",
    "    cumulative_values = np.zeros(len(bins) - 1)\n",
    "\n",
    "    # Initialize legend handles and labels\n",
    "    legend_handles = []\n",
    "    legend_labels = []\n",
    "\n",
    "    # Total count of age differences\n",
    "    total_count = len(age_differences)\n",
    "\n",
    "    # Plot histogram layers for each age group\n",
    "    for i, label in enumerate(age_onset_labels):\n",
    "        hist_values, _ = np.histogram(age_differences[age_groups == label], bins=bins)\n",
    "        if np.any(hist_values):  # Only plot if the group has data\n",
    "            hist_values_percentage = (hist_values / total_count) * 100\n",
    "            bar = plt.bar(\n",
    "                bins[:-1],\n",
    "                hist_values_percentage,\n",
    "                width=np.diff(bins),\n",
    "                color=colors[i],\n",
    "                edgecolor='black',\n",
    "                bottom=cumulative_values\n",
    "            )\n",
    "            cumulative_values += hist_values_percentage\n",
    "            legend_labels.append(label)\n",
    "            legend_handles.append(bar[0])\n",
    "\n",
    "    # Add vertical line at x=0\n",
    "    plt.axvline(0, color='grey', linestyle='--', linewidth=2)\n",
    "\n",
    "    # Add labels, title, and formatting\n",
    "    plt.xlabel('Age difference (years)')\n",
    "    plt.ylabel('Percentage of patients (%)')\n",
    "    plt.title(f'Age difference between {group_name} onset and Dementia onset')\n",
    "    plt.legend(legend_handles, legend_labels, title=\"Dementia onset age groups\", frameon=False)\n",
    "    plt.gca().spines['left'].set_color('black')\n",
    "    plt.gca().spines['bottom'].set_color('black')\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.gca().spines['left'].set_linewidth(2)\n",
    "    plt.gca().spines['bottom'].set_linewidth(2)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot as PDF\n",
    "    file_name = f'./download/{file_prefix}_histogram.pdf'\n",
    "    plt.savefig(file_name, format='pdf', dpi=300)\n",
    "    plt.show()\n",
    "()\n",
    "\n",
    "# Function to generate bell curve plots\n",
    "def plot_age_difference_bell_curve(age_differences, age_onset_alzheimer, group_name, file_prefix):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Define age bins and range for KDE\n",
    "    age_onset_bins = [20, 30, 40, 50, 60, 70, 80, 90, float('inf')]\n",
    "    colors = plt.get_cmap('tab10')(np.linspace(0, 1, len(age_onset_bins) - 1))\n",
    "    age_groups = pd.cut(age_onset_alzheimer, bins=age_onset_bins, labels=False, include_lowest=True)\n",
    "    x_range = np.linspace(age_differences.min() - 5, age_differences.max() + 5, 500)\n",
    "\n",
    "    # Initialize legend handles and labels\n",
    "    legend_handles = []\n",
    "    legend_labels = []\n",
    "\n",
    "    # Plot KDE for each group\n",
    "    for i in range(len(age_onset_bins) - 1):\n",
    "        group_data = age_differences[age_groups == i]\n",
    "        if len(group_data) > 1:\n",
    "            kde = gaussian_kde(group_data)\n",
    "            y_values = kde(x_range)\n",
    "            plt.plot(x_range, y_values, color=colors[i], linewidth=2)\n",
    "            if age_onset_bins[i+1] == float('inf'):\n",
    "                legend_labels.append('90+ years')\n",
    "            else:\n",
    "                legend_labels.append(f'{age_onset_bins[i]:.0f}-{age_onset_bins[i+1]:.0f} years')\n",
    "            legend_handles.append(plt.Line2D([0], [0], color=colors[i], linewidth=2))\n",
    "\n",
    "    # Add vertical line at x=0\n",
    "    plt.axvline(0, color='grey', linestyle='--', linewidth=2)\n",
    "\n",
    "    # Add labels, title, and formatting\n",
    "    plt.xlabel('Age difference (years)')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title(f'Bell Curve of Age difference between {group_name} and Dementia onset')\n",
    "    plt.legend(legend_handles, legend_labels, title=\"Dementia onset age groups\", frameon=False)\n",
    "    plt.gca().spines['left'].set_color('black')\n",
    "    plt.gca().spines['bottom'].set_color('black')\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.gca().spines['left'].set_linewidth(2)\n",
    "    plt.gca().spines['bottom'].set_linewidth(2)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot as PDF\n",
    "    file_name = f'./download/{file_prefix}_bell_curve.pdf'\n",
    "    plt.savefig(file_name, format='pdf', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# Save statistics to TSV files\n",
    "def save_statistics(age_differences, group_name, file_prefix):\n",
    "    stats = {\n",
    "        'Mean Age Difference': [age_differences.mean()],\n",
    "        'Median Age Difference': [age_differences.median()],\n",
    "        'Min Age Difference': [age_differences.min()],\n",
    "        'Max Age Difference': [age_differences.max()]\n",
    "    }\n",
    "    stats_df = pd.DataFrame(stats)\n",
    "    stats_file = f'./download/{file_prefix}_statistics.tsv'\n",
    "    stats_df.to_csv(stats_file, sep='\\t', index=False)\n",
    "    return stats_file\n",
    "\n",
    "# Analyze gram-negative bacteria\n",
    "plot_age_difference_histogram_exact_bins(age_diff_gram_negative, merged_gram_negative['age_onset_alzheimer'], \"Gram-negative Bacteria\", \"gram_negative\")\n",
    "plot_age_difference_bell_curve(age_diff_gram_negative, merged_gram_negative['age_onset_alzheimer'], \"Gram-negative Bacteria\", \"gram_negative\")\n",
    "gram_negative_stats = save_statistics(age_diff_gram_negative, \"Gram-negative Bacteria\", \"gram_negative\")\n",
    "\n",
    "# Analyze gram-positive bacteria\n",
    "plot_age_difference_histogram_exact_bins(age_diff_gram_positive, merged_gram_positive['age_onset_alzheimer'], \"Gram-positive Bacteria\", \"gram_positive\")\n",
    "plot_age_difference_bell_curve(age_diff_gram_positive, merged_gram_positive['age_onset_alzheimer'], \"Gram-positive Bacteria\", \"gram_positive\")\n",
    "gram_positive_stats = save_statistics(age_diff_gram_positive, \"Gram-positive Bacteria\", \"gram_positive\")\n",
    "\n",
    "# Display paths to saved files\n",
    "gram_negative_stats, gram_positive_stats\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Ensure proper sorting of age groups in the desired order\n",
    "age_group_order = ['<60', '60-70', '>70', 'Overall']\n",
    "\n",
    "# Convert Age Group to a categorical type with the specified order\n",
    "enrichment_results_combined_df['Age Group'] = pd.Categorical(\n",
    "    enrichment_results_combined_df['Age Group'],\n",
    "    categories=age_group_order,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Remove the 'Overall' group and sort by Disease and then Odds Ratio\n",
    "filtered_df = enrichment_results_combined_df[enrichment_results_combined_df['Age Group'] != 'Overall']\n",
    "filtered_df_sorted = filtered_df.sort_values(by=['Disease', 'Odds Ratio'], ascending=[True, False])\n",
    "\n",
    "# Save the sorted results to a TSV file\n",
    "output_file_path = './download/alzheimer_enrichment_analysis_sorted_disease_odds_ratio.tsv'\n",
    "filtered_df_sorted.to_csv(output_file_path, sep='\\t', index=False)\n",
    "\n",
    "# Visualize the sorted results with a forest plot\n",
    "plt.figure(figsize=(12, 14))\n",
    "\n",
    "# Calculate 95% confidence intervals\n",
    "ci_lower = []\n",
    "ci_upper = []\n",
    "\n",
    "for i in range(len(filtered_df_sorted)):\n",
    "    row = filtered_df_sorted.iloc[i]\n",
    "    disease = row['Disease']\n",
    "    age_group = row['Age Group']\n",
    "    odds_ratio = row['Odds Ratio']\n",
    "\n",
    "    # Use age-specific counts\n",
    "    a = df[(df['age_group'] == age_group) & (df['person_id'].isin(alzheimer_unique_person_ids))].shape[0]\n",
    "    b = df[(df['age_group'] == age_group) & (~df['person_id'].isin(alzheimer_unique_person_ids))].shape[0]\n",
    "    c = len(alzheimer_unique_person_ids) - a\n",
    "    d = len(older_people) - len(alzheimer_unique_person_ids) - b\n",
    "\n",
    "    # Calculate confidence intervals\n",
    "    se = np.sqrt(1 / a + 1 / b + 1 / c + 1 / d)\n",
    "    log_or = np.log(odds_ratio)\n",
    "    ci_lower.append(np.exp(log_or - 1.96 * se))\n",
    "    ci_upper.append(np.exp(log_or + 1.96 * se))\n",
    "\n",
    "# Create the forest plot\n",
    "xerr = [\n",
    "    np.array(filtered_df_sorted['Odds Ratio']) - np.array(ci_lower),\n",
    "    np.array(ci_upper) - np.array(filtered_df_sorted['Odds Ratio'])\n",
    "]\n",
    "colors = ['blue' if p < 0.05 else 'salmon' for p in filtered_df_sorted['P-Value']]\n",
    "y_positions = range(len(filtered_df_sorted))\n",
    "\n",
    "plt.errorbar(filtered_df_sorted['Odds Ratio'], y_positions, xerr=xerr, fmt='o', color='gray', ecolor='black', capsize=3)\n",
    "\n",
    "# Highlight statistically significant points\n",
    "for i, color in enumerate(colors):\n",
    "    plt.scatter(filtered_df_sorted['Odds Ratio'].iloc[i], y_positions[i], color=color, zorder=3)\n",
    "\n",
    "# Add vertical reference line\n",
    "plt.axvline(x=1, color='red', linestyle='--', zorder=1)\n",
    "\n",
    "# Customize plot\n",
    "plt.gca().spines['left'].set_color('black')\n",
    "plt.gca().spines['bottom'].set_color('black')\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['left'].set_linewidth(2)\n",
    "plt.gca().spines['bottom'].set_linewidth(2)\n",
    "\n",
    "plt.yticks(y_positions, filtered_df_sorted.apply(lambda row: f\"{row['Disease']} ({row['Age Group']})\", axis=1))\n",
    "plt.xlabel('Odds Ratio (log scale)')\n",
    "plt.title('Enrichment Analysis: Alzheimer vs. Selected Diseases\\n(Odds Ratio: Likelihood of Co-occurrence)', fontsize=14, weight='bold')\n",
    "plt.suptitle('Odds Ratio > 1: Disease more common in AD patients | Odds Ratio < 1: Disease less common', fontsize=10, style='italic')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save and display the forest plot\n",
    "forest_plot_path = './download/alzheimer_enrichment_analysis_forest_plot_sorted_disease_odds_ratio.pdf'\n",
    "plt.savefig(forest_plot_path, format='pdf')\n",
    "plt.show()\n",
    "\n",
    "# Display paths of saved files\n",
    "output_file_path, forest_plot_path\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
